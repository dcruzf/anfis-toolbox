{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5d16ef",
   "metadata": {},
   "source": [
    "# Advanced ANFIS Example\n",
    "\n",
    "This notebook demonstrates a more advanced workflow for ANFIS-Toolbox:\n",
    "\n",
    "- 3D nonlinear regression dataset with noise\n",
    "- Feature standardization\n",
    "- Lightweight hyperparameter search with 3-fold CV (grid over `n_mfs`, `mf_type`, `epochs`)\n",
    "- Final training and hold-out evaluation\n",
    "- Visualizations: training curve, parity plot, residuals histogram, and a 2D surface (slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c35e8e",
   "metadata": {},
   "source": [
    "## 1) Imports and setup\n",
    "We import NumPy, plotting, and core utilities from ANFIS-Toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a56f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from anfis_toolbox import QuickANFIS, quick_evaluate\n",
    "from anfis_toolbox.model_selection import KFold, train_test_split\n",
    "from anfis_toolbox.metrics import r2_score\n",
    "\n",
    "np.random.seed(42)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cabaa1f",
   "metadata": {},
   "source": [
    "## 2) Create a 3D nonlinear dataset and standardize\n",
    "Target: `y = sin(x1) + 0.3 * x2^2 + 0.5 * cos(1.5 * x3) + noise`.\n",
    "We standardize inputs to help training stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d23ec4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 3), (800, 3), (800, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 800\n",
    "x1 = np.random.uniform(-3.0, 3.0, size=n)\n",
    "x2 = np.random.uniform(-2.0, 2.0, size=n)\n",
    "x3 = np.random.uniform(-1.5, 1.5, size=n)\n",
    "X = np.column_stack([x1, x2, x3])\n",
    "y = np.sin(x1) + 0.3 * (x2 ** 2) + 0.5 * np.cos(1.5 * x3) + 0.1 * np.random.randn(n)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Standardize features\n",
    "mu = X.mean(axis=0)\n",
    "sd = X.std(axis=0) + 1e-12\n",
    "X_std = (X - mu) / sd\n",
    "X.shape, X_std.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d408f0",
   "metadata": {},
   "source": [
    "## 3) Train/test split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67df5ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((640, 3), (160, 3), (640, 1), (160, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8bec6d",
   "metadata": {},
   "source": [
    "## 4) Hyperparameter grid and 3-fold cross-validation\n",
    "We search over MF count, MF type, and epochs. Metric: mean validation RÂ²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef5a31",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mf_type \u001b[38;5;129;01min\u001b[39;00m param_grid[\u001b[33m'\u001b[39m\u001b[33mmf_type\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epochs \u001b[38;5;129;01min\u001b[39;00m param_grid[\u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         score = \u001b[43mevaluate_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmf_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m         results.append({\u001b[33m'\u001b[39m\u001b[33mn_mfs\u001b[39m\u001b[33m'\u001b[39m: n_mfs, \u001b[33m'\u001b[39m\u001b[33mmf_type\u001b[39m\u001b[33m'\u001b[39m: mf_type, \u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m: epochs, \u001b[33m'\u001b[39m\u001b[33mmean_r2\u001b[39m\u001b[33m'\u001b[39m: score})\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mprint\u001b[39m(score)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mevaluate_config\u001b[39m\u001b[34m(n_mfs, mf_type, epochs)\u001b[39m\n\u001b[32m     13\u001b[39m y_tr, y_va = y_train[tr_idx], y_train[va_idx]\n\u001b[32m     14\u001b[39m model = QuickANFIS.for_regression(X_tr, n_mfs=n_mfs, mf_type=mf_type, init=\u001b[33m'\u001b[39m\u001b[33mfcm\u001b[39m\u001b[33m'\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m y_va_pred = model.predict(X_va)\n\u001b[32m     17\u001b[39m r2s.append(r2_score(y_va, y_va_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/anfis-toolbox/anfis_toolbox/model.py:280\u001b[39m, in \u001b[36mANFIS.fit\u001b[39m\u001b[34m(self, x, y, epochs, learning_rate, verbose, trainer)\u001b[39m\n\u001b[32m    277\u001b[39m     trainer = HybridTrainer(learning_rate=learning_rate, epochs=epochs, verbose=verbose)\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# Delegate training to the provided or default trainer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/anfis-toolbox/anfis_toolbox/optim/hybrid.py:63\u001b[39m, in \u001b[36mHybridTrainer.fit\u001b[39m\u001b[34m(self, model, X, y)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Backpropagate for antecedent (membership) parameters only\u001b[39;00m\n\u001b[32m     62\u001b[39m dL_dy = \u001b[32m2\u001b[39m * (y_pred - y) / y.shape[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m dL_dnorm_w, _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconsequent_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdL_dy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m dL_dw = model.normalization_layer.backward(dL_dnorm_w)\n\u001b[32m     65\u001b[39m gradients = model.rule_layer.backward(dL_dw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/anfis-toolbox/anfis_toolbox/layers.py:367\u001b[39m, in \u001b[36mConsequentLayer.backward\u001b[39m\u001b[34m(self, dL_dy)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_rules):\n\u001b[32m    365\u001b[39m     \u001b[38;5;66;03m# Gradient of y_hat w.r.t. parameters of rule i: norm_w_i * x_aug\u001b[39;00m\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m         \u001b[38;5;28mself\u001b[39m.gradients[i] += dL_dy[b, \u001b[32m0\u001b[39m] * norm_w[b, i] * X_aug[b]\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# Compute gradient of loss w.r.t. normalized weights\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# dy/dnorm_w_i = f_i(x), so dL/dnorm_w_i = dL/dy * f_i(x)\u001b[39;00m\n\u001b[32m    371\u001b[39m dL_dnorm_w = dL_dy * f  \u001b[38;5;66;03m# (batch_size, n_rules)\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_mfs': [5, 7],\n",
    "    'mf_type': ['gaussian', 'bell'],\n",
    "    'epochs': [80, 120]\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "def evaluate_config(n_mfs, mf_type, epochs):\n",
    "    r2s = []\n",
    "    for tr_idx, va_idx in kf.split(X_train):\n",
    "        X_tr, X_va = X_train[tr_idx], X_train[va_idx]\n",
    "        y_tr, y_va = y_train[tr_idx], y_train[va_idx]\n",
    "        model = QuickANFIS.for_regression(X_tr, n_mfs=n_mfs, mf_type=mf_type, init='fcm', random_state=42)\n",
    "        _ = model.fit(X_tr, y_tr, epochs=epochs, learning_rate=0.02, verbose=False)\n",
    "        y_va_pred = model.predict(X_va)\n",
    "        r2s.append(r2_score(y_va, y_va_pred))\n",
    "    return float(np.mean(r2s))\n",
    "\n",
    "best_cfg, best_score = None, -np.inf\n",
    "results = []\n",
    "print(\"Evaluating configurations:\")\n",
    "for n_mfs in param_grid['n_mfs']:\n",
    "    for mf_type in param_grid['mf_type']:\n",
    "        for epochs in param_grid['epochs']:\n",
    "            score = evaluate_config(n_mfs, mf_type, epochs)\n",
    "            results.append({'n_mfs': n_mfs, 'mf_type': mf_type, 'epochs': epochs, 'mean_r2': score})\n",
    "            print(score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_cfg = {'n_mfs': n_mfs, 'mf_type': mf_type, 'epochs': epochs}\n",
    "best_cfg, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91150a3",
   "metadata": {},
   "source": [
    "## 5) Train final model with best config and evaluate on hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5221328",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = QuickANFIS.for_regression(X_train, n_mfs=best_cfg['n_mfs'], mf_type=best_cfg['mf_type'], init='fcm', random_state=123)\n",
    "losses = model_best.fit(X_train, y_train, epochs=best_cfg['epochs'], learning_rate=0.02, verbose=False)\n",
    "metrics_train = quick_evaluate(model_best, X_train, y_train, print_results=False)\n",
    "metrics_test = quick_evaluate(model_best, X_test, y_test, print_results=False)\n",
    "metrics_train, metrics_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef2cb19",
   "metadata": {},
   "source": [
    "### Training curve (loss vs. epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02620d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(losses, color='tab:blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training curve (Hybrid)')\n",
    "# zoom if nearly flat\n",
    "if len(losses) > 5 and (max(losses) - min(losses)) < 1e-2:\n",
    "    lo, hi = min(losses), max(losses)\n",
    "    plt.ylim(lo - 0.02 * (hi - lo + 1e-9), hi + 0.02 * (hi - lo + 1e-9))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f349336",
   "metadata": {},
   "source": [
    "### Parity plot (y true vs. y pred) on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model_best.predict(X_test)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(y_test, y_pred_test, s=10, alpha=0.4, color='tab:green')\n",
    "mn, mx = float(np.min(y_test)), float(np.max(y_test))\n",
    "plt.plot([mn, mx], [mn, mx], 'r--', lw=2, label='ideal')\n",
    "plt.xlabel('y true')\n",
    "plt.ylabel('y pred')\n",
    "plt.title('Parity plot (test)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29524e",
   "metadata": {},
   "source": [
    "### Residuals histogram (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (y_test - y_pred_test).ravel()\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.hist(res, bins=30, color='tab:purple', alpha=0.75)\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Residuals histogram (test)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a56c5f",
   "metadata": {},
   "source": [
    "## 6) 2D prediction surface (slice)\n",
    "We fix one feature at its median (from train set) and visualize predictions over a grid for the other two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23702b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose to vary dimensions 0 and 1; fix dim 2 at its train median\n",
    "dim_x, dim_y, dim_fix = 0, 1, 2\n",
    "fixed_val = np.median(X_train[:, dim_fix])\n",
    "\n",
    "gx = np.linspace(np.percentile(X_train[:, dim_x], 2), np.percentile(X_train[:, dim_x], 98), 60)\n",
    "gy = np.linspace(np.percentile(X_train[:, dim_y], 2), np.percentile(X_train[:, dim_y], 98), 60)\n",
    "GX, GY = np.meshgrid(gx, gy)\n",
    "grid = np.stack([GX.ravel(), GY.ravel(), np.full(GX.size, fixed_val)], axis=1)\n",
    "Z = model_best.predict(grid).reshape(GX.shape)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "cs = plt.contourf(GX, GY, Z, levels=30, cmap='viridis')\n",
    "plt.colorbar(cs, shrink=0.8, label='prediction')\n",
    "plt.xlabel(f'feature {dim_x} (std)')\n",
    "plt.ylabel(f'feature {dim_y} (std)')\n",
    "plt.title('2D prediction surface (slice, fix dim 2)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34cf708",
   "metadata": {},
   "source": [
    "## 7) Tips & next steps\n",
    "- Prefer `init=\"fcm\"` for centers; it often converges faster than a uniform grid.\n",
    "- Tune `n_mfs`, `epochs`, and `learning_rate` via cross-validation.\n",
    "- If residuals show structure, try more MFs or a different MF type.\n",
    "- For larger datasets, consider mini-batch training with `SGDTrainer`.\n",
    "- Save/load parameters: use `model.get_parameters()` and persist with `np.savez`; restore with `model.set_parameters(...)`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
