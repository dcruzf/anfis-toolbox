# ANFIS: Algoritmo H√≠brido vs Backpropagation

Este documento compara os dois m√©todos de otimiza√ß√£o dispon√≠veis no ANFIS Toolbox: o **algoritmo h√≠brido original** de Jang (1993) e o **backpropagation puro** usado em implementa√ß√µes modernas.

## üìö **Contexto Hist√≥rico**

### Algoritmo Original (Jang, 1993)
O ANFIS foi originalmente proposto com um **algoritmo h√≠brido de aprendizado** que combina:
- **M√©todo dos M√≠nimos Quadrados (LSM)** para par√¢metros consequentes
- **Backpropagation** para par√¢metros das fun√ß√µes de pertin√™ncia

### Implementa√ß√µes Modernas
Muitas implementa√ß√µes modernas simplificam o algoritmo usando apenas **backpropagation** para todos os par√¢metros, por ser mais simples de implementar.

## üîç **Diferen√ßas T√©cnicas**

### Algoritmo H√≠brido Original (`fit_hybrid()`)

```python
# Em cada epoch:
# 1. FORWARD PASS - Otimiza√ß√£o anal√≠tica (LSM) dos par√¢metros consequentes
A = construir_matriz_design(x, pesos_normalizados)
theta = (A^T A + reg)^(-1) A^T y  # Solu√ß√£o anal√≠tica √≥tima

# 2. BACKWARD PASS - Backpropagation para fun√ß√µes de pertin√™ncia
gradientes = calcular_gradientes_backprop(x, y, theta_fixo)
atualizar_parametros_pertinencia(gradientes, learning_rate)
```

**Caracter√≠sticas:**
- ‚úÖ **Otimiza√ß√£o anal√≠tica** dos par√¢metros consequentes (√≥timo global)
- ‚úÖ **Converg√™ncia mais r√°pida** (menos epochs necess√°rios)
- ‚úÖ **Melhor precis√£o** na maioria dos casos
- ‚ö†Ô∏è **Custo computacional maior** por epoch (invers√£o de matriz)
- ‚ö†Ô∏è **Poss√≠veis problemas num√©ricos** com matrizes mal-condicionadas

### Backpropagation Puro (`fit()`)

```python
# Em cada epoch:
# 1. FORWARD PASS - Calcular sa√≠da com par√¢metros atuais
y_pred = forward(x)

# 2. BACKWARD PASS - Gradientes para todos os par√¢metros
gradientes = calcular_todos_gradientes(x, y, y_pred)
atualizar_todos_parametros(gradientes, learning_rate)
```

**Caracter√≠sticas:**
- ‚úÖ **Implementa√ß√£o simples** e uniforme
- ‚úÖ **Est√°vel numericamente**
- ‚úÖ **Menor custo computacional** por epoch
- ‚ö†Ô∏è **Converg√™ncia mais lenta** (mais epochs necess√°rios)
- ‚ö†Ô∏è **Pode ficar preso em m√≠nimos locais**

## üìä **Resultados Experimentais**

### Exemplo: Aproxima√ß√£o de Fun√ß√£o 2D
```
Fun√ß√£o: f(x1, x2) = sin(x1) * cos(x2) + 0.5 * x1 * x2
Dados: 100 amostras de treinamento, 400 de teste
Configura√ß√£o: 3√ó3 fun√ß√µes de pertin√™ncia, 50 epochs
```

| M√©trica | Algoritmo H√≠brido | Backpropagation | Vantagem |
|---------|-------------------|-----------------|----------|
| **Loss Final** | 0.000070 | 0.306319 | **H√≠brido 4375x melhor** |
| **RMSE Teste** | 0.020445 | 0.639563 | **H√≠brido 31x melhor** |
| **Tempo/Epoch** | 16.6ms | 13.6ms | Backprop 18% mais r√°pido |
| **Converg√™ncia** | Epoch 1 | Epoch 50+ | **H√≠brido 50x mais r√°pido** |

## üéØ **Quando Usar Cada M√©todo?**

### Use Algoritmo H√≠brido (`fit_hybrid()`) quando:
- ‚úÖ **Precis√£o √© cr√≠tica**
- ‚úÖ **Dados de boa qualidade** (n√£o muito ru√≠do)
- ‚úÖ **Problema bem-definido** com fun√ß√£o objetivo clara
- ‚úÖ **Poucos epochs dispon√≠veis**
- ‚úÖ **Aproxima√ß√£o de fun√ß√µes** matem√°ticas

### Use Backpropagation (`fit()`) quando:
- ‚úÖ **Implementa√ß√£o deve ser simples**
- ‚úÖ **Dados ruidosos** ou mal-condicionados
- ‚úÖ **Muitos epochs dispon√≠veis**
- ‚úÖ **Problemas de classifica√ß√£o**
- ‚úÖ **Modelos muito grandes** (custo de LSM proibitivo)

## üíª **Como Usar**

### Algoritmo H√≠brido (Recomendado)
```python
from anfis_toolbox import ANFIS, GaussianMF

# Criar modelo
input_mfs = {
    'x1': [GaussianMF(-1, 0.8), GaussianMF(0, 0.8), GaussianMF(1, 0.8)],
    'x2': [GaussianMF(-1, 0.8), GaussianMF(0, 0.8), GaussianMF(1, 0.8)]
}
model = ANFIS(input_mfs)

# Treinar com algoritmo h√≠brido original
losses = model.fit_hybrid(x_train, y_train, epochs=50, learning_rate=0.01)
```

### Backpropagation Puro
```python
# Mesmo setup...
# Treinar com backpropagation puro
losses = model.fit(x_train, y_train, epochs=50, learning_rate=0.01)
```

### Compara√ß√£o Autom√°tica
```python
from examples.usage_examples import example_hybrid_vs_backprop

# Executa compara√ß√£o completa nos seus dados
example_hybrid_vs_backprop()
```

## ‚öôÔ∏è **Detalhes da Implementa√ß√£o**

### M√©todo dos M√≠nimos Quadrados (LSM)
O algoritmo h√≠brido constr√≥i a **matriz de design A** onde cada linha representa uma amostra e cada coluna um par√¢metro consequente:

```
A[i, j*(n_inputs+1) : (j+1)*(n_inputs+1)] = w_j[i] * [x1[i], x2[i], ..., xn[i], 1]
```

Onde `w_j[i]` √© o peso normalizado da regra j para a amostra i.

A solu√ß√£o √≥tima √©: `Œ∏ = (A^T A + ŒªI)^(-1) A^T y`

### Regulariza√ß√£o
Para estabilidade num√©rica, adicionamos uma pequena regulariza√ß√£o (Œª=1e-6) na diagonal de A^T A.

### Tratamento de Singularidades
Se a matriz for singular, fazemos fallback para pseudo-inversa: `Œ∏ = pinv(A) y`

## üèÜ **Conclus√£o**

O **algoritmo h√≠brido original** de Jang (1993) demonstra superioridade clara em:
- **Precis√£o**: At√© 4000x menor erro
- **Velocidade de converg√™ncia**: Converge em 1-5 epochs vs 50+
- **Estabilidade**: Menos sens√≠vel a hiperpar√¢metros

O ANFIS Toolbox oferece **ambas as implementa√ß√µes**, permitindo escolher a mais adequada para cada aplica√ß√£o. Para a maioria dos casos, recomendamos o algoritmo h√≠brido original (`fit_hybrid()`) devido √† sua efici√™ncia e precis√£o superiores.

## üìñ **Refer√™ncias**

1. Jang, J.S.R. (1993). "ANFIS: adaptive-network-based fuzzy inference system". IEEE Transactions on Systems, Man, and Cybernetics, 23(3), 665-685.
2. Takagi, T. & Sugeno, M. (1985). "Fuzzy identification of systems and its applications to modeling and control". IEEE Transactions on Systems, Man, and Cybernetics, 15(1), 116-132.
