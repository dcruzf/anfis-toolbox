{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ANFIS Toolbox","text":"<p> The most user-friendly Python library for Adaptive Neuro-Fuzzy Inference Systems (ANFIS) </p> <p>Documentation: https://dcruzf.github.io/anfis-toolbox</p> <p>Source Code: https://github.com/dcruzf/anfis-toolbox</p> <p>PyPI: https://pypi.org/project/anfis-toolbox</p> <p>ANFIS Toolbox is a comprehensive Python library for creating, training, and deploying Adaptive Neuro-Fuzzy Inference Systems (ANFIS). It provides an intuitive API that makes fuzzy neural networks accessible to both beginners and experts.</p>"},{"location":"#key-features","title":"Key Features","text":"<p>\u2728 Easy to Use - Get started with just 3 lines of code \ud83c\udfd7\ufe0f Flexible Architecture - 6 membership functions, hybrid learning \ud83d\udcca Built-in Visualization - Automatic plots for training and results \u2705 Robust Validation - Cross-validation, metrics, model comparison \ud83d\udcda Rich Documentation - Comprehensive examples and tutorials \ud83d\udd27 Production Ready - Model persistence and configuration management</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import numpy as np\nfrom anfis_toolbox import QuickANFIS, quick_evaluate\n\n# 1. Prepare your data\nX = np.random.uniform(-2, 2, (100, 2))  # 2 inputs\ny = X[:, 0]**2 + X[:, 1]**2  # Target: x1\u00b2 + x2\u00b2\n\n# 2. Create and train model (one line!)\nmodel = QuickANFIS.for_regression(X, n_mfs=3)\nlosses = model.fit_hybrid(X, y, epochs=50)\n\n# 3. Evaluate and use\nmetrics = quick_evaluate(model, X, y)\npredictions = model.predict([[1.0, -0.5], [0.5, 1.2]])\n\nprint(f\"R\u00b2 Score: {metrics['r2']:.4f}\")\n</code></pre> <p>That's it! \ud83c\udf89 You just created and trained a neuro-fuzzy system!</p>"},{"location":"#installation","title":"Installation","text":"Basic InstallationFull InstallationSpecific FeaturesDevelopment Installation <p>Install the core package with minimal dependencies:</p> <pre><code>pip install anfis-toolbox\n</code></pre> <p>Install with all features (visualization):</p> <pre><code>pip install anfis-toolbox[all]\n</code></pre> <p>Install with specific optional features:</p> <pre><code># For visualization features\npip install anfis-toolbox[visualization]\n\n# Validation features are built-in (no extra needed)\n</code></pre> <p>For development and contribution:</p> <pre><code>git clone https://github.com/dcruzf/anfis-toolbox.git\ncd anfis-toolbox\npip install -e .[all,dev]\n</code></pre>"},{"location":"#why-anfis-toolbox","title":"Why ANFIS Toolbox?","text":""},{"location":"#simplicity-first","title":"\ud83d\ude80 Simplicity First","text":"<p>Most fuzzy logic libraries require extensive boilerplate code. ANFIS Toolbox gets you running in seconds:</p> <pre><code># Traditional approach (10+ lines)\ninput_mfs = {\n    'x1': [GaussianMF(-1, 1), GaussianMF(1, 1)],\n    'x2': [GaussianMF(-1, 1), GaussianMF(1, 1)]\n}\nmodel = ANFIS(input_mfs)\n# ... manual setup ...\n\n# ANFIS Toolbox approach (1 line)\nmodel = QuickANFIS.for_regression(X)\n</code></pre>"},{"location":"#visual-insights","title":"\ud83d\udcca Visual Insights","text":"<p>Built-in visualization helps you understand your models:</p> <pre><code>from anfis_toolbox import ANFISVisualizer\n\nvisualizer = ANFISVisualizer(model)\nvisualizer.plot_membership_functions()  # Show MF shapes\nvisualizer.plot_training_curves(losses)  # Training progress\nvisualizer.plot_prediction_vs_target(X, y)  # Model performance\n</code></pre>"},{"location":"#validation-made-easy-built-in","title":"\u2705 Validation Made Easy (Built-in)","text":"<p>Comprehensive model evaluation with minimal code:</p> <pre><code>from anfis_toolbox import ANFISValidator\n\nvalidator = ANFISValidator(model)\n\n# Cross-validation\ncv_results = validator.cross_validate(X, y, cv=5)\nprint(f\"CV R\u00b2: {cv_results['r2_mean']:.4f} \u00b1 {cv_results['r2_std']:.4f}\")\n\n# Learning curves\nlearning_data = validator.learning_curve(X, y)\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":"Application Description Code Example Function Approximation Learn complex mathematical functions <code>QuickANFIS.for_function_approximation([(-\u03c0, \u03c0)])</code> Regression Predict continuous values <code>QuickANFIS.for_regression(X)</code> Control Systems Design fuzzy controllers Custom MF setup for error/error-rate Time Series Forecast future values Multi-lag input configuration Pattern Recognition Classify with fuzzy boundaries Post-process regression outputs"},{"location":"#architecture","title":"Architecture","text":"<p>ANFIS Toolbox implements the complete 4-layer ANFIS architecture:</p> <pre><code>graph LR\n    A[Input Layer] --&gt; B[Membership Layer]\n    B --&gt; C[Rule Layer]\n    C --&gt; D[Normalization Layer]\n    D --&gt; E[Consequent Layer]\n    E --&gt; F[Output]</code></pre>"},{"location":"#supported-membership-functions","title":"Supported Membership Functions","text":"<ul> <li>Gaussian (<code>GaussianMF</code>) - Smooth bell curves</li> <li>Triangular (<code>TriangularMF</code>) - Simple triangular shapes</li> <li>Trapezoidal (<code>TrapezoidalMF</code>) - Plateau regions</li> <li>Bell-shaped (<code>BellMF</code>) - Generalized bell curves</li> <li>Sigmoidal (<code>SigmoidalMF</code>) - S-shaped transitions</li> <li>S-shaped (<code>SShapedMF</code>) and Z-shaped (<code>ZShapedMF</code>) - Smoothstep transitions</li> <li>Pi-shaped (<code>PiMF</code>) - Bell with flat top</li> </ul>"},{"location":"#training-methods","title":"Training Methods","text":"<ul> <li>Hybrid Learning (recommended) - Combines least squares + backpropagation</li> <li>Pure Backpropagation - Full gradient-based training</li> <li>Analytical Gradients - Fast and accurate derivative computation</li> </ul>"},{"location":"#performance","title":"Performance","text":"Model Size Training Speed Memory Usage Small (2\u00d73) ~1s / 50 epochs &lt;10 MB Medium (3\u00d74) ~3s / 50 epochs &lt;50 MB Large (5\u00d75) ~15s / 50 epochs &lt;200 MB <p>Benchmarks on Intel i7, 16GB RAM</p>"},{"location":"#whats-next","title":"What's Next?","text":"<ul> <li>\ud83d\udcd6 Getting Started - Install and run your first model</li> <li>\ud83c\udfaf Quick Start - 5-minute tutorial</li> <li>\ud83d\udcda User Guide - Comprehensive documentation</li> <li>\ud83d\udca1 Examples - Real-world use cases</li> <li>\ud83d\udd27 API Reference - Complete function documentation<ul> <li>\ud83d\udcd0 Membership Functions - All MF classes</li> </ul> </li> </ul>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>\ud83d\udc1b Report Issues - Bug reports and feature requests</li> <li>\ud83d\udcac Discussions - Questions and community chat</li> <li>\ud83d\udce7 Contact - Direct contact with maintainers</li> <li>\u2b50 Star on GitHub - Show your support!</li> </ul> Ready to dive into fuzzy neural networks? Get started now \u2192"},{"location":"exemplos/","title":"Exemplos","text":"In\u00a0[\u00a0]: Copied! In\u00a0[1]: Copied! <pre>import numpy as np\n\nfrom anfis_toolbox import QuickANFIS, quick_evaluate\n\n# 1. Prepare your data\nX = np.random.uniform(-2, 2, (100, 2))  # 2 inputs\ny = X[:, 0]**2 + X[:, 1]**2  # Target: x1\u00b2 + x2\u00b2\n\n# 2. Create and train model (one line!)\nmodel = QuickANFIS.for_regression(X, n_mfs=3)\nlosses = model.fit_hybrid(X, y, epochs=50)\n\n# 3. Evaluate and use\nmetrics = quick_evaluate(model, X, y)\npredictions = model.predict([[1.0, -0.5], [0.5, 1.2]])\n\nprint(f\"R\u00b2 Score: {metrics['r2']:.4f}\")\n</pre> import numpy as np  from anfis_toolbox import QuickANFIS, quick_evaluate  # 1. Prepare your data X = np.random.uniform(-2, 2, (100, 2))  # 2 inputs y = X[:, 0]**2 + X[:, 1]**2  # Target: x1\u00b2 + x2\u00b2  # 2. Create and train model (one line!) model = QuickANFIS.for_regression(X, n_mfs=3) losses = model.fit_hybrid(X, y, epochs=50)  # 3. Evaluate and use metrics = quick_evaluate(model, X, y) predictions = model.predict([[1.0, -0.5], [0.5, 1.2]])  print(f\"R\u00b2 Score: {metrics['r2']:.4f}\") <pre>==================================================\nANFIS Model Evaluation Results\n==================================================\nMean Squared Error (MSE):     0.000786\nRoot Mean Squared Error:      0.028043\nMean Absolute Error (MAE):    0.023627\nR-squared (R\u00b2):               0.9997\nMean Abs. Percentage Error:   364.55%\nMaximum Error:                6.878198\nStandard Deviation of Error:  2.474607\n==================================================\nR\u00b2 Score: 0.9997\n</pre> In\u00a0[6]: Copied! <pre>import numpy as np\n\nfrom anfis_toolbox import QuickANFIS\n\n# Generate data\nX = np.random.uniform(-3, 3, (200, 2))\ny = np.sin(X[:, 0]) * np.cos(X[:, 1]) + 0.1 * np.random.randn(200)\n\n# Create and train model\nmodel = QuickANFIS.for_regression(X, n_mfs=4, mf_type='gaussian')\nlosses = model.fit_hybrid(X, y, epochs=100, learning_rate=0.01)\n\n# Evaluate and visualize\n# Evaluate (placeholder)\npred = model.predict(X[:5])\nmetrics = quick_evaluate(model, X, y)\nprint(f\"R\u00b2 Score: {metrics['r2']:.4f}\")\nprint(pred[:3])\n</pre> import numpy as np  from anfis_toolbox import QuickANFIS  # Generate data X = np.random.uniform(-3, 3, (200, 2)) y = np.sin(X[:, 0]) * np.cos(X[:, 1]) + 0.1 * np.random.randn(200)  # Create and train model model = QuickANFIS.for_regression(X, n_mfs=4, mf_type='gaussian') losses = model.fit_hybrid(X, y, epochs=100, learning_rate=0.01)  # Evaluate and visualize # Evaluate (placeholder) pred = model.predict(X[:5]) metrics = quick_evaluate(model, X, y) print(f\"R\u00b2 Score: {metrics['r2']:.4f}\") print(pred[:3]) <pre>==================================================\nANFIS Model Evaluation Results\n==================================================\nMean Squared Error (MSE):     0.008008\nRoot Mean Squared Error:      0.089486\nMean Absolute Error (MAE):    0.066921\nR-squared (R\u00b2):               0.9663\nMean Abs. Percentage Error:   460.00%\nMaximum Error:                2.075404\nStandard Deviation of Error:  0.684013\n==================================================\nR\u00b2 Score: 0.9663\n[[-0.0553184 ]\n [ 0.24896099]\n [ 0.17627969]]\n</pre> In\u00a0[7]: Copied! <pre>import numpy as np\n\nfrom anfis_toolbox import ANFISBuilder\n\n# Prepare data\nX = np.random.uniform(-1, 1, (300, 3))\ny = X[:, 0] * X[:, 1] + np.sin(X[:, 2]) + 0.05 * np.random.randn(300)\n\n# Configure model\nconfig = dict(n_epochs=150, learning_rate=0.02)\n\n# Build model with custom architecture\nbuilder = (ANFISBuilder()\n    .add_input('x1', 'gaussian', n_mfs=3)\n    .add_input('x2', 'bell', n_mfs=4)\n    .add_input('x3', 'triangular', n_mfs=2)\n    .set_config(config)\n)\n\nmodel = builder.build()\n\n# Train with validation\nlosses = model.fit_hybrid(X, y, **config)\n\n# Comprehensive evaluation\n# Placeholder evaluation\nprint(f\"Loss history (len): {len(losses)}\")\n\n# Save model\n# Placeholder persistence\n# model.save('complex_model.pkl')\n</pre> import numpy as np  from anfis_toolbox import ANFISBuilder  # Prepare data X = np.random.uniform(-1, 1, (300, 3)) y = X[:, 0] * X[:, 1] + np.sin(X[:, 2]) + 0.05 * np.random.randn(300)  # Configure model config = dict(n_epochs=150, learning_rate=0.02)  # Build model with custom architecture builder = (ANFISBuilder()     .add_input('x1', 'gaussian', n_mfs=3)     .add_input('x2', 'bell', n_mfs=4)     .add_input('x3', 'triangular', n_mfs=2)     .set_config(config) )  model = builder.build()  # Train with validation losses = model.fit_hybrid(X, y, **config)  # Comprehensive evaluation # Placeholder evaluation print(f\"Loss history (len): {len(losses)}\")  # Save model # Placeholder persistence # model.save('complex_model.pkl') <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[7], line 13\n      9 config = dict(n_epochs=150, learning_rate=0.02)\n     11 # Build model with custom architecture\n     12 builder = (ANFISBuilder()\n---&gt; 13     .add_input('x1', 'gaussian', n_mfs=3)\n     14     .add_input('x2', 'bell', n_mfs=4)\n     15     .add_input('x3', 'triangular', n_mfs=2)\n     16     .set_config(config)\n     17 )\n     19 model = builder.build()\n     21 # Train with validation\n\nTypeError: ANFISBuilder.add_input() missing 1 required positional argument: 'range_max'</pre> In\u00a0[9]: Copied! <pre>import matplotlib.pyplot as plt\n\n\ndef plot_anfis_structure(n_inputs=2, mfs_per_input=2, n_rules=4):\n    fig, ax = plt.subplots(figsize=(8, 5))\n\n    # fun\u00e7\u00e3o auxiliar: cria coordenadas centralizadas\n    def centered_positions(x, n):\n        offset = (n - 1) / 2\n        return [(x, i - offset) for i in range(n)]\n\n    # posi\u00e7\u00f5es dos n\u00f3s\n    layers = {\n        \"inputs\": centered_positions(0, n_inputs),\n        \"mfs\": centered_positions(1, n_inputs * mfs_per_input),\n        \"rules\": centered_positions(2, n_rules),\n        \"output\": [(3, 0)],  # sempre centrado\n    }\n\n    # plot inputs\n    for idx, (x, y) in enumerate(layers[\"inputs\"], start=1):\n        ax.scatter(x, y, c=\"skyblue\", s=100, edgecolors=\"k\")\n        ax.text(x - 0.2, y, f\"x{idx}\", ha=\"right\", va=\"center\")\n\n    # plot membership functions\n    for idx, (x, y) in enumerate(layers[\"mfs\"], start=1):\n        ax.scatter(x, y, c=\"lightgreen\", s=100, edgecolors=\"k\")\n        ax.text(x, y + 0.2, f\"MF{idx}\", ha=\"center\")\n\n    # plot rules\n    for idx, (x, y) in enumerate(layers[\"rules\"], start=1):\n        ax.scatter(x, y, c=\"orange\", s=100, edgecolors=\"k\")\n        ax.text(x, y + 0.2, f\"R{idx}\", ha=\"center\")\n\n    # plot output\n    x, y = layers[\"output\"][0]\n    ax.scatter(x, y, c=\"red\", s=120, edgecolors=\"k\")\n    ax.text(x + 0.2, y, \"\u0177\", va=\"center\")\n\n    # conex\u00f5es inputs -&gt; MFs\n    for i, (xi, yi) in enumerate(layers[\"inputs\"]):\n        for j in range(mfs_per_input):\n            xm, ym = layers[\"mfs\"][i * mfs_per_input + j]\n            ax.plot([xi, xm], [yi, ym], \"k-\", lw=0.8)\n\n    # conex\u00f5es MFs -&gt; Regras (simplifica\u00e7\u00e3o: conecta todas)\n    for (xm, ym) in layers[\"mfs\"]:\n        for (xr, yr) in layers[\"rules\"]:\n            ax.plot([xm, xr], [ym, yr], \"k-\", lw=0.5, alpha=0.5)\n\n    # conex\u00f5es Regras -&gt; Sa\u00edda\n    xo, yo = layers[\"output\"][0]\n    for (xr, yr) in layers[\"rules\"]:\n        ax.plot([xr, xo], [yr, yo], \"k-\", lw=1)\n\n    ax.axis(\"off\")\n    plt.show()\n\n\nplot_anfis_structure(n_inputs=3, mfs_per_input=2, n_rules=4)\n</pre> import matplotlib.pyplot as plt   def plot_anfis_structure(n_inputs=2, mfs_per_input=2, n_rules=4):     fig, ax = plt.subplots(figsize=(8, 5))      # fun\u00e7\u00e3o auxiliar: cria coordenadas centralizadas     def centered_positions(x, n):         offset = (n - 1) / 2         return [(x, i - offset) for i in range(n)]      # posi\u00e7\u00f5es dos n\u00f3s     layers = {         \"inputs\": centered_positions(0, n_inputs),         \"mfs\": centered_positions(1, n_inputs * mfs_per_input),         \"rules\": centered_positions(2, n_rules),         \"output\": [(3, 0)],  # sempre centrado     }      # plot inputs     for idx, (x, y) in enumerate(layers[\"inputs\"], start=1):         ax.scatter(x, y, c=\"skyblue\", s=100, edgecolors=\"k\")         ax.text(x - 0.2, y, f\"x{idx}\", ha=\"right\", va=\"center\")      # plot membership functions     for idx, (x, y) in enumerate(layers[\"mfs\"], start=1):         ax.scatter(x, y, c=\"lightgreen\", s=100, edgecolors=\"k\")         ax.text(x, y + 0.2, f\"MF{idx}\", ha=\"center\")      # plot rules     for idx, (x, y) in enumerate(layers[\"rules\"], start=1):         ax.scatter(x, y, c=\"orange\", s=100, edgecolors=\"k\")         ax.text(x, y + 0.2, f\"R{idx}\", ha=\"center\")      # plot output     x, y = layers[\"output\"][0]     ax.scatter(x, y, c=\"red\", s=120, edgecolors=\"k\")     ax.text(x + 0.2, y, \"\u0177\", va=\"center\")      # conex\u00f5es inputs -&gt; MFs     for i, (xi, yi) in enumerate(layers[\"inputs\"]):         for j in range(mfs_per_input):             xm, ym = layers[\"mfs\"][i * mfs_per_input + j]             ax.plot([xi, xm], [yi, ym], \"k-\", lw=0.8)      # conex\u00f5es MFs -&gt; Regras (simplifica\u00e7\u00e3o: conecta todas)     for (xm, ym) in layers[\"mfs\"]:         for (xr, yr) in layers[\"rules\"]:             ax.plot([xm, xr], [ym, yr], \"k-\", lw=0.5, alpha=0.5)      # conex\u00f5es Regras -&gt; Sa\u00edda     xo, yo = layers[\"output\"][0]     for (xr, yr) in layers[\"rules\"]:         ax.plot([xr, xo], [yr, yo], \"k-\", lw=1)      ax.axis(\"off\")     plt.show()   plot_anfis_structure(n_inputs=3, mfs_per_input=2, n_rules=4) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"hybrid_vs_backprop/","title":"ANFIS: Algoritmo H\u00edbrido vs Backpropagation","text":"<p>Este documento compara os dois m\u00e9todos de otimiza\u00e7\u00e3o dispon\u00edveis no ANFIS Toolbox: o algoritmo h\u00edbrido original de Jang (1993) e o backpropagation puro usado em implementa\u00e7\u00f5es modernas.</p>"},{"location":"hybrid_vs_backprop/#contexto-historico","title":"\ud83d\udcda Contexto Hist\u00f3rico","text":""},{"location":"hybrid_vs_backprop/#algoritmo-original-jang-1993","title":"Algoritmo Original (Jang, 1993)","text":"<p>O ANFIS foi originalmente proposto com um algoritmo h\u00edbrido de aprendizado que combina: - M\u00e9todo dos M\u00ednimos Quadrados (LSM) para par\u00e2metros consequentes - Backpropagation para par\u00e2metros das fun\u00e7\u00f5es de pertin\u00eancia</p>"},{"location":"hybrid_vs_backprop/#implementacoes-modernas","title":"Implementa\u00e7\u00f5es Modernas","text":"<p>Muitas implementa\u00e7\u00f5es modernas simplificam o algoritmo usando apenas backpropagation para todos os par\u00e2metros, por ser mais simples de implementar.</p>"},{"location":"hybrid_vs_backprop/#diferencas-tecnicas","title":"\ud83d\udd0d Diferen\u00e7as T\u00e9cnicas","text":""},{"location":"hybrid_vs_backprop/#algoritmo-hibrido-original-fit_hybrid","title":"Algoritmo H\u00edbrido Original (<code>fit_hybrid()</code>)","text":"<pre><code># Em cada epoch:\n# 1. FORWARD PASS - Otimiza\u00e7\u00e3o anal\u00edtica (LSM) dos par\u00e2metros consequentes\nA = construir_matriz_design(x, pesos_normalizados)\ntheta = (A^T A + reg)^(-1) A^T y  # Solu\u00e7\u00e3o anal\u00edtica \u00f3tima\n\n# 2. BACKWARD PASS - Backpropagation para fun\u00e7\u00f5es de pertin\u00eancia\ngradientes = calcular_gradientes_backprop(x, y, theta_fixo)\natualizar_parametros_pertinencia(gradientes, learning_rate)\n</code></pre> <p>Caracter\u00edsticas: - \u2705 Otimiza\u00e7\u00e3o anal\u00edtica dos par\u00e2metros consequentes (\u00f3timo global) - \u2705 Converg\u00eancia mais r\u00e1pida (menos epochs necess\u00e1rios) - \u2705 Melhor precis\u00e3o na maioria dos casos - \u26a0\ufe0f Custo computacional maior por epoch (invers\u00e3o de matriz) - \u26a0\ufe0f Poss\u00edveis problemas num\u00e9ricos com matrizes mal-condicionadas</p>"},{"location":"hybrid_vs_backprop/#backpropagation-puro-fit","title":"Backpropagation Puro (<code>fit()</code>)","text":"<pre><code># Em cada epoch:\n# 1. FORWARD PASS - Calcular sa\u00edda com par\u00e2metros atuais\ny_pred = forward(x)\n\n# 2. BACKWARD PASS - Gradientes para todos os par\u00e2metros\ngradientes = calcular_todos_gradientes(x, y, y_pred)\natualizar_todos_parametros(gradientes, learning_rate)\n</code></pre> <p>Caracter\u00edsticas: - \u2705 Implementa\u00e7\u00e3o simples e uniforme - \u2705 Est\u00e1vel numericamente - \u2705 Menor custo computacional por epoch - \u26a0\ufe0f Converg\u00eancia mais lenta (mais epochs necess\u00e1rios) - \u26a0\ufe0f Pode ficar preso em m\u00ednimos locais</p>"},{"location":"hybrid_vs_backprop/#resultados-experimentais","title":"\ud83d\udcca Resultados Experimentais","text":""},{"location":"hybrid_vs_backprop/#exemplo-aproximacao-de-funcao-2d","title":"Exemplo: Aproxima\u00e7\u00e3o de Fun\u00e7\u00e3o 2D","text":"<pre><code>Fun\u00e7\u00e3o: f(x1, x2) = sin(x1) * cos(x2) + 0.5 * x1 * x2\nDados: 100 amostras de treinamento, 400 de teste\nConfigura\u00e7\u00e3o: 3\u00d73 fun\u00e7\u00f5es de pertin\u00eancia, 50 epochs\n</code></pre> M\u00e9trica Algoritmo H\u00edbrido Backpropagation Vantagem Loss Final 0.000070 0.306319 H\u00edbrido 4375x melhor RMSE Teste 0.020445 0.639563 H\u00edbrido 31x melhor Tempo/Epoch 16.6ms 13.6ms Backprop 18% mais r\u00e1pido Converg\u00eancia Epoch 1 Epoch 50+ H\u00edbrido 50x mais r\u00e1pido"},{"location":"hybrid_vs_backprop/#quando-usar-cada-metodo","title":"\ud83c\udfaf Quando Usar Cada M\u00e9todo?","text":""},{"location":"hybrid_vs_backprop/#use-algoritmo-hibrido-fit_hybrid-quando","title":"Use Algoritmo H\u00edbrido (<code>fit_hybrid()</code>) quando:","text":"<ul> <li>\u2705 Precis\u00e3o \u00e9 cr\u00edtica</li> <li>\u2705 Dados de boa qualidade (n\u00e3o muito ru\u00eddo)</li> <li>\u2705 Problema bem-definido com fun\u00e7\u00e3o objetivo clara</li> <li>\u2705 Poucos epochs dispon\u00edveis</li> <li>\u2705 Aproxima\u00e7\u00e3o de fun\u00e7\u00f5es matem\u00e1ticas</li> </ul>"},{"location":"hybrid_vs_backprop/#use-backpropagation-fit-quando","title":"Use Backpropagation (<code>fit()</code>) quando:","text":"<ul> <li>\u2705 Implementa\u00e7\u00e3o deve ser simples</li> <li>\u2705 Dados ruidosos ou mal-condicionados</li> <li>\u2705 Muitos epochs dispon\u00edveis</li> <li>\u2705 Problemas de classifica\u00e7\u00e3o</li> <li>\u2705 Modelos muito grandes (custo de LSM proibitivo)</li> </ul>"},{"location":"hybrid_vs_backprop/#como-usar","title":"\ud83d\udcbb Como Usar","text":""},{"location":"hybrid_vs_backprop/#algoritmo-hibrido-recomendado","title":"Algoritmo H\u00edbrido (Recomendado)","text":"<pre><code>from anfis_toolbox import ANFIS, GaussianMF\n\n# Criar modelo\ninput_mfs = {\n    'x1': [GaussianMF(-1, 0.8), GaussianMF(0, 0.8), GaussianMF(1, 0.8)],\n    'x2': [GaussianMF(-1, 0.8), GaussianMF(0, 0.8), GaussianMF(1, 0.8)]\n}\nmodel = ANFIS(input_mfs)\n\n# Treinar com algoritmo h\u00edbrido original\nlosses = model.fit_hybrid(x_train, y_train, epochs=50, learning_rate=0.01)\n</code></pre>"},{"location":"hybrid_vs_backprop/#backpropagation-puro","title":"Backpropagation Puro","text":"<pre><code># Mesmo setup...\n# Treinar com backpropagation puro\nlosses = model.fit(x_train, y_train, epochs=50, learning_rate=0.01)\n</code></pre>"},{"location":"hybrid_vs_backprop/#comparacao-automatica","title":"Compara\u00e7\u00e3o Autom\u00e1tica","text":"<pre><code>from examples.usage_examples import example_hybrid_vs_backprop\n\n# Executa compara\u00e7\u00e3o completa nos seus dados\nexample_hybrid_vs_backprop()\n</code></pre>"},{"location":"hybrid_vs_backprop/#detalhes-da-implementacao","title":"\u2699\ufe0f Detalhes da Implementa\u00e7\u00e3o","text":""},{"location":"hybrid_vs_backprop/#metodo-dos-minimos-quadrados-lsm","title":"M\u00e9todo dos M\u00ednimos Quadrados (LSM)","text":"<p>O algoritmo h\u00edbrido constr\u00f3i a matriz de design A onde cada linha representa uma amostra e cada coluna um par\u00e2metro consequente:</p> <pre><code>A[i, j*(n_inputs+1) : (j+1)*(n_inputs+1)] = w_j[i] * [x1[i], x2[i], ..., xn[i], 1]\n</code></pre> <p>Onde <code>w_j[i]</code> \u00e9 o peso normalizado da regra j para a amostra i.</p> <p>A solu\u00e7\u00e3o \u00f3tima \u00e9: <code>\u03b8 = (A^T A + \u03bbI)^(-1) A^T y</code></p>"},{"location":"hybrid_vs_backprop/#regularizacao","title":"Regulariza\u00e7\u00e3o","text":"<p>Para estabilidade num\u00e9rica, adicionamos uma pequena regulariza\u00e7\u00e3o (\u03bb=1e-6) na diagonal de A^T A.</p>"},{"location":"hybrid_vs_backprop/#tratamento-de-singularidades","title":"Tratamento de Singularidades","text":"<p>Se a matriz for singular, fazemos fallback para pseudo-inversa: <code>\u03b8 = pinv(A) y</code></p>"},{"location":"hybrid_vs_backprop/#conclusao","title":"\ud83c\udfc6 Conclus\u00e3o","text":"<p>O algoritmo h\u00edbrido original de Jang (1993) demonstra superioridade clara em: - Precis\u00e3o: At\u00e9 4000x menor erro - Velocidade de converg\u00eancia: Converge em 1-5 epochs vs 50+ - Estabilidade: Menos sens\u00edvel a hiperpar\u00e2metros</p> <p>O ANFIS Toolbox oferece ambas as implementa\u00e7\u00f5es, permitindo escolher a mais adequada para cada aplica\u00e7\u00e3o. Para a maioria dos casos, recomendamos o algoritmo h\u00edbrido original (<code>fit_hybrid()</code>) devido \u00e0 sua efici\u00eancia e precis\u00e3o superiores.</p>"},{"location":"hybrid_vs_backprop/#referencias","title":"\ud83d\udcd6 Refer\u00eancias","text":"<ol> <li>Jang, J.S.R. (1993). \"ANFIS: adaptive-network-based fuzzy inference system\". IEEE Transactions on Systems, Man, and Cybernetics, 23(3), 665-685.</li> <li>Takagi, T. &amp; Sugeno, M. (1985). \"Fuzzy identification of systems and its applications to modeling and control\". IEEE Transactions on Systems, Man, and Cybernetics, 15(1), 116-132.</li> </ol>"},{"location":"api/builders/","title":"Builders","text":""},{"location":"api/builders/#anfis_toolbox.QuickANFIS","title":"anfis_toolbox.QuickANFIS","text":"<p>Quick setup class for common ANFIS use cases.</p>"},{"location":"api/builders/#anfis_toolbox.QuickANFIS.for_classification","title":"for_classification  <code>staticmethod</code>","text":"<pre><code>for_classification(\n    X: ndarray,\n    n_classes: int,\n    n_mfs: int = 3,\n    mf_type: str = \"gaussian\",\n    init: str = \"grid\",\n    random_state: int | None = None,\n) -&gt; ANFISClassifier\n</code></pre> <p>Create ANFISClassifier configured from data.</p> <p>Mirrors for_regression but returns a classifier with n_classes.</p>"},{"location":"api/builders/#anfis_toolbox.QuickANFIS.for_function_approximation","title":"for_function_approximation  <code>staticmethod</code>","text":"<pre><code>for_function_approximation(\n    input_ranges: list[tuple[float, float]], n_mfs: int = 5\n) -&gt; ANFIS\n</code></pre> <p>Create ANFIS model for function approximation.</p> <p>Parameters:</p> Name Type Description Default <code>input_ranges</code> <code>list[tuple[float, float]]</code> <p>List of (min, max) tuples for each input dimension</p> required <code>n_mfs</code> <code>int</code> <p>Number of membership functions per input</p> <code>5</code> <p>Returns:</p> Type Description <code>ANFIS</code> <p>Configured ANFIS model</p>"},{"location":"api/builders/#anfis_toolbox.QuickANFIS.for_regression","title":"for_regression  <code>staticmethod</code>","text":"<pre><code>for_regression(\n    X: ndarray,\n    n_mfs: int = 3,\n    mf_type: str = \"gaussian\",\n    init: str = \"grid\",\n    random_state: int | None = None,\n) -&gt; ANFIS\n</code></pre> <p>Create ANFIS model automatically configured for regression data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Input training data (n_samples, n_features)</p> required <code>n_mfs</code> <code>int</code> <p>Number of membership functions per input</p> <code>3</code> <code>mf_type</code> <code>str</code> <p>Type of membership functions</p> <code>'gaussian'</code> <code>init</code> <code>str</code> <p>Initialization strategy per input: 'grid' (default) or 'fcm'.</p> <code>'grid'</code> <code>random_state</code> <code>int | None</code> <p>Optional seed for deterministic FCM.</p> <code>None</code> <p>Returns:</p> Type Description <code>ANFIS</code> <p>Configured ANFIS model</p>"},{"location":"api/builders/#anfis_toolbox.ANFISBuilder","title":"anfis_toolbox.ANFISBuilder","text":"<pre><code>ANFISBuilder()\n</code></pre> <p>Builder class for creating ANFIS models with intuitive API.</p>"},{"location":"api/builders/#anfis_toolbox.ANFISBuilder.add_input","title":"add_input","text":"<pre><code>add_input(\n    name: str,\n    range_min: float,\n    range_max: float,\n    n_mfs: int = 3,\n    mf_type: str = \"gaussian\",\n    overlap: float = 0.5,\n) -&gt; ANFISBuilder\n</code></pre> <p>Add an input variable with automatic membership function generation.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the input variable</p> required <code>range_min</code> <code>float</code> <p>Minimum value of the input range</p> required <code>range_max</code> <code>float</code> <p>Maximum value of the input range</p> required <code>n_mfs</code> <code>int</code> <p>Number of membership functions (default: 3)</p> <code>3</code> <code>mf_type</code> <code>str</code> <p>Type of membership functions. Supported: 'gaussian', 'gaussian2', 'triangular', 'trapezoidal', 'bell', 'sigmoidal', 'sshape', 'zshape', 'pi'</p> <code>'gaussian'</code> <code>overlap</code> <code>float</code> <p>Overlap factor between adjacent MFs (0.0 to 1.0)</p> <code>0.5</code> <p>Returns:</p> Type Description <code>ANFISBuilder</code> <p>Self for method chaining</p>"},{"location":"api/builders/#anfis_toolbox.ANFISBuilder.add_input_from_data","title":"add_input_from_data","text":"<pre><code>add_input_from_data(\n    name: str,\n    data: ndarray,\n    n_mfs: int = 3,\n    mf_type: str = \"gaussian\",\n    overlap: float = 0.5,\n    margin: float = 0.1,\n    init: str = \"grid\",\n    random_state: int | None = None,\n) -&gt; ANFISBuilder\n</code></pre> <p>Add an input inferring range_min/range_max from data with a margin.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Input name</p> required <code>data</code> <code>ndarray</code> <p>1D array-like samples for this input</p> required <code>n_mfs</code> <code>int</code> <p>Number of membership functions</p> <code>3</code> <code>mf_type</code> <code>str</code> <p>Membership function type (see add_input)</p> <code>'gaussian'</code> <code>overlap</code> <code>float</code> <p>Overlap factor between adjacent MFs</p> <code>0.5</code> <code>margin</code> <code>float</code> <p>Fraction of (max-min) to pad on each side</p> <code>0.1</code> <code>init</code> <code>str</code> <p>Initialization strategy: \"grid\" (default) or \"fcm\". When \"fcm\", clusters from the data determine MF centers and widths (supports 'gaussian' and 'bell').</p> <code>'grid'</code> <code>random_state</code> <code>int | None</code> <p>Optional seed for deterministic FCM initialization.</p> <code>None</code>"},{"location":"api/builders/#anfis_toolbox.ANFISBuilder.build","title":"build","text":"<pre><code>build() -&gt; ANFIS\n</code></pre> <p>Build the ANFIS model with configured parameters.</p>"},{"location":"api/core/","title":"Core Classes","text":""},{"location":"api/core/#anfis_toolbox.ANFIS","title":"anfis_toolbox.ANFIS","text":"<pre><code>ANFIS(input_mfs: dict[str, list[MembershipFunction]])\n</code></pre> <p>Adaptive Neuro-Fuzzy Inference System (ANFIS) model.</p> <p>Implements the classic 4-layer ANFIS architecture:</p> <p>1) MembershipLayer \u2014 fuzzification of inputs 2) RuleLayer \u2014 rule strength computation (T-norm) 3) NormalizationLayer \u2014 weight normalization 4) ConsequentLayer \u2014 final output via a TSK model</p> <p>Supports forward/backward passes for training, parameter access/update, and a simple prediction API.</p> <p>Attributes:</p> Name Type Description <code>input_mfs</code> <code>dict[str, list[MembershipFunction]]</code> <p>Mapping from input name to its list of membership functions.</p> <code>membership_layer</code> <code>MembershipLayer</code> <p>Layer 1 \u2014 fuzzification.</p> <code>rule_layer</code> <code>RuleLayer</code> <p>Layer 2 \u2014 rule strength computation.</p> <code>normalization_layer</code> <code>NormalizationLayer</code> <p>Layer 3 \u2014 weight normalization.</p> <code>consequent_layer</code> <code>ConsequentLayer</code> <p>Layer 4 \u2014 final TSK output.</p> <code>input_names</code> <code>list[str]</code> <p>Ordered list of input variable names.</p> <code>n_inputs</code> <code>int</code> <p>Number of input variables (features).</p> <code>n_rules</code> <code>int</code> <p>Number of fuzzy rules (Cartesian product of MFs per input).</p> <p>Parameters:</p> Name Type Description Default <code>input_mfs</code> <code>dict[str, list[MembershipFunction]]</code> <p>Mapping from input name to a list of membership functions. Example: <code>{\"x1\": [GaussianMF(0,1), ...], \"x2\": [...]}</code>.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from anfis_toolbox.membership import GaussianMF\n&gt;&gt;&gt; input_mfs = {\n...     'x1': [GaussianMF(0, 1), GaussianMF(1, 1)],\n...     'x2': [GaussianMF(0, 1), GaussianMF(1, 1)]\n... }\n&gt;&gt;&gt; model = ANFIS(input_mfs)\n</code></pre> Source code in <code>anfis_toolbox/model.py</code> <pre><code>def __init__(self, input_mfs: dict[str, list[MembershipFunction]]):\n    \"\"\"Initialize the ANFIS model.\n\n    Args:\n        input_mfs (dict[str, list[MembershipFunction]]): Mapping from input\n            name to a list of membership functions. Example:\n            ``{\"x1\": [GaussianMF(0,1), ...], \"x2\": [...]}``.\n\n    Examples:\n        &gt;&gt;&gt; from anfis_toolbox.membership import GaussianMF\n        &gt;&gt;&gt; input_mfs = {\n        ...     'x1': [GaussianMF(0, 1), GaussianMF(1, 1)],\n        ...     'x2': [GaussianMF(0, 1), GaussianMF(1, 1)]\n        ... }\n        &gt;&gt;&gt; model = ANFIS(input_mfs)\n    \"\"\"\n    self.input_mfs = input_mfs\n    self.input_names = list(input_mfs.keys())\n    self.n_inputs = len(input_mfs)\n\n    # Calculate number of membership functions per input\n    mf_per_input = [len(mfs) for mfs in input_mfs.values()]\n\n    # Calculate total number of rules (Cartesian product)\n    self.n_rules = np.prod(mf_per_input)\n\n    # Initialize all layers\n    self.membership_layer = MembershipLayer(input_mfs)\n    self.rule_layer = RuleLayer(self.input_names, mf_per_input)\n    self.normalization_layer = NormalizationLayer()\n    self.consequent_layer = ConsequentLayer(self.n_rules, self.n_inputs)\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.membership_functions","title":"membership_functions  <code>property</code>","text":"<pre><code>membership_functions: dict[str, list[MembershipFunction]]\n</code></pre> <p>Return the membership functions grouped by input.</p> <p>Returns:</p> Type Description <code>dict[str, list[MembershipFunction]]</code> <p>dict[str, list[MembershipFunction]]: Mapping from input name to</p> <code>dict[str, list[MembershipFunction]]</code> <p>its list of membership functions.</p>"},{"location":"api/core/#anfis_toolbox.ANFIS.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Returns detailed representation of the ANFIS model.</p> Source code in <code>anfis_toolbox/model.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Returns detailed representation of the ANFIS model.\"\"\"\n    return f\"ANFIS(n_inputs={self.n_inputs}, n_rules={self.n_rules})\"\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Returns string representation of the ANFIS model.</p> Source code in <code>anfis_toolbox/model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Returns string representation of the ANFIS model.\"\"\"\n    return (\n        f\"ANFIS Model:\\n\"\n        f\"  - Inputs: {self.n_inputs} ({', '.join(self.input_names)})\\n\"\n        f\"  - Rules: {self.n_rules}\\n\"\n        f\"  - Membership Functions: {[len(mfs) for mfs in self.input_mfs.values()]}\\n\"\n        f\"  - Parameters: \\\n                {sum(len(mfs) * 2 for mfs in self.input_mfs.values()) + self.n_rules * (self.n_inputs + 1)}\"\n    )\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Run a backward pass through all layers.</p> <p>Propagates gradients from the output back through all layers and stores parameter gradients for a later update step.</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss w.r.t. the model output, shape <code>(batch_size, 1)</code>.</p> required Source code in <code>anfis_toolbox/model.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Run a backward pass through all layers.\n\n    Propagates gradients from the output back through all layers and stores\n    parameter gradients for a later update step.\n\n    Args:\n        dL_dy (np.ndarray): Gradient of the loss w.r.t. the model output,\n            shape ``(batch_size, 1)``.\n    \"\"\"\n    # Backward pass through Layer 4: Consequent layer\n    dL_dnorm_w, _ = self.consequent_layer.backward(dL_dy)\n\n    # Backward pass through Layer 3: Normalization layer\n    dL_dw = self.normalization_layer.backward(dL_dnorm_w)\n\n    # Backward pass through Layer 2: Rule layer\n    gradients = self.rule_layer.backward(dL_dw)\n\n    # Backward pass through Layer 1: Membership layer\n    self.membership_layer.backward(gradients)\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.fit","title":"fit","text":"<pre><code>fit(\n    x: ndarray,\n    y: ndarray,\n    epochs: int = 100,\n    learning_rate: float = 0.01,\n    verbose: bool = True,\n    trainer: None | object = None,\n) -&gt; list[float]\n</code></pre> <p>Train the ANFIS model.</p> <p>If a trainer is provided (see <code>anfis_toolbox.optim</code>), delegate training to it while preserving a scikit-learn-style <code>fit(X, y)</code> entry point. If no trainer is provided, a default <code>HybridTrainer</code> is used with the given hyperparameters.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Training inputs of shape <code>(n_samples, n_inputs)</code>.</p> required <code>y</code> <code>ndarray</code> <p>Training targets of shape <code>(n_samples, 1)</code> for regression.</p> required <code>epochs</code> <code>int</code> <p>Number of epochs. Defaults to <code>100</code>.</p> <code>100</code> <code>learning_rate</code> <code>float</code> <p>Learning rate. Defaults to <code>0.01</code>.</p> <code>0.01</code> <code>verbose</code> <code>bool</code> <p>Whether to log progress. Defaults to <code>True</code>.</p> <code>True</code> <code>trainer</code> <code>object | None</code> <p>External trainer implementing <code>fit(model, X, y)</code>. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: Per-epoch loss values.</p> Source code in <code>anfis_toolbox/model.py</code> <pre><code>def fit(\n    self,\n    x: np.ndarray,\n    y: np.ndarray,\n    epochs: int = 100,\n    learning_rate: float = 0.01,\n    verbose: bool = True,\n    trainer: None | object = None,\n) -&gt; list[float]:\n    \"\"\"Train the ANFIS model.\n\n    If a trainer is provided (see ``anfis_toolbox.optim``), delegate training\n    to it while preserving a scikit-learn-style ``fit(X, y)`` entry point. If\n    no trainer is provided, a default ``HybridTrainer`` is used with the given\n    hyperparameters.\n\n    Args:\n        x (np.ndarray): Training inputs of shape ``(n_samples, n_inputs)``.\n        y (np.ndarray): Training targets of shape ``(n_samples, 1)`` for\n            regression.\n        epochs (int, optional): Number of epochs. Defaults to ``100``.\n        learning_rate (float, optional): Learning rate. Defaults to ``0.01``.\n        verbose (bool, optional): Whether to log progress. Defaults to ``True``.\n        trainer (object | None, optional): External trainer implementing\n            ``fit(model, X, y)``. Defaults to ``None``.\n\n    Returns:\n        list[float]: Per-epoch loss values.\n    \"\"\"\n    if trainer is None:\n        # Lazy import to avoid unnecessary dependency at module import time\n        from .optim import HybridTrainer\n\n        trainer = HybridTrainer(learning_rate=learning_rate, epochs=epochs, verbose=verbose)\n\n    # Delegate training to the provided or default trainer\n    return trainer.fit(self, x, y)\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Run a forward pass through the model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array of shape <code>(batch_size, n_inputs)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Output array of shape <code>(batch_size, 1)</code>.</p> Source code in <code>anfis_toolbox/model.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Run a forward pass through the model.\n\n    Args:\n        x (np.ndarray): Input array of shape ``(batch_size, n_inputs)``.\n\n    Returns:\n        np.ndarray: Output array of shape ``(batch_size, 1)``.\n    \"\"\"\n    # Layer 1: Fuzzification - convert crisp inputs to membership degrees\n    membership_outputs = self.membership_layer.forward(x)\n\n    # Layer 2: Rule strength computation using T-norm (product)\n    rule_strengths = self.rule_layer.forward(membership_outputs)\n\n    # Layer 3: Normalization - ensure rule weights sum to 1.0\n    normalized_weights = self.normalization_layer.forward(rule_strengths)\n\n    # Layer 4: Consequent computation and final output\n    output = self.consequent_layer.forward(x, normalized_weights)\n\n    return output\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.get_gradients","title":"get_gradients","text":"<pre><code>get_gradients() -&gt; dict[str, np.ndarray]\n</code></pre> <p>Return the latest computed gradients.</p> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>dict[str, np.ndarray | dict]: Dictionary with two entries:</p> <code>dict[str, ndarray]</code> <ul> <li><code>\"membership\"</code>: dict mapping input name to a list of MF gradient dicts (one per membership function).</li> </ul> <code>dict[str, ndarray]</code> <ul> <li><code>\"consequent\"</code>: numpy array with consequent gradients.</li> </ul> Source code in <code>anfis_toolbox/model.py</code> <pre><code>def get_gradients(self) -&gt; dict[str, np.ndarray]:\n    \"\"\"Return the latest computed gradients.\n\n    Returns:\n            dict[str, np.ndarray | dict]: Dictionary with two entries:\n\n            - ``\"membership\"``: dict mapping input name to a list of MF\n                gradient dicts (one per membership function).\n            - ``\"consequent\"``: numpy array with consequent gradients.\n    \"\"\"\n    gradients = {\"membership\": {}, \"consequent\": self.consequent_layer.gradients.copy()}\n\n    # Extract membership function gradients\n    for name in self.input_names:\n        gradients[\"membership\"][name] = []\n        for mf in self.input_mfs[name]:\n            mf_grads = mf.gradients.copy()\n            gradients[\"membership\"][name].append(mf_grads)\n\n    return gradients\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.get_parameters","title":"get_parameters","text":"<pre><code>get_parameters() -&gt; dict[str, np.ndarray]\n</code></pre> <p>Return a snapshot of all trainable parameters.</p> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>dict[str, np.ndarray | dict]: Dictionary with two entries:</p> <ul> <li><code>\"membership\"</code>: dict mapping input name to a list of MF     parameter dicts (one per membership function).</li> <li><code>\"consequent\"</code>: numpy array with consequent parameters.</li> </ul> Source code in <code>anfis_toolbox/model.py</code> <pre><code>def get_parameters(self) -&gt; dict[str, np.ndarray]:\n    \"\"\"Return a snapshot of all trainable parameters.\n\n    Returns:\n            dict[str, np.ndarray | dict]:\n                    Dictionary with two entries:\n\n                    - ``\"membership\"``: dict mapping input name to a list of MF\n                        parameter dicts (one per membership function).\n                    - ``\"consequent\"``: numpy array with consequent parameters.\n    \"\"\"\n    parameters = {\"membership\": {}, \"consequent\": self.consequent_layer.parameters.copy()}\n\n    # Extract membership function parameters\n    for name in self.input_names:\n        parameters[\"membership\"][name] = []\n        for mf in self.input_mfs[name]:\n            mf_params = mf.parameters.copy()\n            parameters[\"membership\"][name].append(mf_params)\n\n    return parameters\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.predict","title":"predict","text":"<pre><code>predict(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict using the current model parameters.</p> <p>Accepts Python lists, 1D or 2D arrays and coerces to the expected shape.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray | list[float]</code> <p>Input data. If 1D, must have exactly <code>n_inputs</code> elements; if 2D, must be <code>(batch_size, n_inputs)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Predictions of shape <code>(batch_size, 1)</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input dimensionality or feature count does not match the model configuration.</p> Source code in <code>anfis_toolbox/model.py</code> <pre><code>def predict(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Predict using the current model parameters.\n\n    Accepts Python lists, 1D or 2D arrays and coerces to the expected shape.\n\n    Args:\n        x (np.ndarray | list[float]): Input data. If 1D, must have\n            exactly ``n_inputs`` elements; if 2D, must be\n            ``(batch_size, n_inputs)``.\n\n    Returns:\n        np.ndarray: Predictions of shape ``(batch_size, 1)``.\n\n    Raises:\n        ValueError: If input dimensionality or feature count does not match\n            the model configuration.\n    \"\"\"\n    # Accept Python lists or 1D arrays by coercing to correct 2D shape\n    x_arr = np.asarray(x, dtype=float)\n    if x_arr.ndim == 1:\n        # Single sample; ensure feature count matches\n        if x_arr.size != self.n_inputs:\n            raise ValueError(f\"Expected {self.n_inputs} features, got {x_arr.size} in 1D input\")\n        x_arr = x_arr.reshape(1, self.n_inputs)\n    elif x_arr.ndim == 2:\n        # Validate feature count\n        if x_arr.shape[1] != self.n_inputs:\n            raise ValueError(f\"Expected input with {self.n_inputs} features, got {x_arr.shape[1]}\")\n    else:\n        raise ValueError(\"Expected input with shape (batch_size, n_inputs)\")\n\n    return self.forward(x_arr)\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.reset_gradients","title":"reset_gradients","text":"<pre><code>reset_gradients()\n</code></pre> <p>Reset all accumulated gradients to zero.</p> <p>Call this before each optimization step to avoid mixing gradients across iterations.</p> Source code in <code>anfis_toolbox/model.py</code> <pre><code>def reset_gradients(self):\n    \"\"\"Reset all accumulated gradients to zero.\n\n    Call this before each optimization step to avoid mixing gradients\n    across iterations.\n    \"\"\"\n    # Reset membership function gradients\n    self.membership_layer.reset()\n\n    # Reset consequent layer gradients\n    self.consequent_layer.reset()\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.set_parameters","title":"set_parameters","text":"<pre><code>set_parameters(parameters: dict[str, ndarray])\n</code></pre> <p>Load parameters into the model.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <code>dict[str, ndarray | dict]</code> <p>Dictionary with the same structure as returned by :meth:<code>get_parameters</code>.</p> required Source code in <code>anfis_toolbox/model.py</code> <pre><code>def set_parameters(self, parameters: dict[str, np.ndarray]):\n    \"\"\"Load parameters into the model.\n\n    Args:\n        parameters (dict[str, np.ndarray | dict]): Dictionary with the same\n            structure as returned by :meth:`get_parameters`.\n    \"\"\"\n    # Set consequent layer parameters\n    if \"consequent\" in parameters:\n        self.consequent_layer.parameters = parameters[\"consequent\"].copy()\n\n    # Set membership function parameters\n    if \"membership\" in parameters:\n        membership_params = parameters[\"membership\"]\n        for name in self.input_names:\n            mf_params_list = membership_params.get(name)\n            if not mf_params_list:\n                continue\n            # Only update up to the available MFs for this input\n            for mf, mf_params in zip(self.input_mfs[name], mf_params_list, strict=False):\n                mf.parameters = mf_params.copy()\n</code></pre>"},{"location":"api/core/#anfis_toolbox.ANFIS.update_parameters","title":"update_parameters","text":"<pre><code>update_parameters(learning_rate: float)\n</code></pre> <p>Apply a single gradient descent update step.</p> <p>Parameters:</p> Name Type Description Default <code>learning_rate</code> <code>float</code> <p>Step size used to update parameters.</p> required Source code in <code>anfis_toolbox/model.py</code> <pre><code>def update_parameters(self, learning_rate: float):\n    \"\"\"Apply a single gradient descent update step.\n\n    Args:\n        learning_rate (float): Step size used to update parameters.\n    \"\"\"\n    # Update consequent layer parameters\n    self.consequent_layer.parameters -= learning_rate * self.consequent_layer.gradients\n\n    # Update membership function parameters\n    for name in self.input_names:\n        for mf in self.input_mfs[name]:\n            for param_name, gradient in mf.gradients.items():\n                mf.parameters[param_name] -= learning_rate * gradient\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.GaussianMF","title":"anfis_toolbox.membership.GaussianMF","text":"<pre><code>GaussianMF(mean: float = 0.0, sigma: float = 1.0)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Gaussian Membership Function.</p> <p>Implements a Gaussian (bell-shaped) membership function using the formula: \u03bc(x) = exp(-((x - mean)\u00b2 / (2 * sigma\u00b2)))</p> <p>This function is commonly used in fuzzy logic systems due to its smooth and differentiable properties.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>Mean of the Gaussian (center). Defaults to 0.0.</p> <code>0.0</code> <code>sigma</code> <code>float</code> <p>Standard deviation (width). Defaults to 1.0.</p> <code>1.0</code> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, mean: float = 0.0, sigma: float = 1.0):\n    \"\"\"Initialize with mean and standard deviation.\n\n    Args:\n        mean: Mean of the Gaussian (center). Defaults to 0.0.\n        sigma: Standard deviation (width). Defaults to 1.0.\n    \"\"\"\n    super().__init__()\n    self.parameters = {\"mean\": mean, \"sigma\": sigma}\n    # Initialize gradients to zero for all parameters\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.GaussianMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute gradients w.r.t. parameters given upstream gradient.</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss with respect to the output of this layer.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute gradients w.r.t. parameters given upstream gradient.\n\n    Args:\n        dL_dy: Gradient of the loss with respect to the output of this layer.\n\n    Returns:\n        None\n    \"\"\"\n    mean = self.parameters[\"mean\"]\n    sigma = self.parameters[\"sigma\"]\n\n    x = self.last_input\n    y = self.last_output\n\n    z = (x - mean) / sigma\n\n    # Derivatives of the Gaussian function\n    dy_dmean = -y * z / sigma\n    dy_dsigma = y * (z**2) / sigma\n\n    # Gradient with respect to mean\n    dL_dmean = np.sum(dL_dy * dy_dmean)\n\n    # Gradient with respect to sigma\n    dL_dsigma = np.sum(dL_dy * dy_dsigma)\n\n    # Update gradients\n    self.gradients[\"mean\"] += dL_dmean\n    self.gradients[\"sigma\"] += dL_dsigma\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.GaussianMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute Gaussian membership values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array for which the membership values are computed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of Gaussian membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute Gaussian membership values.\n\n    Args:\n        x: Input array for which the membership values are computed.\n\n    Returns:\n        np.ndarray: Array of Gaussian membership values.\n    \"\"\"\n    mean = self.parameters[\"mean\"]\n    sigma = self.parameters[\"sigma\"]\n    self.last_input = x\n    self.last_output = np.exp(-((x - mean) ** 2) / (2 * sigma**2))\n    return self.last_output\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.TriangularMF","title":"anfis_toolbox.membership.TriangularMF","text":"<pre><code>TriangularMF(a: float, b: float, c: float)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Triangular Membership Function.</p> <p>Implements a triangular membership function using piecewise linear segments: \u03bc(x) = { 0,           x \u2264 a or x \u2265 c        { (x-a)/(b-a), a &lt; x &lt; b        { (c-x)/(c-b), b \u2264 x &lt; c</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left base point of the triangle.</p> required <code>b</code> <code>float</code> <p>Peak point of the triangle (\u03bc(b) = 1).</p> required <code>c</code> <code>float</code> <p>Right base point of the triangle.</p> required Note <p>Must satisfy: a \u2264 b \u2264 c</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left base point (must satisfy a \u2264 b).</p> required <code>b</code> <code>float</code> <p>Peak point (must satisfy a \u2264 b \u2264 c).</p> required <code>c</code> <code>float</code> <p>Right base point (must satisfy b \u2264 c).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If parameters do not satisfy a \u2264 b \u2264 c or if a == c (zero width).</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float, b: float, c: float):\n    \"\"\"Initialize the triangular membership function.\n\n    Args:\n        a: Left base point (must satisfy a \u2264 b).\n        b: Peak point (must satisfy a \u2264 b \u2264 c).\n        c: Right base point (must satisfy b \u2264 c).\n\n    Raises:\n        ValueError: If parameters do not satisfy a \u2264 b \u2264 c or if a == c (zero width).\n    \"\"\"\n    super().__init__()\n\n    if not (a &lt;= b &lt;= c):\n        raise ValueError(f\"Triangular MF parameters must satisfy a \u2264 b \u2264 c, got a={a}, b={b}, c={c}\")\n    if a == c:\n        raise ValueError(\"Parameters 'a' and 'c' cannot be equal (zero width triangle)\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b), \"c\": float(c)}\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.TriangularMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Accumulate gradients for a, b, c given upstream gradient.</p> <p>Computes analytical derivatives for the rising (a, b) and falling (b, c) regions and sums them over the batch.</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss w.r.t. \u03bc(x); same shape or broadcastable to output.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Accumulate gradients for a, b, c given upstream gradient.\n\n    Computes analytical derivatives for the rising (a, b) and falling (b, c)\n    regions and sums them over the batch.\n\n    Args:\n        dL_dy: Gradient of the loss w.r.t. \u03bc(x); same shape or broadcastable to output.\n\n    Returns:\n        None\n    \"\"\"\n    if self.last_input is None or self.last_output is None:\n        return\n\n    a, b, c = self.parameters[\"a\"], self.parameters[\"b\"], self.parameters[\"c\"]\n    x = self.last_input\n\n    dL_da = 0.0\n    dL_db = 0.0\n    dL_dc = 0.0\n\n    # Left slope: a &lt; x &lt; b\n    if b &gt; a:\n        left_mask = (x &gt; a) &amp; (x &lt; b)\n        if np.any(left_mask):\n            x_left = x[left_mask]\n            dL_dy_left = dL_dy[left_mask]\n\n            # \u2202\u03bc/\u2202a = (x - b) / (b - a)^2\n            dmu_da_left = (x_left - b) / ((b - a) ** 2)\n            dL_da += np.sum(dL_dy_left * dmu_da_left)\n\n            # \u2202\u03bc/\u2202b = -(x - a) / (b - a)^2\n            dmu_db_left = -(x_left - a) / ((b - a) ** 2)\n            dL_db += np.sum(dL_dy_left * dmu_db_left)\n\n    # Right slope: b &lt; x &lt; c\n    if c &gt; b:\n        right_mask = (x &gt; b) &amp; (x &lt; c)\n        if np.any(right_mask):\n            x_right = x[right_mask]\n            dL_dy_right = dL_dy[right_mask]\n\n            # \u2202\u03bc/\u2202b = (x - c) / (c - b)^2\n            dmu_db_right = (x_right - c) / ((c - b) ** 2)\n            dL_db += np.sum(dL_dy_right * dmu_db_right)\n\n            # \u2202\u03bc/\u2202c = (x - b) / (c - b)^2\n            dmu_dc_right = (x_right - b) / ((c - b) ** 2)\n            dL_dc += np.sum(dL_dy_right * dmu_dc_right)\n\n    # Update gradients\n    self.gradients[\"a\"] += dL_da\n    self.gradients[\"b\"] += dL_db\n    self.gradients[\"c\"] += dL_dc\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.TriangularMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute triangular membership values \u03bc(x).</p> <p>Uses piecewise linear segments defined by (a, b, c): - 0 outside [a, c] - rising slope in (a, b) - peak 1 at x == b - falling slope in (b, c)</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Membership values in [0, 1] with the same shape as x.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute triangular membership values \u03bc(x).\n\n    Uses piecewise linear segments defined by (a, b, c):\n    - 0 outside [a, c]\n    - rising slope in (a, b)\n    - peak 1 at x == b\n    - falling slope in (b, c)\n\n    Args:\n        x: Input array.\n\n    Returns:\n        np.ndarray: Membership values in [0, 1] with the same shape as x.\n    \"\"\"\n    a, b, c = self.parameters[\"a\"], self.parameters[\"b\"], self.parameters[\"c\"]\n    self.last_input = x\n\n    output = np.zeros_like(x, dtype=float)\n\n    # Left slope\n    if b &gt; a:\n        left_mask = (x &gt; a) &amp; (x &lt; b)\n        output[left_mask] = (x[left_mask] - a) / (b - a)\n\n    # Peak\n    peak_mask = x == b\n    output[peak_mask] = 1.0\n\n    # Right slope\n    if c &gt; b:\n        right_mask = (x &gt; b) &amp; (x &lt; c)\n        output[right_mask] = (c - x[right_mask]) / (c - b)\n\n    # Clip for numerical stability\n    output = np.clip(output, 0.0, 1.0)\n\n    self.last_output = output\n    return output\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.TrapezoidalMF","title":"anfis_toolbox.membership.TrapezoidalMF","text":"<pre><code>TrapezoidalMF(a: float, b: float, c: float, d: float)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Trapezoidal Membership Function.</p> <p>Implements a trapezoidal membership function using piecewise linear segments: \u03bc(x) = { 0,           x \u2264 a or x \u2265 d        { (x-a)/(b-a), a &lt; x &lt; b        { 1,           b \u2264 x \u2264 c        { (d-x)/(d-c), c &lt; x &lt; d</p> <p>This function is commonly used in fuzzy logic systems when you need a plateau region of full membership, providing robustness to noise and uncertainty.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left base point of the trapezoid (lower support bound).</p> required <code>b</code> <code>float</code> <p>Left peak point (start of plateau where \u03bc(x) = 1).</p> required <code>c</code> <code>float</code> <p>Right peak point (end of plateau where \u03bc(x) = 1).</p> required <code>d</code> <code>float</code> <p>Right base point of the trapezoid (upper support bound).</p> required Note <p>Parameters must satisfy: a \u2264 b \u2264 c \u2264 d for a valid trapezoidal function.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left base point (\u03bc(a) = 0).</p> required <code>b</code> <code>float</code> <p>Left peak point (\u03bc(b) = 1, start of plateau).</p> required <code>c</code> <code>float</code> <p>Right peak point (\u03bc\u00a9 = 1, end of plateau).</p> required <code>d</code> <code>float</code> <p>Right base point (\u03bc(d) = 0).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If parameters don't satisfy a \u2264 b \u2264 c \u2264 d.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float, b: float, c: float, d: float):\n    \"\"\"Initialize the trapezoidal membership function.\n\n    Args:\n        a: Left base point (\u03bc(a) = 0).\n        b: Left peak point (\u03bc(b) = 1, start of plateau).\n        c: Right peak point (\u03bc(c) = 1, end of plateau).\n        d: Right base point (\u03bc(d) = 0).\n\n    Raises:\n        ValueError: If parameters don't satisfy a \u2264 b \u2264 c \u2264 d.\n    \"\"\"\n    super().__init__()\n\n    # Validate parameters\n    if not (a &lt;= b &lt;= c &lt;= d):\n        raise ValueError(f\"Trapezoidal MF parameters must satisfy a \u2264 b \u2264 c \u2264 d, got a={a}, b={b}, c={c}, d={d}\")\n\n    if a == d:\n        raise ValueError(\"Parameters 'a' and 'd' cannot be equal (zero width trapezoid)\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b), \"c\": float(c), \"d\": float(d)}\n    # Initialize gradients to zero for all parameters\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.TrapezoidalMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute gradients for parameters based on upstream loss gradient.</p> <p>Analytical gradients for the piecewise linear function: - \u2202\u03bc/\u2202a: left slope - \u2202\u03bc/\u2202b: left slope and plateau transition - \u2202\u03bc/\u2202c: right slope and plateau transition - \u2202\u03bc/\u2202d: right slope</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss w.r.t. the output of this layer.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute gradients for parameters based on upstream loss gradient.\n\n    Analytical gradients for the piecewise linear function:\n    - \u2202\u03bc/\u2202a: left slope\n    - \u2202\u03bc/\u2202b: left slope and plateau transition\n    - \u2202\u03bc/\u2202c: right slope and plateau transition\n    - \u2202\u03bc/\u2202d: right slope\n\n    Args:\n        dL_dy: Gradient of the loss w.r.t. the output of this layer.\n\n    Returns:\n        None\n    \"\"\"\n    if self.last_input is None or self.last_output is None:\n        return\n\n    a = self.parameters[\"a\"]\n    b = self.parameters[\"b\"]\n    c = self.parameters[\"c\"]\n    d = self.parameters[\"d\"]\n\n    x = self.last_input\n\n    # Initialize gradients\n    dL_da = 0.0\n    dL_db = 0.0\n    dL_dc = 0.0\n    dL_dd = 0.0\n\n    # Left slope region: a &lt; x &lt; b, \u03bc(x) = (x-a)/(b-a)\n    if b &gt; a:\n        left_mask = (x &gt; a) &amp; (x &lt; b)\n        if np.any(left_mask):\n            x_left = x[left_mask]\n            dL_dy_left = dL_dy[left_mask]\n\n            # \u2202\u03bc/\u2202a = -1/(b-a) for left slope\n            dmu_da_left = -1.0 / (b - a)\n            dL_da += np.sum(dL_dy_left * dmu_da_left)\n\n            # \u2202\u03bc/\u2202b = -(x-a)/(b-a)\u00b2 for left slope\n            dmu_db_left = -(x_left - a) / ((b - a) ** 2)\n            dL_db += np.sum(dL_dy_left * dmu_db_left)\n\n    # Plateau region: b \u2264 x \u2264 c, \u03bc(x) = 1\n    # No gradients for plateau region (constant function)\n\n    # Right slope region: c &lt; x &lt; d, \u03bc(x) = (d-x)/(d-c)\n    if d &gt; c:\n        right_mask = (x &gt; c) &amp; (x &lt; d)\n        if np.any(right_mask):\n            x_right = x[right_mask]\n            dL_dy_right = dL_dy[right_mask]\n\n            # \u2202\u03bc/\u2202c = (x-d)/(d-c)\u00b2 for right slope\n            dmu_dc_right = (x_right - d) / ((d - c) ** 2)\n            dL_dc += np.sum(dL_dy_right * dmu_dc_right)\n\n            # \u2202\u03bc/\u2202d = (x-c)/(d-c)\u00b2 for right slope (derivative of (d-x)/(d-c) w.r.t. d)\n            dmu_dd_right = (x_right - c) / ((d - c) ** 2)\n            dL_dd += np.sum(dL_dy_right * dmu_dd_right)\n\n    # Update gradients (accumulate for batch processing)\n    self.gradients[\"a\"] += dL_da\n    self.gradients[\"b\"] += dL_db\n    self.gradients[\"c\"] += dL_dc\n    self.gradients[\"d\"] += dL_dd\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.TrapezoidalMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute trapezoidal membership values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array containing the trapezoidal membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute trapezoidal membership values.\n\n    Args:\n        x: Input array.\n\n    Returns:\n        np.ndarray: Array containing the trapezoidal membership values.\n    \"\"\"\n    a = self.parameters[\"a\"]\n    b = self.parameters[\"b\"]\n    c = self.parameters[\"c\"]\n    d = self.parameters[\"d\"]\n\n    self.last_input = x\n\n    # Initialize output with zeros\n    output = np.zeros_like(x)\n\n    # Left slope: (x - a) / (b - a) for a &lt; x &lt; b\n    if b &gt; a:  # Avoid division by zero\n        left_mask = (x &gt; a) &amp; (x &lt; b)\n        output[left_mask] = (x[left_mask] - a) / (b - a)\n\n    # Plateau: \u03bc(x) = 1 for b \u2264 x \u2264 c\n    plateau_mask = (x &gt;= b) &amp; (x &lt;= c)\n    output[plateau_mask] = 1.0\n\n    # Right slope: (d - x) / (d - c) for c &lt; x &lt; d\n    if d &gt; c:  # Avoid division by zero\n        right_mask = (x &gt; c) &amp; (x &lt; d)\n        output[right_mask] = (d - x[right_mask]) / (d - c)\n\n    # Values outside [a, d] are already zero\n\n    self.last_output = output\n    return output\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.BellMF","title":"anfis_toolbox.membership.BellMF","text":"<pre><code>BellMF(a: float = 1.0, b: float = 2.0, c: float = 0.0)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Bell-shaped (Generalized Bell) Membership Function.</p> <p>Implements a bell-shaped membership function using the formula: \u03bc(x) = 1 / (1 + |((x - c) / a)|^(2b))</p> <p>This function is a generalization of the Gaussian function and provides more flexibility in controlling the shape through the 'b' parameter. It's particularly useful when you need asymmetric membership functions or want to fine-tune the slope characteristics.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Width parameter (positive). Controls the width of the curve.</p> <code>1.0</code> <code>b</code> <code>float</code> <p>Slope parameter (positive). Controls the steepness of the curve.</p> <code>2.0</code> <code>c</code> <code>float</code> <p>Center parameter. Controls the center position of the curve.</p> <code>0.0</code> Note <p>Parameters 'a' and 'b' must be positive for a valid bell function.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Width parameter (must be positive). Defaults to 1.0.</p> <code>1.0</code> <code>b</code> <code>float</code> <p>Slope parameter (must be positive). Defaults to 2.0.</p> <code>2.0</code> <code>c</code> <code>float</code> <p>Center parameter. Defaults to 0.0.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If 'a' or 'b' are not positive.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float = 1.0, b: float = 2.0, c: float = 0.0):\n    \"\"\"Initialize with width, slope, and center parameters.\n\n    Args:\n        a: Width parameter (must be positive). Defaults to 1.0.\n        b: Slope parameter (must be positive). Defaults to 2.0.\n        c: Center parameter. Defaults to 0.0.\n\n    Raises:\n        ValueError: If 'a' or 'b' are not positive.\n    \"\"\"\n    super().__init__()\n\n    # Validate parameters\n    if a &lt;= 0:\n        raise ValueError(f\"Parameter 'a' must be positive, got a={a}\")\n\n    if b &lt;= 0:\n        raise ValueError(f\"Parameter 'b' must be positive, got b={b}\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b), \"c\": float(c)}\n    # Initialize gradients to zero for all parameters\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.BellMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute parameter gradients given upstream gradient.</p> <p>Analytical gradients: - \u2202\u03bc/\u2202a: width - \u2202\u03bc/\u2202b: steepness - \u2202\u03bc/\u2202c: center</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss w.r.t. the output of this layer.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute parameter gradients given upstream gradient.\n\n    Analytical gradients:\n    - \u2202\u03bc/\u2202a: width\n    - \u2202\u03bc/\u2202b: steepness\n    - \u2202\u03bc/\u2202c: center\n\n    Args:\n        dL_dy: Gradient of the loss w.r.t. the output of this layer.\n\n    Returns:\n        None\n    \"\"\"\n    a = self.parameters[\"a\"]\n    b = self.parameters[\"b\"]\n    c = self.parameters[\"c\"]\n\n    x = self.last_input\n    y = self.last_output  # This is \u03bc(x)\n\n    # Intermediate calculations\n    normalized = (x - c) / a\n    abs_normalized = np.abs(normalized)\n\n    # Avoid division by zero and numerical issues\n    # Only compute gradients where abs_normalized &gt; epsilon\n    epsilon = 1e-12\n    valid_mask = abs_normalized &gt; epsilon\n\n    if not np.any(valid_mask):\n        # If all values are at the peak (x \u2248 c), gradients are zero\n        return\n\n    # Initialize gradients\n    dL_da = 0.0\n    dL_db = 0.0\n    dL_dc = 0.0\n\n    # Only compute where we have valid values\n    x_valid = x[valid_mask]\n    y_valid = y[valid_mask]\n    dL_dy_valid = dL_dy[valid_mask]\n    normalized_valid = (x_valid - c) / a\n    abs_normalized_valid = np.abs(normalized_valid)\n\n    # Power term: |normalized|^(2b)\n    power_term_valid = np.power(abs_normalized_valid, 2 * b)\n\n    # For the bell function \u03bc = 1/(1 + z) where z = |normalized|^(2b)\n    # \u2202\u03bc/\u2202z = -1/(1 + z)\u00b2 = -\u03bc\u00b2\n    dmu_dz = -y_valid * y_valid\n\n    # Chain rule: \u2202L/\u2202param = \u2202L/\u2202\u03bc \u00d7 \u2202\u03bc/\u2202z \u00d7 \u2202z/\u2202param\n\n    # \u2202z/\u2202a = \u2202(|normalized|^(2b))/\u2202a\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 \u2202|normalized|/\u2202a\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 \u2202normalized/\u2202a\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 (-(x-c)/a\u00b2)\n    # = -2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 (x-c)/a\u00b2\n\n    sign_normalized = np.sign(normalized_valid)\n    dz_da = -2 * b * np.power(abs_normalized_valid, 2 * b - 1) * sign_normalized * (x_valid - c) / (a * a)\n    dL_da += np.sum(dL_dy_valid * dmu_dz * dz_da)\n\n    # \u2202z/\u2202b = \u2202(|normalized|^(2b))/\u2202b\n    # = |normalized|^(2b) \u00d7 ln(|normalized|) \u00d7 2\n    # But ln(|normalized|) can be problematic near zero, so we use a safe version\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        ln_abs_normalized = np.log(abs_normalized_valid)\n        ln_abs_normalized = np.where(np.isfinite(ln_abs_normalized), ln_abs_normalized, 0.0)\n\n    dz_db = 2 * power_term_valid * ln_abs_normalized\n    dL_db += np.sum(dL_dy_valid * dmu_dz * dz_db)\n\n    # \u2202z/\u2202c = \u2202(|normalized|^(2b))/\u2202c\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 \u2202normalized/\u2202c\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 (-1/a)\n    # = -2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) / a\n\n    dz_dc = -2 * b * np.power(abs_normalized_valid, 2 * b - 1) * sign_normalized / a\n    dL_dc += np.sum(dL_dy_valid * dmu_dz * dz_dc)\n\n    # Update gradients (accumulate for batch processing)\n    self.gradients[\"a\"] += dL_da\n    self.gradients[\"b\"] += dL_db\n    self.gradients[\"c\"] += dL_dc\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.BellMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute bell membership values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array for which the membership values are computed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of bell membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute bell membership values.\n\n    Args:\n        x: Input array for which the membership values are computed.\n\n    Returns:\n        np.ndarray: Array of bell membership values.\n    \"\"\"\n    a = self.parameters[\"a\"]\n    b = self.parameters[\"b\"]\n    c = self.parameters[\"c\"]\n\n    self.last_input = x\n\n    # Compute the bell function: \u03bc(x) = 1 / (1 + |((x - c) / a)|^(2b))\n    # To avoid numerical issues, we use the absolute value and handle edge cases\n\n    # Compute (x - c) / a\n    normalized = (x - c) / a\n\n    # Compute |normalized|^(2b)\n    # Use np.abs to handle negative values properly\n    abs_normalized = np.abs(normalized)\n\n    # Handle the case where abs_normalized is very close to zero\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        power_term = np.power(abs_normalized, 2 * b)\n        # Replace any inf or nan with a very large number to make output close to 0\n        power_term = np.where(np.isfinite(power_term), power_term, 1e10)\n\n    # Compute the final result\n    output = 1.0 / (1.0 + power_term)\n\n    self.last_output = output\n    return output\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.SigmoidalMF","title":"anfis_toolbox.membership.SigmoidalMF","text":"<pre><code>SigmoidalMF(a: float = 1.0, c: float = 0.0)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Sigmoidal Membership Function.</p> <p>Implements a sigmoidal (S-shaped) membership function using the formula: \u03bc(x) = 1 / (1 + exp(-a(x - c)))</p> <p>This function provides a smooth S-shaped curve that transitions from 0 to 1. It's particularly useful for modeling gradual transitions and is commonly used in neural networks and fuzzy systems.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Slope parameter. Controls the steepness of the sigmoid.        - Positive values: standard sigmoid (0 \u2192 1 as x increases)        - Negative values: inverted sigmoid (1 \u2192 0 as x increases)        - Larger |a|: steeper transition</p> <code>1.0</code> <code>c</code> <code>float</code> <p>Center parameter. Controls the inflection point where \u03bc\u00a9 = 0.5.</p> <code>0.0</code> Note <p>Parameter 'a' cannot be zero (would result in constant function).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Slope parameter (cannot be zero). Defaults to 1.0.</p> <code>1.0</code> <code>c</code> <code>float</code> <p>Center parameter (inflection point). Defaults to 0.0.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If 'a' is zero.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float = 1.0, c: float = 0.0):\n    \"\"\"Initialize the sigmoidal membership function.\n\n    Args:\n        a: Slope parameter (cannot be zero). Defaults to 1.0.\n        c: Center parameter (inflection point). Defaults to 0.0.\n\n    Raises:\n        ValueError: If 'a' is zero.\n    \"\"\"\n    super().__init__()\n\n    # Validate parameters\n    if a == 0:\n        raise ValueError(f\"Parameter 'a' cannot be zero, got a={a}\")\n\n    self.parameters = {\"a\": float(a), \"c\": float(c)}\n    # Initialize gradients to zero for all parameters\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.SigmoidalMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute parameter gradients given upstream gradient.</p> <p>For \u03bc(x) = 1/(1 + exp(-a(x-c))): - \u2202\u03bc/\u2202a = \u03bc(x)(1-\u03bc(x))(x-c) - \u2202\u03bc/\u2202c = -a\u03bc(x)(1-\u03bc(x))</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss w.r.t. the output of this layer.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute parameter gradients given upstream gradient.\n\n    For \u03bc(x) = 1/(1 + exp(-a(x-c))):\n    - \u2202\u03bc/\u2202a = \u03bc(x)(1-\u03bc(x))(x-c)\n    - \u2202\u03bc/\u2202c = -a\u03bc(x)(1-\u03bc(x))\n\n    Args:\n        dL_dy: Gradient of the loss w.r.t. the output of this layer.\n\n    Returns:\n        None\n    \"\"\"\n    a = self.parameters[\"a\"]\n    c = self.parameters[\"c\"]\n\n    x = self.last_input\n    y = self.last_output  # This is \u03bc(x)\n\n    # For sigmoid: \u2202\u03bc/\u2202z = \u03bc(1-\u03bc) where z = -a(x-c)\n    # This is a fundamental property of the sigmoid function\n    dmu_dz = y * (1.0 - y)\n\n    # Chain rule: \u2202L/\u2202param = \u2202L/\u2202\u03bc \u00d7 \u2202\u03bc/\u2202z \u00d7 \u2202z/\u2202param\n\n    # For z = a(x-c):\n    # \u2202z/\u2202a = (x-c)\n    # \u2202z/\u2202c = -a\n\n    # Gradient w.r.t. 'a'\n    dz_da = x - c\n    dL_da = np.sum(dL_dy * dmu_dz * dz_da)\n\n    # Gradient w.r.t. 'c'\n    dz_dc = -a\n    dL_dc = np.sum(dL_dy * dmu_dz * dz_dc)\n\n    # Update gradients (accumulate for batch processing)\n    self.gradients[\"a\"] += dL_da\n    self.gradients[\"c\"] += dL_dc\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.SigmoidalMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute sigmoidal membership values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array for which the membership values are computed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of sigmoidal membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute sigmoidal membership values.\n\n    Args:\n        x: Input array for which the membership values are computed.\n\n    Returns:\n        np.ndarray: Array of sigmoidal membership values.\n    \"\"\"\n    a = self.parameters[\"a\"]\n    c = self.parameters[\"c\"]\n\n    self.last_input = x\n\n    # Compute the sigmoid function: \u03bc(x) = 1 / (1 + exp(-a(x - c)))\n    # To avoid numerical overflow, we use a stable implementation\n\n    # Compute a(x - c) (note: not -a(x - c))\n    z = a * (x - c)\n\n    # Use stable sigmoid implementation to avoid overflow\n    # Standard sigmoid: \u03c3(z) = 1 / (1 + exp(-z))\n    # For numerical stability:\n    # If z &gt;= 0: \u03c3(z) = 1 / (1 + exp(-z))\n    # If z &lt; 0: \u03c3(z) = exp(z) / (1 + exp(z))\n\n    output = np.zeros_like(x, dtype=float)\n\n    # Case 1: z &gt;= 0 (standard case)\n    mask_pos = z &gt;= 0\n    if np.any(mask_pos):\n        output[mask_pos] = 1.0 / (1.0 + np.exp(-z[mask_pos]))\n\n    # Case 2: z &lt; 0 (to avoid exp overflow)\n    mask_neg = z &lt; 0\n    if np.any(mask_neg):\n        exp_z = np.exp(z[mask_neg])\n        output[mask_neg] = exp_z / (1.0 + exp_z)\n\n    self.last_output = output\n    return output\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.PiMF","title":"anfis_toolbox.membership.PiMF","text":"<pre><code>PiMF(a: float, b: float, c: float, d: float)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Pi-shaped membership function.</p> <p>The Pi-shaped membership function is characterized by a trapezoidal-like shape with smooth S-shaped transitions on both sides. It is defined by four parameters that control the shape and position:</p> <p>Mathematical definition: \u03bc(x) = S(x; a, b) for x \u2208 [a, b]      = 1 for x \u2208 [b, c]      = Z(x; c, d) for x \u2208 [c, d]      = 0 elsewhere</p> <p>Where: - S(x; a, b) is an S-shaped function from 0 to 1 - Z(x; c, d) is a Z-shaped function from 1 to 0</p> <p>The S and Z functions use smooth cubic splines for differentiability: S(x; a, b) = 2*((x-a)/(b-a))^3 for x \u2208 [a, (a+b)/2]            = 1 - 2*((b-x)/(b-a))^3 for x \u2208 [(a+b)/2, b]</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left foot of the function (where function starts rising from 0)</p> required <code>b</code> <code>float</code> <p>Left shoulder of the function (where function reaches 1)</p> required <code>c</code> <code>float</code> <p>Right shoulder of the function (where function starts falling from 1)</p> required <code>d</code> <code>float</code> <p>Right foot of the function (where function reaches 0)</p> required Note <p>Parameters must satisfy: a &lt; b \u2264 c &lt; d</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left foot parameter.</p> required <code>b</code> <code>float</code> <p>Left shoulder parameter.</p> required <code>c</code> <code>float</code> <p>Right shoulder parameter.</p> required <code>d</code> <code>float</code> <p>Right foot parameter.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If parameters don't satisfy a &lt; b \u2264 c &lt; d.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float, b: float, c: float, d: float):\n    \"\"\"Initialize the Pi-shaped membership function.\n\n    Args:\n        a: Left foot parameter.\n        b: Left shoulder parameter.\n        c: Right shoulder parameter.\n        d: Right foot parameter.\n\n    Raises:\n        ValueError: If parameters don't satisfy a &lt; b \u2264 c &lt; d.\n    \"\"\"\n    super().__init__()\n\n    # Parameter validation\n    if not (a &lt; b &lt;= c &lt; d):\n        raise ValueError(f\"Parameters must satisfy a &lt; b \u2264 c &lt; d, got a={a}, b={b}, c={c}, d={d}\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b), \"c\": float(c), \"d\": float(d)}\n    self.gradients = {\"a\": 0.0, \"b\": 0.0, \"c\": 0.0, \"d\": 0.0}\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.PiMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute gradients for backpropagation.</p> <p>Analytical gradients are computed by region: - S-function: gradients w.r.t. a, b - Z-function: gradients w.r.t. c, d - Flat region: no gradients</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of loss w.r.t. function output.</p> required Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute gradients for backpropagation.\n\n    Analytical gradients are computed by region:\n    - S-function: gradients w.r.t. a, b\n    - Z-function: gradients w.r.t. c, d\n    - Flat region: no gradients\n\n    Args:\n        dL_dy: Gradient of loss w.r.t. function output.\n    \"\"\"\n    if self.last_input is None or self.last_output is None:\n        return\n\n    x = self.last_input\n    dL_dy = np.asarray(dL_dy)\n\n    a, b, c, d = self.parameters[\"a\"], self.parameters[\"b\"], self.parameters[\"c\"], self.parameters[\"d\"]\n\n    # Initialize gradients\n    grad_a = grad_b = grad_c = grad_d = 0.0\n\n    # S-function gradients [a, b]\n    mask_s = (x &gt;= a) &amp; (x &lt;= b)\n    if np.any(mask_s) and b != a:\n        x_s = x[mask_s]\n        dL_dy_s = dL_dy[mask_s]\n        t = (x_s - a) / (b - a)\n\n        # Calculate parameter derivatives\n        dt_da = (x_s - b) / (b - a) ** 2  # Correct derivative\n        dt_db = -(x_s - a) / (b - a) ** 2\n\n        # For smoothstep S(t) = 3*t\u00b2 - 2*t\u00b3, derivative is dS/dt = 6*t - 6*t\u00b2 = 6*t*(1-t)\n        dS_dt = _dsmoothstep_dt(t)\n\n        # Apply chain rule: dS/da = dS/dt * dt/da\n        dS_da = dS_dt * dt_da\n        dS_db = dS_dt * dt_db\n\n        grad_a += np.sum(dL_dy_s * dS_da)\n        grad_b += np.sum(dL_dy_s * dS_db)\n\n    # Z-function gradients [c, d]\n    mask_z = (x &gt;= c) &amp; (x &lt;= d)\n    if np.any(mask_z) and d != c:\n        x_z = x[mask_z]\n        dL_dy_z = dL_dy[mask_z]\n        t = (x_z - c) / (d - c)\n\n        # Calculate parameter derivatives\n        dt_dc = (x_z - d) / (d - c) ** 2  # Correct derivative\n        dt_dd = -(x_z - c) / (d - c) ** 2\n\n        # For Z(t) = 1 - S(t) = 1 - (3*t\u00b2 - 2*t\u00b3), derivative is dZ/dt = -dS/dt = -6*t*(1-t) = 6*t*(t-1)\n        dZ_dt = -_dsmoothstep_dt(t)\n\n        # Apply chain rule: dZ/dc = dZ/dt * dt/dc\n        dZ_dc = dZ_dt * dt_dc\n        dZ_dd = dZ_dt * dt_dd\n\n        grad_c += np.sum(dL_dy_z * dZ_dc)\n        grad_d += np.sum(dL_dy_z * dZ_dd)\n\n    # Accumulate gradients\n    self.gradients[\"a\"] += grad_a\n    self.gradients[\"b\"] += grad_b\n    self.gradients[\"c\"] += grad_c\n    self.gradients[\"d\"] += grad_d\n</code></pre>"},{"location":"api/core/#anfis_toolbox.membership.PiMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute the Pi-shaped membership function.</p> <p>Combines S and Z functions for smooth transitions: - Rising edge: S-function from a to b - Flat top: constant 1 from b to c - Falling edge: Z-function from c to d - Outside: 0</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input values.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Membership values \u03bc(x) \u2208 [0, 1].</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute the Pi-shaped membership function.\n\n    Combines S and Z functions for smooth transitions:\n    - Rising edge: S-function from a to b\n    - Flat top: constant 1 from b to c\n    - Falling edge: Z-function from c to d\n    - Outside: 0\n\n    Args:\n        x: Input values.\n\n    Returns:\n        np.ndarray: Membership values \u03bc(x) \u2208 [0, 1].\n    \"\"\"\n    x = np.asarray(x)\n    self.last_input = x.copy()\n\n    a, b, c, d = self.parameters[\"a\"], self.parameters[\"b\"], self.parameters[\"c\"], self.parameters[\"d\"]\n\n    # Initialize output\n    y = np.zeros_like(x, dtype=np.float64)\n\n    # S-function for rising edge [a, b]\n    mask_s = (x &gt;= a) &amp; (x &lt;= b)\n    if np.any(mask_s):\n        x_s = x[mask_s]\n        # Avoid division by zero\n        if b != a:\n            t = (x_s - a) / (b - a)  # Normalize to [0, 1]\n\n            # Smooth S-function using smoothstep: S(t) = 3*t\u00b2 - 2*t\u00b3\n            # This is continuous and differentiable across the entire [0,1] interval\n            y_s = _smoothstep(t)\n\n            y[mask_s] = y_s\n        else:\n            # Degenerate case: instant transition\n            y[mask_s] = 1.0\n\n    # Flat region [b, c]: \u03bc(x) = 1\n    mask_flat = (x &gt;= b) &amp; (x &lt;= c)\n    y[mask_flat] = 1.0\n\n    # Z-function for falling edge [c, d]\n    mask_z = (x &gt;= c) &amp; (x &lt;= d)\n    if np.any(mask_z):\n        x_z = x[mask_z]\n        # Avoid division by zero\n        if d != c:\n            t = (x_z - c) / (d - c)  # Normalize to [0, 1]\n\n            # Smooth Z-function (inverted smoothstep): Z(t) = 1 - S(t) = 1 - (3*t\u00b2 - 2*t\u00b3)\n            # This is continuous and differentiable, going from 1 to 0\n            y_z = 1 - _smoothstep(t)\n\n            y[mask_z] = y_z\n        else:\n            # Degenerate case: instant transition\n            y[mask_z] = 0.0\n\n    self.last_output = y.copy()\n    return y\n</code></pre>"},{"location":"api/membership-functions/","title":"Membership Functions","text":"<p>Reference for all built-in membership function (MF) classes. These are used to define fuzzy sets on each input dimension.</p> <ul> <li>Smooth MFs (differentiable): GaussianMF, BellMF, SigmoidalMF, SShapedMF, ZShapedMF, PiMF</li> <li>Piecewise-linear MFs: TriangularMF, TrapezoidalMF</li> </ul> <p>Each class documents its parameters, forward behavior, and analytical gradients used during training.</p>"},{"location":"api/membership-functions/#gaussianmf","title":"GaussianMF","text":""},{"location":"api/membership-functions/#anfis_toolbox.membership.GaussianMF","title":"anfis_toolbox.membership.GaussianMF","text":"<pre><code>GaussianMF(mean: float = 0.0, sigma: float = 1.0)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Gaussian Membership Function.</p> <p>Implements a Gaussian (bell-shaped) membership function using the formula: \u03bc(x) = exp(-((x - mean)\u00b2 / (2 * sigma\u00b2)))</p> <p>This function is commonly used in fuzzy logic systems due to its smooth and differentiable properties.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>Mean of the Gaussian (center). Defaults to 0.0.</p> <code>0.0</code> <code>sigma</code> <code>float</code> <p>Standard deviation (width). Defaults to 1.0.</p> <code>1.0</code> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, mean: float = 0.0, sigma: float = 1.0):\n    \"\"\"Initialize with mean and standard deviation.\n\n    Args:\n        mean: Mean of the Gaussian (center). Defaults to 0.0.\n        sigma: Standard deviation (width). Defaults to 1.0.\n    \"\"\"\n    super().__init__()\n    self.parameters = {\"mean\": mean, \"sigma\": sigma}\n    # Initialize gradients to zero for all parameters\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.GaussianMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute gradients w.r.t. parameters given upstream gradient.</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss with respect to the output of this layer.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute gradients w.r.t. parameters given upstream gradient.\n\n    Args:\n        dL_dy: Gradient of the loss with respect to the output of this layer.\n\n    Returns:\n        None\n    \"\"\"\n    mean = self.parameters[\"mean\"]\n    sigma = self.parameters[\"sigma\"]\n\n    x = self.last_input\n    y = self.last_output\n\n    z = (x - mean) / sigma\n\n    # Derivatives of the Gaussian function\n    dy_dmean = -y * z / sigma\n    dy_dsigma = y * (z**2) / sigma\n\n    # Gradient with respect to mean\n    dL_dmean = np.sum(dL_dy * dy_dmean)\n\n    # Gradient with respect to sigma\n    dL_dsigma = np.sum(dL_dy * dy_dsigma)\n\n    # Update gradients\n    self.gradients[\"mean\"] += dL_dmean\n    self.gradients[\"sigma\"] += dL_dsigma\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.GaussianMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute Gaussian membership values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array for which the membership values are computed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of Gaussian membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute Gaussian membership values.\n\n    Args:\n        x: Input array for which the membership values are computed.\n\n    Returns:\n        np.ndarray: Array of Gaussian membership values.\n    \"\"\"\n    mean = self.parameters[\"mean\"]\n    sigma = self.parameters[\"sigma\"]\n    self.last_input = x\n    self.last_output = np.exp(-((x - mean) ** 2) / (2 * sigma**2))\n    return self.last_output\n</code></pre>"},{"location":"api/membership-functions/#bellmf","title":"BellMF","text":""},{"location":"api/membership-functions/#anfis_toolbox.membership.BellMF","title":"anfis_toolbox.membership.BellMF","text":"<pre><code>BellMF(a: float = 1.0, b: float = 2.0, c: float = 0.0)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Bell-shaped (Generalized Bell) Membership Function.</p> <p>Implements a bell-shaped membership function using the formula: \u03bc(x) = 1 / (1 + |((x - c) / a)|^(2b))</p> <p>This function is a generalization of the Gaussian function and provides more flexibility in controlling the shape through the 'b' parameter. It's particularly useful when you need asymmetric membership functions or want to fine-tune the slope characteristics.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Width parameter (positive). Controls the width of the curve.</p> <code>1.0</code> <code>b</code> <code>float</code> <p>Slope parameter (positive). Controls the steepness of the curve.</p> <code>2.0</code> <code>c</code> <code>float</code> <p>Center parameter. Controls the center position of the curve.</p> <code>0.0</code> Note <p>Parameters 'a' and 'b' must be positive for a valid bell function.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Width parameter (must be positive). Defaults to 1.0.</p> <code>1.0</code> <code>b</code> <code>float</code> <p>Slope parameter (must be positive). Defaults to 2.0.</p> <code>2.0</code> <code>c</code> <code>float</code> <p>Center parameter. Defaults to 0.0.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If 'a' or 'b' are not positive.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float = 1.0, b: float = 2.0, c: float = 0.0):\n    \"\"\"Initialize with width, slope, and center parameters.\n\n    Args:\n        a: Width parameter (must be positive). Defaults to 1.0.\n        b: Slope parameter (must be positive). Defaults to 2.0.\n        c: Center parameter. Defaults to 0.0.\n\n    Raises:\n        ValueError: If 'a' or 'b' are not positive.\n    \"\"\"\n    super().__init__()\n\n    # Validate parameters\n    if a &lt;= 0:\n        raise ValueError(f\"Parameter 'a' must be positive, got a={a}\")\n\n    if b &lt;= 0:\n        raise ValueError(f\"Parameter 'b' must be positive, got b={b}\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b), \"c\": float(c)}\n    # Initialize gradients to zero for all parameters\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.BellMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute parameter gradients given upstream gradient.</p> <p>Analytical gradients: - \u2202\u03bc/\u2202a: width - \u2202\u03bc/\u2202b: steepness - \u2202\u03bc/\u2202c: center</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss w.r.t. the output of this layer.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute parameter gradients given upstream gradient.\n\n    Analytical gradients:\n    - \u2202\u03bc/\u2202a: width\n    - \u2202\u03bc/\u2202b: steepness\n    - \u2202\u03bc/\u2202c: center\n\n    Args:\n        dL_dy: Gradient of the loss w.r.t. the output of this layer.\n\n    Returns:\n        None\n    \"\"\"\n    a = self.parameters[\"a\"]\n    b = self.parameters[\"b\"]\n    c = self.parameters[\"c\"]\n\n    x = self.last_input\n    y = self.last_output  # This is \u03bc(x)\n\n    # Intermediate calculations\n    normalized = (x - c) / a\n    abs_normalized = np.abs(normalized)\n\n    # Avoid division by zero and numerical issues\n    # Only compute gradients where abs_normalized &gt; epsilon\n    epsilon = 1e-12\n    valid_mask = abs_normalized &gt; epsilon\n\n    if not np.any(valid_mask):\n        # If all values are at the peak (x \u2248 c), gradients are zero\n        return\n\n    # Initialize gradients\n    dL_da = 0.0\n    dL_db = 0.0\n    dL_dc = 0.0\n\n    # Only compute where we have valid values\n    x_valid = x[valid_mask]\n    y_valid = y[valid_mask]\n    dL_dy_valid = dL_dy[valid_mask]\n    normalized_valid = (x_valid - c) / a\n    abs_normalized_valid = np.abs(normalized_valid)\n\n    # Power term: |normalized|^(2b)\n    power_term_valid = np.power(abs_normalized_valid, 2 * b)\n\n    # For the bell function \u03bc = 1/(1 + z) where z = |normalized|^(2b)\n    # \u2202\u03bc/\u2202z = -1/(1 + z)\u00b2 = -\u03bc\u00b2\n    dmu_dz = -y_valid * y_valid\n\n    # Chain rule: \u2202L/\u2202param = \u2202L/\u2202\u03bc \u00d7 \u2202\u03bc/\u2202z \u00d7 \u2202z/\u2202param\n\n    # \u2202z/\u2202a = \u2202(|normalized|^(2b))/\u2202a\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 \u2202|normalized|/\u2202a\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 \u2202normalized/\u2202a\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 (-(x-c)/a\u00b2)\n    # = -2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 (x-c)/a\u00b2\n\n    sign_normalized = np.sign(normalized_valid)\n    dz_da = -2 * b * np.power(abs_normalized_valid, 2 * b - 1) * sign_normalized * (x_valid - c) / (a * a)\n    dL_da += np.sum(dL_dy_valid * dmu_dz * dz_da)\n\n    # \u2202z/\u2202b = \u2202(|normalized|^(2b))/\u2202b\n    # = |normalized|^(2b) \u00d7 ln(|normalized|) \u00d7 2\n    # But ln(|normalized|) can be problematic near zero, so we use a safe version\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        ln_abs_normalized = np.log(abs_normalized_valid)\n        ln_abs_normalized = np.where(np.isfinite(ln_abs_normalized), ln_abs_normalized, 0.0)\n\n    dz_db = 2 * power_term_valid * ln_abs_normalized\n    dL_db += np.sum(dL_dy_valid * dmu_dz * dz_db)\n\n    # \u2202z/\u2202c = \u2202(|normalized|^(2b))/\u2202c\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 \u2202normalized/\u2202c\n    # = 2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) \u00d7 (-1/a)\n    # = -2b \u00d7 |normalized|^(2b-1) \u00d7 sign(normalized) / a\n\n    dz_dc = -2 * b * np.power(abs_normalized_valid, 2 * b - 1) * sign_normalized / a\n    dL_dc += np.sum(dL_dy_valid * dmu_dz * dz_dc)\n\n    # Update gradients (accumulate for batch processing)\n    self.gradients[\"a\"] += dL_da\n    self.gradients[\"b\"] += dL_db\n    self.gradients[\"c\"] += dL_dc\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.BellMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute bell membership values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array for which the membership values are computed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of bell membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute bell membership values.\n\n    Args:\n        x: Input array for which the membership values are computed.\n\n    Returns:\n        np.ndarray: Array of bell membership values.\n    \"\"\"\n    a = self.parameters[\"a\"]\n    b = self.parameters[\"b\"]\n    c = self.parameters[\"c\"]\n\n    self.last_input = x\n\n    # Compute the bell function: \u03bc(x) = 1 / (1 + |((x - c) / a)|^(2b))\n    # To avoid numerical issues, we use the absolute value and handle edge cases\n\n    # Compute (x - c) / a\n    normalized = (x - c) / a\n\n    # Compute |normalized|^(2b)\n    # Use np.abs to handle negative values properly\n    abs_normalized = np.abs(normalized)\n\n    # Handle the case where abs_normalized is very close to zero\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        power_term = np.power(abs_normalized, 2 * b)\n        # Replace any inf or nan with a very large number to make output close to 0\n        power_term = np.where(np.isfinite(power_term), power_term, 1e10)\n\n    # Compute the final result\n    output = 1.0 / (1.0 + power_term)\n\n    self.last_output = output\n    return output\n</code></pre>"},{"location":"api/membership-functions/#sigmoidalmf","title":"SigmoidalMF","text":""},{"location":"api/membership-functions/#anfis_toolbox.membership.SigmoidalMF","title":"anfis_toolbox.membership.SigmoidalMF","text":"<pre><code>SigmoidalMF(a: float = 1.0, c: float = 0.0)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Sigmoidal Membership Function.</p> <p>Implements a sigmoidal (S-shaped) membership function using the formula: \u03bc(x) = 1 / (1 + exp(-a(x - c)))</p> <p>This function provides a smooth S-shaped curve that transitions from 0 to 1. It's particularly useful for modeling gradual transitions and is commonly used in neural networks and fuzzy systems.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Slope parameter. Controls the steepness of the sigmoid.        - Positive values: standard sigmoid (0 \u2192 1 as x increases)        - Negative values: inverted sigmoid (1 \u2192 0 as x increases)        - Larger |a|: steeper transition</p> <code>1.0</code> <code>c</code> <code>float</code> <p>Center parameter. Controls the inflection point where \u03bc\u00a9 = 0.5.</p> <code>0.0</code> Note <p>Parameter 'a' cannot be zero (would result in constant function).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Slope parameter (cannot be zero). Defaults to 1.0.</p> <code>1.0</code> <code>c</code> <code>float</code> <p>Center parameter (inflection point). Defaults to 0.0.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If 'a' is zero.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float = 1.0, c: float = 0.0):\n    \"\"\"Initialize the sigmoidal membership function.\n\n    Args:\n        a: Slope parameter (cannot be zero). Defaults to 1.0.\n        c: Center parameter (inflection point). Defaults to 0.0.\n\n    Raises:\n        ValueError: If 'a' is zero.\n    \"\"\"\n    super().__init__()\n\n    # Validate parameters\n    if a == 0:\n        raise ValueError(f\"Parameter 'a' cannot be zero, got a={a}\")\n\n    self.parameters = {\"a\": float(a), \"c\": float(c)}\n    # Initialize gradients to zero for all parameters\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.SigmoidalMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute parameter gradients given upstream gradient.</p> <p>For \u03bc(x) = 1/(1 + exp(-a(x-c))): - \u2202\u03bc/\u2202a = \u03bc(x)(1-\u03bc(x))(x-c) - \u2202\u03bc/\u2202c = -a\u03bc(x)(1-\u03bc(x))</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss w.r.t. the output of this layer.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute parameter gradients given upstream gradient.\n\n    For \u03bc(x) = 1/(1 + exp(-a(x-c))):\n    - \u2202\u03bc/\u2202a = \u03bc(x)(1-\u03bc(x))(x-c)\n    - \u2202\u03bc/\u2202c = -a\u03bc(x)(1-\u03bc(x))\n\n    Args:\n        dL_dy: Gradient of the loss w.r.t. the output of this layer.\n\n    Returns:\n        None\n    \"\"\"\n    a = self.parameters[\"a\"]\n    c = self.parameters[\"c\"]\n\n    x = self.last_input\n    y = self.last_output  # This is \u03bc(x)\n\n    # For sigmoid: \u2202\u03bc/\u2202z = \u03bc(1-\u03bc) where z = -a(x-c)\n    # This is a fundamental property of the sigmoid function\n    dmu_dz = y * (1.0 - y)\n\n    # Chain rule: \u2202L/\u2202param = \u2202L/\u2202\u03bc \u00d7 \u2202\u03bc/\u2202z \u00d7 \u2202z/\u2202param\n\n    # For z = a(x-c):\n    # \u2202z/\u2202a = (x-c)\n    # \u2202z/\u2202c = -a\n\n    # Gradient w.r.t. 'a'\n    dz_da = x - c\n    dL_da = np.sum(dL_dy * dmu_dz * dz_da)\n\n    # Gradient w.r.t. 'c'\n    dz_dc = -a\n    dL_dc = np.sum(dL_dy * dmu_dz * dz_dc)\n\n    # Update gradients (accumulate for batch processing)\n    self.gradients[\"a\"] += dL_da\n    self.gradients[\"c\"] += dL_dc\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.SigmoidalMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute sigmoidal membership values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array for which the membership values are computed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of sigmoidal membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute sigmoidal membership values.\n\n    Args:\n        x: Input array for which the membership values are computed.\n\n    Returns:\n        np.ndarray: Array of sigmoidal membership values.\n    \"\"\"\n    a = self.parameters[\"a\"]\n    c = self.parameters[\"c\"]\n\n    self.last_input = x\n\n    # Compute the sigmoid function: \u03bc(x) = 1 / (1 + exp(-a(x - c)))\n    # To avoid numerical overflow, we use a stable implementation\n\n    # Compute a(x - c) (note: not -a(x - c))\n    z = a * (x - c)\n\n    # Use stable sigmoid implementation to avoid overflow\n    # Standard sigmoid: \u03c3(z) = 1 / (1 + exp(-z))\n    # For numerical stability:\n    # If z &gt;= 0: \u03c3(z) = 1 / (1 + exp(-z))\n    # If z &lt; 0: \u03c3(z) = exp(z) / (1 + exp(z))\n\n    output = np.zeros_like(x, dtype=float)\n\n    # Case 1: z &gt;= 0 (standard case)\n    mask_pos = z &gt;= 0\n    if np.any(mask_pos):\n        output[mask_pos] = 1.0 / (1.0 + np.exp(-z[mask_pos]))\n\n    # Case 2: z &lt; 0 (to avoid exp overflow)\n    mask_neg = z &lt; 0\n    if np.any(mask_neg):\n        exp_z = np.exp(z[mask_neg])\n        output[mask_neg] = exp_z / (1.0 + exp_z)\n\n    self.last_output = output\n    return output\n</code></pre>"},{"location":"api/membership-functions/#sshapedmf","title":"SShapedMF","text":""},{"location":"api/membership-functions/#anfis_toolbox.membership.SShapedMF","title":"anfis_toolbox.membership.SShapedMF","text":"<pre><code>SShapedMF(a: float, b: float)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>S-shaped Membership Function.</p> <p>Smoothly transitions from 0 to 1 between two parameters a and b using the smoothstep polynomial S(t) = 3t\u00b2 - 2t\u00b3. Commonly used in fuzzy logic for gradual onset of membership.</p> <p>Definition with a &lt; b: - \u03bc(x) = 0, for x \u2264 a - \u03bc(x) = 3t\u00b2 - 2t\u00b3, t = (x-a)/(b-a), for a &lt; x &lt; b - \u03bc(x) = 1, for x \u2265 b</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left foot (start of transition from 0).</p> required <code>b</code> <code>float</code> <p>Right shoulder (end of transition at 1).</p> required Note <p>Requires a &lt; b.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>The first parameter, must be less than 'b'.</p> required <code>b</code> <code>float</code> <p>The second parameter, must be greater than 'a'.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If 'a' is not less than 'b'.</p> <p>Attributes:</p> Name Type Description <code>parameters</code> <code>dict</code> <p>Dictionary containing 'a' and 'b' as floats.</p> <code>gradients</code> <code>dict</code> <p>Dictionary containing gradients for 'a' and 'b', initialized to 0.0.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float, b: float):\n    \"\"\"Initialize the membership function with parameters 'a' and 'b'.\n\n    Args:\n        a (float): The first parameter, must be less than 'b'.\n        b (float): The second parameter, must be greater than 'a'.\n\n    Raises:\n        ValueError: If 'a' is not less than 'b'.\n\n    Attributes:\n        parameters (dict): Dictionary containing 'a' and 'b' as floats.\n        gradients (dict): Dictionary containing gradients for 'a' and 'b', initialized to 0.0.\n    \"\"\"\n    super().__init__()\n\n    if not (a &lt; b):\n        raise ValueError(f\"Parameters must satisfy a &lt; b, got a={a}, b={b}\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b)}\n    self.gradients = {\"a\": 0.0, \"b\": 0.0}\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.SShapedMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Accumulate gradients for a and b using analytical derivatives.</p> <p>Uses S(t) = 3t\u00b2 - 2t\u00b3, t = (x-a)/(b-a) on the transition region.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Accumulate gradients for a and b using analytical derivatives.\n\n    Uses S(t) = 3t\u00b2 - 2t\u00b3, t = (x-a)/(b-a) on the transition region.\n    \"\"\"\n    if self.last_input is None or self.last_output is None:\n        return\n\n    x = self.last_input\n    dL_dy = np.asarray(dL_dy)\n\n    a, b = self.parameters[\"a\"], self.parameters[\"b\"]\n\n    # Only transition region contributes to parameter gradients\n    mask = (x &gt;= a) &amp; (x &lt;= b)\n    if not (np.any(mask) and b != a):\n        return\n\n    x_t = x[mask]\n    dL_dy_t = dL_dy[mask]\n    t = (x_t - a) / (b - a)\n\n    # dS/dt = 6*t*(1-t)\n    dS_dt = _dsmoothstep_dt(t)\n\n    # dt/da and dt/db\n    dt_da = (x_t - b) / (b - a) ** 2\n    dt_db = -(x_t - a) / (b - a) ** 2\n\n    dS_da = dS_dt * dt_da\n    dS_db = dS_dt * dt_db\n\n    self.gradients[\"a\"] += float(np.sum(dL_dy_t * dS_da))\n    self.gradients[\"b\"] += float(np.sum(dL_dy_t * dS_db))\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.SShapedMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute S-shaped membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute S-shaped membership values.\"\"\"\n    x = np.asarray(x)\n    self.last_input = x.copy()\n\n    a, b = self.parameters[\"a\"], self.parameters[\"b\"]\n\n    y = np.zeros_like(x, dtype=np.float64)\n\n    # Right side (x \u2265 b): \u03bc = 1\n    mask_right = x &gt;= b\n    y[mask_right] = 1.0\n\n    # Transition region (a &lt; x &lt; b): \u03bc = smoothstep(t)\n    mask_trans = (x &gt; a) &amp; (x &lt; b)\n    if np.any(mask_trans):\n        x_t = x[mask_trans]\n        t = (x_t - a) / (b - a)\n        y[mask_trans] = _smoothstep(t)\n\n    # Left side (x \u2264 a) remains 0\n\n    self.last_output = y.copy()\n    return y\n</code></pre>"},{"location":"api/membership-functions/#zshapedmf","title":"ZShapedMF","text":""},{"location":"api/membership-functions/#anfis_toolbox.membership.ZShapedMF","title":"anfis_toolbox.membership.ZShapedMF","text":"<pre><code>ZShapedMF(a: float, b: float)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Z-shaped Membership Function.</p> <p>Smoothly transitions from 1 to 0 between two parameters a and b using the smoothstep polynomial S(t) = 3t\u00b2 - 2t\u00b3 (Z = 1 - S). Commonly used in fuzzy logic as the complement of the S-shaped function.</p> <p>Definition with a &lt; b: - \u03bc(x) = 1, for x \u2264 a - \u03bc(x) = 1 - (3t\u00b2 - 2t\u00b3), t = (x-a)/(b-a), for a &lt; x &lt; b - \u03bc(x) = 0, for x \u2265 b</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left shoulder (start of transition).</p> required <code>b</code> <code>float</code> <p>Right foot (end of transition).</p> required Note <p>Requires a &lt; b. In the degenerate case a == b, the function becomes an instantaneous drop at x=a.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Lower bound parameter.</p> required <code>b</code> <code>float</code> <p>Upper bound parameter.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If a is not less than b.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float, b: float):\n    \"\"\"Initialize the membership function with parameters a and b.\n\n    Args:\n        a: Lower bound parameter.\n        b: Upper bound parameter.\n\n    Raises:\n        ValueError: If a is not less than b.\n    \"\"\"\n    super().__init__()\n\n    if not (a &lt; b):\n        raise ValueError(f\"Parameters must satisfy a &lt; b, got a={a}, b={b}\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b)}\n    self.gradients = {\"a\": 0.0, \"b\": 0.0}\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.ZShapedMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Accumulate gradients for a and b using analytical derivatives.</p> <p>Uses Z(t) = 1 - (3t\u00b2 - 2t\u00b3), t = (x-a)/(b-a) on the transition region.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Accumulate gradients for a and b using analytical derivatives.\n\n    Uses Z(t) = 1 - (3t\u00b2 - 2t\u00b3), t = (x-a)/(b-a) on the transition region.\n    \"\"\"\n    if self.last_input is None or self.last_output is None:\n        return\n\n    x = self.last_input\n    dL_dy = np.asarray(dL_dy)\n\n    a, b = self.parameters[\"a\"], self.parameters[\"b\"]\n\n    # Only transition region contributes to parameter gradients\n    mask = (x &gt;= a) &amp; (x &lt;= b)\n    if not (np.any(mask) and b != a):\n        return\n\n    x_t = x[mask]\n    dL_dy_t = dL_dy[mask]\n    t = (x_t - a) / (b - a)\n\n    # dZ/dt = -dS/dt = 6*t*(t-1)\n    dZ_dt = -_dsmoothstep_dt(t)\n\n    # dt/da and dt/db\n    dt_da = (x_t - b) / (b - a) ** 2\n    dt_db = -(x_t - a) / (b - a) ** 2\n\n    dZ_da = dZ_dt * dt_da\n    dZ_db = dZ_dt * dt_db\n\n    self.gradients[\"a\"] += float(np.sum(dL_dy_t * dZ_da))\n    self.gradients[\"b\"] += float(np.sum(dL_dy_t * dZ_db))\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.ZShapedMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute Z-shaped membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute Z-shaped membership values.\"\"\"\n    x = np.asarray(x)\n    self.last_input = x.copy()\n\n    a, b = self.parameters[\"a\"], self.parameters[\"b\"]\n\n    y = np.zeros_like(x, dtype=np.float64)\n\n    # Left side (x \u2264 a): \u03bc = 1\n    mask_left = x &lt;= a\n    y[mask_left] = 1.0\n\n    # Transition region (a &lt; x &lt; b): \u03bc = 1 - smoothstep(t)\n    mask_trans = (x &gt; a) &amp; (x &lt; b)\n    if np.any(mask_trans):\n        x_t = x[mask_trans]\n        t = (x_t - a) / (b - a)\n        y[mask_trans] = 1.0 - _smoothstep(t)\n\n    # Right side (x \u2265 b) remains 0\n\n    self.last_output = y.copy()\n    return y\n</code></pre>"},{"location":"api/membership-functions/#pimf","title":"PiMF","text":""},{"location":"api/membership-functions/#anfis_toolbox.membership.PiMF","title":"anfis_toolbox.membership.PiMF","text":"<pre><code>PiMF(a: float, b: float, c: float, d: float)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Pi-shaped membership function.</p> <p>The Pi-shaped membership function is characterized by a trapezoidal-like shape with smooth S-shaped transitions on both sides. It is defined by four parameters that control the shape and position:</p> <p>Mathematical definition: \u03bc(x) = S(x; a, b) for x \u2208 [a, b]      = 1 for x \u2208 [b, c]      = Z(x; c, d) for x \u2208 [c, d]      = 0 elsewhere</p> <p>Where: - S(x; a, b) is an S-shaped function from 0 to 1 - Z(x; c, d) is a Z-shaped function from 1 to 0</p> <p>The S and Z functions use smooth cubic splines for differentiability: S(x; a, b) = 2*((x-a)/(b-a))^3 for x \u2208 [a, (a+b)/2]            = 1 - 2*((b-x)/(b-a))^3 for x \u2208 [(a+b)/2, b]</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left foot of the function (where function starts rising from 0)</p> required <code>b</code> <code>float</code> <p>Left shoulder of the function (where function reaches 1)</p> required <code>c</code> <code>float</code> <p>Right shoulder of the function (where function starts falling from 1)</p> required <code>d</code> <code>float</code> <p>Right foot of the function (where function reaches 0)</p> required Note <p>Parameters must satisfy: a &lt; b \u2264 c &lt; d</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left foot parameter.</p> required <code>b</code> <code>float</code> <p>Left shoulder parameter.</p> required <code>c</code> <code>float</code> <p>Right shoulder parameter.</p> required <code>d</code> <code>float</code> <p>Right foot parameter.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If parameters don't satisfy a &lt; b \u2264 c &lt; d.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float, b: float, c: float, d: float):\n    \"\"\"Initialize the Pi-shaped membership function.\n\n    Args:\n        a: Left foot parameter.\n        b: Left shoulder parameter.\n        c: Right shoulder parameter.\n        d: Right foot parameter.\n\n    Raises:\n        ValueError: If parameters don't satisfy a &lt; b \u2264 c &lt; d.\n    \"\"\"\n    super().__init__()\n\n    # Parameter validation\n    if not (a &lt; b &lt;= c &lt; d):\n        raise ValueError(f\"Parameters must satisfy a &lt; b \u2264 c &lt; d, got a={a}, b={b}, c={c}, d={d}\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b), \"c\": float(c), \"d\": float(d)}\n    self.gradients = {\"a\": 0.0, \"b\": 0.0, \"c\": 0.0, \"d\": 0.0}\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.PiMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute gradients for backpropagation.</p> <p>Analytical gradients are computed by region: - S-function: gradients w.r.t. a, b - Z-function: gradients w.r.t. c, d - Flat region: no gradients</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of loss w.r.t. function output.</p> required Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute gradients for backpropagation.\n\n    Analytical gradients are computed by region:\n    - S-function: gradients w.r.t. a, b\n    - Z-function: gradients w.r.t. c, d\n    - Flat region: no gradients\n\n    Args:\n        dL_dy: Gradient of loss w.r.t. function output.\n    \"\"\"\n    if self.last_input is None or self.last_output is None:\n        return\n\n    x = self.last_input\n    dL_dy = np.asarray(dL_dy)\n\n    a, b, c, d = self.parameters[\"a\"], self.parameters[\"b\"], self.parameters[\"c\"], self.parameters[\"d\"]\n\n    # Initialize gradients\n    grad_a = grad_b = grad_c = grad_d = 0.0\n\n    # S-function gradients [a, b]\n    mask_s = (x &gt;= a) &amp; (x &lt;= b)\n    if np.any(mask_s) and b != a:\n        x_s = x[mask_s]\n        dL_dy_s = dL_dy[mask_s]\n        t = (x_s - a) / (b - a)\n\n        # Calculate parameter derivatives\n        dt_da = (x_s - b) / (b - a) ** 2  # Correct derivative\n        dt_db = -(x_s - a) / (b - a) ** 2\n\n        # For smoothstep S(t) = 3*t\u00b2 - 2*t\u00b3, derivative is dS/dt = 6*t - 6*t\u00b2 = 6*t*(1-t)\n        dS_dt = _dsmoothstep_dt(t)\n\n        # Apply chain rule: dS/da = dS/dt * dt/da\n        dS_da = dS_dt * dt_da\n        dS_db = dS_dt * dt_db\n\n        grad_a += np.sum(dL_dy_s * dS_da)\n        grad_b += np.sum(dL_dy_s * dS_db)\n\n    # Z-function gradients [c, d]\n    mask_z = (x &gt;= c) &amp; (x &lt;= d)\n    if np.any(mask_z) and d != c:\n        x_z = x[mask_z]\n        dL_dy_z = dL_dy[mask_z]\n        t = (x_z - c) / (d - c)\n\n        # Calculate parameter derivatives\n        dt_dc = (x_z - d) / (d - c) ** 2  # Correct derivative\n        dt_dd = -(x_z - c) / (d - c) ** 2\n\n        # For Z(t) = 1 - S(t) = 1 - (3*t\u00b2 - 2*t\u00b3), derivative is dZ/dt = -dS/dt = -6*t*(1-t) = 6*t*(t-1)\n        dZ_dt = -_dsmoothstep_dt(t)\n\n        # Apply chain rule: dZ/dc = dZ/dt * dt/dc\n        dZ_dc = dZ_dt * dt_dc\n        dZ_dd = dZ_dt * dt_dd\n\n        grad_c += np.sum(dL_dy_z * dZ_dc)\n        grad_d += np.sum(dL_dy_z * dZ_dd)\n\n    # Accumulate gradients\n    self.gradients[\"a\"] += grad_a\n    self.gradients[\"b\"] += grad_b\n    self.gradients[\"c\"] += grad_c\n    self.gradients[\"d\"] += grad_d\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.PiMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute the Pi-shaped membership function.</p> <p>Combines S and Z functions for smooth transitions: - Rising edge: S-function from a to b - Flat top: constant 1 from b to c - Falling edge: Z-function from c to d - Outside: 0</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input values.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Membership values \u03bc(x) \u2208 [0, 1].</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute the Pi-shaped membership function.\n\n    Combines S and Z functions for smooth transitions:\n    - Rising edge: S-function from a to b\n    - Flat top: constant 1 from b to c\n    - Falling edge: Z-function from c to d\n    - Outside: 0\n\n    Args:\n        x: Input values.\n\n    Returns:\n        np.ndarray: Membership values \u03bc(x) \u2208 [0, 1].\n    \"\"\"\n    x = np.asarray(x)\n    self.last_input = x.copy()\n\n    a, b, c, d = self.parameters[\"a\"], self.parameters[\"b\"], self.parameters[\"c\"], self.parameters[\"d\"]\n\n    # Initialize output\n    y = np.zeros_like(x, dtype=np.float64)\n\n    # S-function for rising edge [a, b]\n    mask_s = (x &gt;= a) &amp; (x &lt;= b)\n    if np.any(mask_s):\n        x_s = x[mask_s]\n        # Avoid division by zero\n        if b != a:\n            t = (x_s - a) / (b - a)  # Normalize to [0, 1]\n\n            # Smooth S-function using smoothstep: S(t) = 3*t\u00b2 - 2*t\u00b3\n            # This is continuous and differentiable across the entire [0,1] interval\n            y_s = _smoothstep(t)\n\n            y[mask_s] = y_s\n        else:\n            # Degenerate case: instant transition\n            y[mask_s] = 1.0\n\n    # Flat region [b, c]: \u03bc(x) = 1\n    mask_flat = (x &gt;= b) &amp; (x &lt;= c)\n    y[mask_flat] = 1.0\n\n    # Z-function for falling edge [c, d]\n    mask_z = (x &gt;= c) &amp; (x &lt;= d)\n    if np.any(mask_z):\n        x_z = x[mask_z]\n        # Avoid division by zero\n        if d != c:\n            t = (x_z - c) / (d - c)  # Normalize to [0, 1]\n\n            # Smooth Z-function (inverted smoothstep): Z(t) = 1 - S(t) = 1 - (3*t\u00b2 - 2*t\u00b3)\n            # This is continuous and differentiable, going from 1 to 0\n            y_z = 1 - _smoothstep(t)\n\n            y[mask_z] = y_z\n        else:\n            # Degenerate case: instant transition\n            y[mask_z] = 0.0\n\n    self.last_output = y.copy()\n    return y\n</code></pre>"},{"location":"api/membership-functions/#triangularmf","title":"TriangularMF","text":""},{"location":"api/membership-functions/#anfis_toolbox.membership.TriangularMF","title":"anfis_toolbox.membership.TriangularMF","text":"<pre><code>TriangularMF(a: float, b: float, c: float)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Triangular Membership Function.</p> <p>Implements a triangular membership function using piecewise linear segments: \u03bc(x) = { 0,           x \u2264 a or x \u2265 c        { (x-a)/(b-a), a &lt; x &lt; b        { (c-x)/(c-b), b \u2264 x &lt; c</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left base point of the triangle.</p> required <code>b</code> <code>float</code> <p>Peak point of the triangle (\u03bc(b) = 1).</p> required <code>c</code> <code>float</code> <p>Right base point of the triangle.</p> required Note <p>Must satisfy: a \u2264 b \u2264 c</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left base point (must satisfy a \u2264 b).</p> required <code>b</code> <code>float</code> <p>Peak point (must satisfy a \u2264 b \u2264 c).</p> required <code>c</code> <code>float</code> <p>Right base point (must satisfy b \u2264 c).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If parameters do not satisfy a \u2264 b \u2264 c or if a == c (zero width).</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float, b: float, c: float):\n    \"\"\"Initialize the triangular membership function.\n\n    Args:\n        a: Left base point (must satisfy a \u2264 b).\n        b: Peak point (must satisfy a \u2264 b \u2264 c).\n        c: Right base point (must satisfy b \u2264 c).\n\n    Raises:\n        ValueError: If parameters do not satisfy a \u2264 b \u2264 c or if a == c (zero width).\n    \"\"\"\n    super().__init__()\n\n    if not (a &lt;= b &lt;= c):\n        raise ValueError(f\"Triangular MF parameters must satisfy a \u2264 b \u2264 c, got a={a}, b={b}, c={c}\")\n    if a == c:\n        raise ValueError(\"Parameters 'a' and 'c' cannot be equal (zero width triangle)\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b), \"c\": float(c)}\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.TriangularMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Accumulate gradients for a, b, c given upstream gradient.</p> <p>Computes analytical derivatives for the rising (a, b) and falling (b, c) regions and sums them over the batch.</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss w.r.t. \u03bc(x); same shape or broadcastable to output.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Accumulate gradients for a, b, c given upstream gradient.\n\n    Computes analytical derivatives for the rising (a, b) and falling (b, c)\n    regions and sums them over the batch.\n\n    Args:\n        dL_dy: Gradient of the loss w.r.t. \u03bc(x); same shape or broadcastable to output.\n\n    Returns:\n        None\n    \"\"\"\n    if self.last_input is None or self.last_output is None:\n        return\n\n    a, b, c = self.parameters[\"a\"], self.parameters[\"b\"], self.parameters[\"c\"]\n    x = self.last_input\n\n    dL_da = 0.0\n    dL_db = 0.0\n    dL_dc = 0.0\n\n    # Left slope: a &lt; x &lt; b\n    if b &gt; a:\n        left_mask = (x &gt; a) &amp; (x &lt; b)\n        if np.any(left_mask):\n            x_left = x[left_mask]\n            dL_dy_left = dL_dy[left_mask]\n\n            # \u2202\u03bc/\u2202a = (x - b) / (b - a)^2\n            dmu_da_left = (x_left - b) / ((b - a) ** 2)\n            dL_da += np.sum(dL_dy_left * dmu_da_left)\n\n            # \u2202\u03bc/\u2202b = -(x - a) / (b - a)^2\n            dmu_db_left = -(x_left - a) / ((b - a) ** 2)\n            dL_db += np.sum(dL_dy_left * dmu_db_left)\n\n    # Right slope: b &lt; x &lt; c\n    if c &gt; b:\n        right_mask = (x &gt; b) &amp; (x &lt; c)\n        if np.any(right_mask):\n            x_right = x[right_mask]\n            dL_dy_right = dL_dy[right_mask]\n\n            # \u2202\u03bc/\u2202b = (x - c) / (c - b)^2\n            dmu_db_right = (x_right - c) / ((c - b) ** 2)\n            dL_db += np.sum(dL_dy_right * dmu_db_right)\n\n            # \u2202\u03bc/\u2202c = (x - b) / (c - b)^2\n            dmu_dc_right = (x_right - b) / ((c - b) ** 2)\n            dL_dc += np.sum(dL_dy_right * dmu_dc_right)\n\n    # Update gradients\n    self.gradients[\"a\"] += dL_da\n    self.gradients[\"b\"] += dL_db\n    self.gradients[\"c\"] += dL_dc\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.TriangularMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute triangular membership values \u03bc(x).</p> <p>Uses piecewise linear segments defined by (a, b, c): - 0 outside [a, c] - rising slope in (a, b) - peak 1 at x == b - falling slope in (b, c)</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Membership values in [0, 1] with the same shape as x.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute triangular membership values \u03bc(x).\n\n    Uses piecewise linear segments defined by (a, b, c):\n    - 0 outside [a, c]\n    - rising slope in (a, b)\n    - peak 1 at x == b\n    - falling slope in (b, c)\n\n    Args:\n        x: Input array.\n\n    Returns:\n        np.ndarray: Membership values in [0, 1] with the same shape as x.\n    \"\"\"\n    a, b, c = self.parameters[\"a\"], self.parameters[\"b\"], self.parameters[\"c\"]\n    self.last_input = x\n\n    output = np.zeros_like(x, dtype=float)\n\n    # Left slope\n    if b &gt; a:\n        left_mask = (x &gt; a) &amp; (x &lt; b)\n        output[left_mask] = (x[left_mask] - a) / (b - a)\n\n    # Peak\n    peak_mask = x == b\n    output[peak_mask] = 1.0\n\n    # Right slope\n    if c &gt; b:\n        right_mask = (x &gt; b) &amp; (x &lt; c)\n        output[right_mask] = (c - x[right_mask]) / (c - b)\n\n    # Clip for numerical stability\n    output = np.clip(output, 0.0, 1.0)\n\n    self.last_output = output\n    return output\n</code></pre>"},{"location":"api/membership-functions/#trapezoidalmf","title":"TrapezoidalMF","text":"<p>See also: Core Classes for the overall ANFIS architecture.</p>"},{"location":"api/membership-functions/#anfis_toolbox.membership.TrapezoidalMF","title":"anfis_toolbox.membership.TrapezoidalMF","text":"<pre><code>TrapezoidalMF(a: float, b: float, c: float, d: float)\n</code></pre> <p>               Bases: <code>MembershipFunction</code></p> <p>Trapezoidal Membership Function.</p> <p>Implements a trapezoidal membership function using piecewise linear segments: \u03bc(x) = { 0,           x \u2264 a or x \u2265 d        { (x-a)/(b-a), a &lt; x &lt; b        { 1,           b \u2264 x \u2264 c        { (d-x)/(d-c), c &lt; x &lt; d</p> <p>This function is commonly used in fuzzy logic systems when you need a plateau region of full membership, providing robustness to noise and uncertainty.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left base point of the trapezoid (lower support bound).</p> required <code>b</code> <code>float</code> <p>Left peak point (start of plateau where \u03bc(x) = 1).</p> required <code>c</code> <code>float</code> <p>Right peak point (end of plateau where \u03bc(x) = 1).</p> required <code>d</code> <code>float</code> <p>Right base point of the trapezoid (upper support bound).</p> required Note <p>Parameters must satisfy: a \u2264 b \u2264 c \u2264 d for a valid trapezoidal function.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Left base point (\u03bc(a) = 0).</p> required <code>b</code> <code>float</code> <p>Left peak point (\u03bc(b) = 1, start of plateau).</p> required <code>c</code> <code>float</code> <p>Right peak point (\u03bc\u00a9 = 1, end of plateau).</p> required <code>d</code> <code>float</code> <p>Right base point (\u03bc(d) = 0).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If parameters don't satisfy a \u2264 b \u2264 c \u2264 d.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def __init__(self, a: float, b: float, c: float, d: float):\n    \"\"\"Initialize the trapezoidal membership function.\n\n    Args:\n        a: Left base point (\u03bc(a) = 0).\n        b: Left peak point (\u03bc(b) = 1, start of plateau).\n        c: Right peak point (\u03bc(c) = 1, end of plateau).\n        d: Right base point (\u03bc(d) = 0).\n\n    Raises:\n        ValueError: If parameters don't satisfy a \u2264 b \u2264 c \u2264 d.\n    \"\"\"\n    super().__init__()\n\n    # Validate parameters\n    if not (a &lt;= b &lt;= c &lt;= d):\n        raise ValueError(f\"Trapezoidal MF parameters must satisfy a \u2264 b \u2264 c \u2264 d, got a={a}, b={b}, c={c}, d={d}\")\n\n    if a == d:\n        raise ValueError(\"Parameters 'a' and 'd' cannot be equal (zero width trapezoid)\")\n\n    self.parameters = {\"a\": float(a), \"b\": float(b), \"c\": float(c), \"d\": float(d)}\n    # Initialize gradients to zero for all parameters\n    self.gradients = dict.fromkeys(self.parameters.keys(), 0.0)\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.TrapezoidalMF.backward","title":"backward","text":"<pre><code>backward(dL_dy: ndarray)\n</code></pre> <p>Compute gradients for parameters based on upstream loss gradient.</p> <p>Analytical gradients for the piecewise linear function: - \u2202\u03bc/\u2202a: left slope - \u2202\u03bc/\u2202b: left slope and plateau transition - \u2202\u03bc/\u2202c: right slope and plateau transition - \u2202\u03bc/\u2202d: right slope</p> <p>Parameters:</p> Name Type Description Default <code>dL_dy</code> <code>ndarray</code> <p>Gradient of the loss w.r.t. the output of this layer.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def backward(self, dL_dy: np.ndarray):\n    \"\"\"Compute gradients for parameters based on upstream loss gradient.\n\n    Analytical gradients for the piecewise linear function:\n    - \u2202\u03bc/\u2202a: left slope\n    - \u2202\u03bc/\u2202b: left slope and plateau transition\n    - \u2202\u03bc/\u2202c: right slope and plateau transition\n    - \u2202\u03bc/\u2202d: right slope\n\n    Args:\n        dL_dy: Gradient of the loss w.r.t. the output of this layer.\n\n    Returns:\n        None\n    \"\"\"\n    if self.last_input is None or self.last_output is None:\n        return\n\n    a = self.parameters[\"a\"]\n    b = self.parameters[\"b\"]\n    c = self.parameters[\"c\"]\n    d = self.parameters[\"d\"]\n\n    x = self.last_input\n\n    # Initialize gradients\n    dL_da = 0.0\n    dL_db = 0.0\n    dL_dc = 0.0\n    dL_dd = 0.0\n\n    # Left slope region: a &lt; x &lt; b, \u03bc(x) = (x-a)/(b-a)\n    if b &gt; a:\n        left_mask = (x &gt; a) &amp; (x &lt; b)\n        if np.any(left_mask):\n            x_left = x[left_mask]\n            dL_dy_left = dL_dy[left_mask]\n\n            # \u2202\u03bc/\u2202a = -1/(b-a) for left slope\n            dmu_da_left = -1.0 / (b - a)\n            dL_da += np.sum(dL_dy_left * dmu_da_left)\n\n            # \u2202\u03bc/\u2202b = -(x-a)/(b-a)\u00b2 for left slope\n            dmu_db_left = -(x_left - a) / ((b - a) ** 2)\n            dL_db += np.sum(dL_dy_left * dmu_db_left)\n\n    # Plateau region: b \u2264 x \u2264 c, \u03bc(x) = 1\n    # No gradients for plateau region (constant function)\n\n    # Right slope region: c &lt; x &lt; d, \u03bc(x) = (d-x)/(d-c)\n    if d &gt; c:\n        right_mask = (x &gt; c) &amp; (x &lt; d)\n        if np.any(right_mask):\n            x_right = x[right_mask]\n            dL_dy_right = dL_dy[right_mask]\n\n            # \u2202\u03bc/\u2202c = (x-d)/(d-c)\u00b2 for right slope\n            dmu_dc_right = (x_right - d) / ((d - c) ** 2)\n            dL_dc += np.sum(dL_dy_right * dmu_dc_right)\n\n            # \u2202\u03bc/\u2202d = (x-c)/(d-c)\u00b2 for right slope (derivative of (d-x)/(d-c) w.r.t. d)\n            dmu_dd_right = (x_right - c) / ((d - c) ** 2)\n            dL_dd += np.sum(dL_dy_right * dmu_dd_right)\n\n    # Update gradients (accumulate for batch processing)\n    self.gradients[\"a\"] += dL_da\n    self.gradients[\"b\"] += dL_db\n    self.gradients[\"c\"] += dL_dc\n    self.gradients[\"d\"] += dL_dd\n</code></pre>"},{"location":"api/membership-functions/#anfis_toolbox.membership.TrapezoidalMF.forward","title":"forward","text":"<pre><code>forward(x: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute trapezoidal membership values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array containing the trapezoidal membership values.</p> Source code in <code>anfis_toolbox/membership.py</code> <pre><code>def forward(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute trapezoidal membership values.\n\n    Args:\n        x: Input array.\n\n    Returns:\n        np.ndarray: Array containing the trapezoidal membership values.\n    \"\"\"\n    a = self.parameters[\"a\"]\n    b = self.parameters[\"b\"]\n    c = self.parameters[\"c\"]\n    d = self.parameters[\"d\"]\n\n    self.last_input = x\n\n    # Initialize output with zeros\n    output = np.zeros_like(x)\n\n    # Left slope: (x - a) / (b - a) for a &lt; x &lt; b\n    if b &gt; a:  # Avoid division by zero\n        left_mask = (x &gt; a) &amp; (x &lt; b)\n        output[left_mask] = (x[left_mask] - a) / (b - a)\n\n    # Plateau: \u03bc(x) = 1 for b \u2264 x \u2264 c\n    plateau_mask = (x &gt;= b) &amp; (x &lt;= c)\n    output[plateau_mask] = 1.0\n\n    # Right slope: (d - x) / (d - c) for c &lt; x &lt; d\n    if d &gt; c:  # Avoid division by zero\n        right_mask = (x &gt; c) &amp; (x &lt; d)\n        output[right_mask] = (d - x[right_mask]) / (d - c)\n\n    # Values outside [a, d] are already zero\n\n    self.last_output = output\n    return output\n</code></pre>"},{"location":"api/overview/","title":"API Reference","text":"<p>Complete reference documentation for all ANFIS Toolbox classes, functions, and modules.</p>"},{"location":"api/overview/#core-architecture","title":"\ud83c\udfd7\ufe0f Core Architecture","text":""},{"location":"api/overview/#main-classes","title":"Main Classes","text":"Class Description Documentation <code>ANFIS</code> Core ANFIS implementation \ud83d\udd17 Details <code>QuickANFIS</code> Simplified API for common use cases \ud83d\udd17 Details <code>ANFISBuilder</code> Fluent API for custom model construction \ud83d\udd17 Details"},{"location":"api/overview/#membership-functions","title":"Membership Functions","text":"Class Type Parameters Documentation <code>GaussianMF</code> Gaussian <code>mean</code>, <code>sigma</code> \ud83d\udd17 Details <code>TriangularMF</code> Triangular <code>a</code>, <code>b</code>, <code>c</code> \ud83d\udd17 Details <code>TrapezoidalMF</code> Trapezoidal <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code> \ud83d\udd17 Details <code>BellMF</code> Bell-shaped <code>a</code>, <code>b</code>, <code>c</code> \ud83d\udd17 Details <code>SigmoidalMF</code> Sigmoidal <code>a</code>, <code>c</code> \ud83d\udd17 Details <code>SShapedMF</code> S-shaped <code>a</code>, <code>b</code> \ud83d\udd17 Details <code>ZShapedMF</code> Z-shaped <code>a</code>, <code>b</code> \ud83d\udd17 Details <code>PiMF</code> Pi-shaped <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code> \ud83d\udd17 Details"},{"location":"api/overview/#analysis-visualization","title":"\ud83d\udcca Analysis &amp; Visualization","text":"Class/Function Purpose Documentation <code>ANFISVisualizer</code> Plotting and visualization Coming soon <code>ANFISValidator</code> Model validation and metrics Coming soon <code>ANFISMetrics</code> Performance metrics Coming soon <code>quick_evaluate</code> Fast model evaluation Coming soon"},{"location":"api/overview/#configuration-utilities","title":"\u2699\ufe0f Configuration &amp; Utilities","text":"Class/Function Purpose Documentation <code>ANFISConfig</code> Configuration management Coming soon <code>load_anfis</code> Model loading Coming soon <code>save_anfis</code> Model saving Coming soon"},{"location":"api/overview/#module-organization","title":"\ud83d\udce6 Module Organization","text":"<pre><code>anfis_toolbox/\n\u251c\u2500\u2500 core.py              # ANFIS main class\n\u251c\u2500\u2500 membership.py        # Membership function classes\n\u251c\u2500\u2500 builders.py          # QuickANFIS and ANFISBuilder\n\u251c\u2500\u2500 training.py          # Training algorithms\n\u251c\u2500\u2500 validation.py        # Validation and metrics\n\u251c\u2500\u2500 visualization.py     # Plotting utilities\n\u251c\u2500\u2500 config.py           # Configuration management\n\u251c\u2500\u2500 utils.py            # Helper functions\n\u2514\u2500\u2500 __init__.py         # Package initialization\n</code></pre>"},{"location":"api/overview/#quick-reference","title":"\ud83d\ude80 Quick Reference","text":""},{"location":"api/overview/#essential-imports","title":"Essential Imports","text":"<pre><code># Core functionality\nfrom anfis_toolbox import ANFIS, QuickANFIS, ANFISBuilder\n\n# Membership functions\nfrom anfis_toolbox.membership import (\n    GaussianMF, TriangularMF, TrapezoidalMF,\n    BellMF, SigmoidalMF, SShapedMF, ZShapedMF, PiMF\n)\n\n# Validation and visualization (optional dependencies)\nfrom anfis_toolbox import (\n    ANFISValidator, ANFISVisualizer, ANFISMetrics,\n    quick_evaluate, ANFISConfig\n)\n\n# Persistence\nfrom anfis_toolbox import load_anfis\n</code></pre>"},{"location":"api/overview/#common-patterns","title":"Common Patterns","text":""},{"location":"api/overview/#quick-start","title":"\ud83c\udfaf Quick Start","text":"<pre><code>model = QuickANFIS.for_regression(X, n_mfs=3)\nlosses = model.fit_hybrid(X, y, epochs=100)\nmetrics = quick_evaluate(model, X, y)\n</code></pre>"},{"location":"api/overview/#custom-building","title":"\ud83c\udfd7\ufe0f Custom Building","text":"<pre><code>builder = (ANFISBuilder()\n    .add_input('x1', 'gaussian', 3)\n    .add_input('x2', 'bell', 4)\n    .set_config(ANFISConfig(learning_rate=0.01))\n)\nmodel = builder.build()\n</code></pre>"},{"location":"api/overview/#comprehensive-analysis","title":"\ud83d\udcca Comprehensive Analysis","text":"<pre><code>validator = ANFISValidator(model)\ncv_results = validator.cross_validate(X, y, cv=5)\n\nvisualizer = ANFISVisualizer(model)\nvisualizer.plot_membership_functions()\nvisualizer.plot_training_curves(losses)\n</code></pre>"},{"location":"api/overview/#detailed-documentation","title":"\ud83d\udcda Detailed Documentation","text":""},{"location":"api/overview/#by-category","title":"By Category","text":"<ul> <li>Core Classes - ANFIS, basic functionality</li> <li>Builders - QuickANFIS, ANFISBuilder</li> <li>Membership Functions - All MF types Training, Validation, Visualization, Configuration, Persistence, and Utilities docs are coming soon.</li> </ul>"},{"location":"api/overview/#by-use-case","title":"By Use Case","text":"<ul> <li>Getting Started - Basic usage patterns Function Approximation, Regression Analysis, Control Systems, and Time Series docs are coming soon.</li> </ul>"},{"location":"api/overview/#search-and-navigation","title":"\ud83d\udd0d Search and Navigation","text":""},{"location":"api/overview/#find-by-functionality","title":"Find by Functionality","text":"I want to... Look at... Create a simple model <code>QuickANFIS</code> in Builders Build custom architecture <code>ANFISBuilder</code> in Builders Choose membership functions Membership Functions Train my model <code>fit_hybrid()</code>, <code>fit()</code> in Core Evaluate performance <code>quick_evaluate()</code> (docs coming soon) Visualize results <code>ANFISVisualizer</code> (docs coming soon) Save/load models Persistence (docs coming soon) Configure training <code>ANFISConfig</code> (docs coming soon)"},{"location":"api/overview/#find-by-data-type","title":"Find by Data Type","text":"Data Type Relevant Classes/Functions Numpy arrays All core functionality Pandas DataFrames <code>QuickANFIS.from_dataframe()</code> Time series <code>QuickANFIS.for_time_series()</code> Images Custom MF setup, reshape utilities Control signals <code>ANFISBuilder</code> with domain-specific MFs"},{"location":"api/overview/#parameter-reference","title":"\ud83d\udcca Parameter Reference","text":""},{"location":"api/overview/#training-parameters","title":"Training Parameters","text":"Parameter Type Default Description <code>epochs</code> <code>int</code> <code>100</code> Number of training epochs <code>learning_rate</code> <code>float</code> <code>0.01</code> Learning rate for gradient descent <code>tolerance</code> <code>float</code> <code>1e-6</code> Convergence tolerance <code>patience</code> <code>int</code> <code>10</code> Early stopping patience <code>validation_split</code> <code>float</code> <code>0.0</code> Fraction of data for validation"},{"location":"api/overview/#model-parameters","title":"Model Parameters","text":"Parameter Type Default Description <code>n_mfs</code> <code>int</code> <code>3</code> Number of membership functions per input <code>mf_type</code> <code>str</code> <code>'gaussian'</code> Type of membership function <code>random_state</code> <code>int</code> <code>None</code> Random seed for reproducibility"},{"location":"api/overview/#complete-parameter-lists-available-in-each-class-documentation","title":"Complete parameter lists available in each class documentation.","text":""},{"location":"api/overview/#testing-and-validation","title":"\ud83e\uddea Testing and Validation","text":""},{"location":"api/overview/#unit-tests","title":"Unit Tests","text":"<pre><code># Run all tests\npytest tests/\n\n# Test specific module\npytest tests/test_membership.py\n\n# Test with coverage\npytest --cov=anfis_toolbox tests/\n</code></pre>"},{"location":"api/overview/#type-checking","title":"Type Checking","text":"<pre><code># Check types\nmypy anfis_toolbox/\n\n# Check specific file\nmypy anfis_toolbox/core.py\n</code></pre>"},{"location":"api/overview/#examples-and-tutorials","title":"\ud83c\udfaf Examples and Tutorials","text":"<p>Each API component includes:</p> <ul> <li>\ud83d\udca1 Usage examples - Basic usage patterns</li> <li>\ud83d\udd27 Advanced examples - Complex configurations</li> <li>\u26a0\ufe0f Common pitfalls - What to avoid</li> <li>\ud83d\udcd6 Related functions - Cross-references</li> <li>\ud83e\uddea Test cases - Validation examples</li> </ul>"},{"location":"api/overview/#contributing-to-documentation","title":"\ud83e\udd1d Contributing to Documentation","text":"<p>Documentation is generated using mkdocstrings from docstrings in the source code. To improve documentation:</p> <ol> <li>Edit docstrings in source files</li> <li>Follow Google style docstring format</li> <li>Include examples in docstrings</li> <li>Add type hints to all functions</li> <li>Run tests to ensure accuracy</li> </ol>"},{"location":"api/overview/#docstring-format","title":"Docstring Format","text":"<pre><code>def example_function(param1: int, param2: str = \"default\") -&gt; float:\n    \"\"\"Brief description of the function.\n\n    Longer description with more details about what the function does,\n    when to use it, and any important considerations.\n\n    Args:\n        param1: Description of param1.\n        param2: Description of param2 with default value.\n\n    Returns:\n        Description of return value.\n\n    Raises:\n        ValueError: When param1 is negative.\n        TypeError: When param2 is not a string.\n\n    Examples:\n        Basic usage:\n        ```python\n        result = example_function(5, \"test\")\n        print(result)  # Output: 42.0\n        ```\n\n        Advanced usage:\n        ```python\n        result = example_function(10)  # Uses default param2\n        ```\n    \"\"\"\n    if param1 &lt; 0:\n        raise ValueError(\"param1 must be non-negative\")\n    return float(param1 * len(param2))\n</code></pre>"},{"location":"api/overview/#navigation","title":"Navigation","text":"<p>Start here for specific needs:</p> <ul> <li>\ud83d\ude80 New user? \u2192 Core Classes</li> <li>\ud83c\udfd7\ufe0f Building models? \u2192 Builders</li> <li>\ud83d\udcca Analyzing results? \u2192 Validation (docs coming soon)</li> <li>\ud83c\udfa8 Visualizing? \u2192 Visualization (docs coming soon)</li> <li>\u2699\ufe0f Configuring? \u2192 Configuration (docs coming soon)</li> </ul> <p>Or browse by alphabetical order:</p> <p>A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z</p>"},{"location":"examples/advanced_example/","title":"Advanced ANFIS Example","text":"In\u00a0[4]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom anfis_toolbox import QuickANFIS, quick_evaluate\nfrom anfis_toolbox.metrics import r2_score\nfrom anfis_toolbox.model_selection import KFold, train_test_split\n\nnp.random.seed(42)  # reproducibility\n</pre> import matplotlib.pyplot as plt import numpy as np  from anfis_toolbox import QuickANFIS, quick_evaluate from anfis_toolbox.metrics import r2_score from anfis_toolbox.model_selection import KFold, train_test_split  np.random.seed(42)  # reproducibility In\u00a0[5]: Copied! <pre>n = 800\nx1 = np.random.uniform(-3.0, 3.0, size=n)\nx2 = np.random.uniform(-2.0, 2.0, size=n)\nx3 = np.random.uniform(-1.5, 1.5, size=n)\nX = np.column_stack([x1, x2, x3])\ny = np.sin(x1) + 0.3 * (x2 ** 2) + 0.5 * np.cos(1.5 * x3) + 0.1 * np.random.randn(n)\ny = y.reshape(-1, 1)\n\n# Standardize features\nmu = X.mean(axis=0)\nsd = X.std(axis=0) + 1e-12\nX_std = (X - mu) / sd\nX.shape, X_std.shape, y.shape\n</pre> n = 800 x1 = np.random.uniform(-3.0, 3.0, size=n) x2 = np.random.uniform(-2.0, 2.0, size=n) x3 = np.random.uniform(-1.5, 1.5, size=n) X = np.column_stack([x1, x2, x3]) y = np.sin(x1) + 0.3 * (x2 ** 2) + 0.5 * np.cos(1.5 * x3) + 0.1 * np.random.randn(n) y = y.reshape(-1, 1)  # Standardize features mu = X.mean(axis=0) sd = X.std(axis=0) + 1e-12 X_std = (X - mu) / sd X.shape, X_std.shape, y.shape Out[5]: <pre>((800, 3), (800, 3), (800, 1))</pre> In\u00a0[6]: Copied! <pre>X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=0)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n</pre> X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=0) X_train.shape, X_test.shape, y_train.shape, y_test.shape Out[6]: <pre>((640, 3), (160, 3), (640, 1), (160, 1))</pre> In\u00a0[7]: Copied! <pre>param_grid = {\n    'n_mfs': [5, 7],\n    'mf_type': ['gaussian', 'bell'],\n    'epochs': [80, 120]\n}\n\nkf = KFold(n_splits=3, shuffle=True, random_state=0)\n\ndef evaluate_config(n_mfs, mf_type, epochs):\n    r2s = []\n    for tr_idx, va_idx in kf.split(X_train):\n        X_tr, X_va = X_train[tr_idx], X_train[va_idx]\n        y_tr, y_va = y_train[tr_idx], y_train[va_idx]\n        model = QuickANFIS.for_regression(X_tr, n_mfs=n_mfs, mf_type=mf_type, init='fcm', random_state=42)\n        _ = model.fit(X_tr, y_tr, epochs=epochs, learning_rate=0.02, verbose=False)\n        y_va_pred = model.predict(X_va)\n        r2s.append(r2_score(y_va, y_va_pred))\n    return float(np.mean(r2s))\n\nbest_cfg, best_score = None, -np.inf\nresults = []\nprint(\"Evaluating configurations:\")\nfor n_mfs in param_grid['n_mfs']:\n    for mf_type in param_grid['mf_type']:\n        for epochs in param_grid['epochs']:\n            score = evaluate_config(n_mfs, mf_type, epochs)\n            results.append({'n_mfs': n_mfs, 'mf_type': mf_type, 'epochs': epochs, 'mean_r2': score})\n            print(score)\n            if score &gt; best_score:\n                best_score = score\n                best_cfg = {'n_mfs': n_mfs, 'mf_type': mf_type, 'epochs': epochs}\nbest_cfg, best_score\n</pre> param_grid = {     'n_mfs': [5, 7],     'mf_type': ['gaussian', 'bell'],     'epochs': [80, 120] }  kf = KFold(n_splits=3, shuffle=True, random_state=0)  def evaluate_config(n_mfs, mf_type, epochs):     r2s = []     for tr_idx, va_idx in kf.split(X_train):         X_tr, X_va = X_train[tr_idx], X_train[va_idx]         y_tr, y_va = y_train[tr_idx], y_train[va_idx]         model = QuickANFIS.for_regression(X_tr, n_mfs=n_mfs, mf_type=mf_type, init='fcm', random_state=42)         _ = model.fit(X_tr, y_tr, epochs=epochs, learning_rate=0.02, verbose=False)         y_va_pred = model.predict(X_va)         r2s.append(r2_score(y_va, y_va_pred))     return float(np.mean(r2s))  best_cfg, best_score = None, -np.inf results = [] print(\"Evaluating configurations:\") for n_mfs in param_grid['n_mfs']:     for mf_type in param_grid['mf_type']:         for epochs in param_grid['epochs']:             score = evaluate_config(n_mfs, mf_type, epochs)             results.append({'n_mfs': n_mfs, 'mf_type': mf_type, 'epochs': epochs, 'mean_r2': score})             print(score)             if score &gt; best_score:                 best_score = score                 best_cfg = {'n_mfs': n_mfs, 'mf_type': mf_type, 'epochs': epochs} best_cfg, best_score <pre>Evaluating configurations:\n-9.564034368864718\n-24.113957366133153\n-6.633278023678602\n-16.771932607788827\n0.5611883161213395\n0.4345172625778757\n0.1489655257641426\n0.3683488532923132\n</pre> Out[7]: <pre>({'n_mfs': 7, 'mf_type': 'gaussian', 'epochs': 80}, 0.5611883161213395)</pre> In\u00a0[8]: Copied! <pre>model_best = QuickANFIS.for_regression(X_train, n_mfs=best_cfg['n_mfs'], mf_type=best_cfg['mf_type'], init='fcm', random_state=123)\nlosses = model_best.fit(X_train, y_train, epochs=best_cfg['epochs'], learning_rate=0.02, verbose=False)\nmetrics_train = quick_evaluate(model_best, X_train, y_train, print_results=False)\nmetrics_test = quick_evaluate(model_best, X_test, y_test, print_results=False)\nmetrics_train, metrics_test\n</pre> model_best = QuickANFIS.for_regression(X_train, n_mfs=best_cfg['n_mfs'], mf_type=best_cfg['mf_type'], init='fcm', random_state=123) losses = model_best.fit(X_train, y_train, epochs=best_cfg['epochs'], learning_rate=0.02, verbose=False) metrics_train = quick_evaluate(model_best, X_train, y_train, print_results=False) metrics_test = quick_evaluate(model_best, X_test, y_test, print_results=False) metrics_train, metrics_test Out[8]: <pre>({'mse': 3.284219167484291e-08,\n  'rmse': np.float64(0.00018122414760412837),\n  'mae': 3.780887981312326e-05,\n  'r2': 0.999999954196575,\n  'mape': np.float64(0.012982695978181805),\n  'max_error': np.float64(0.003173606934868234),\n  'std_error': np.float64(0.00018122411543007529)},\n {'mse': 0.2939164446687753,\n  'rmse': np.float64(0.5421406133732976),\n  'mae': 0.34670961382480164,\n  'r2': 0.4986060712238396,\n  'mape': np.float64(145.7614512309781),\n  'max_error': np.float64(3.205974893698987),\n  'std_error': np.float64(0.5416649670141173)})</pre> In\u00a0[9]: Copied! <pre>plt.figure(figsize=(5,3))\nplt.plot(losses, color='tab:blue')\nplt.xlabel('Epoch')\nplt.ylabel('MSE Loss')\nplt.title('Training curve (Hybrid)')\n# zoom if nearly flat\nif len(losses) &gt; 5 and (max(losses) - min(losses)) &lt; 1e-2:\n    lo, hi = min(losses), max(losses)\n    plt.ylim(lo - 0.02 * (hi - lo + 1e-9), hi + 0.02 * (hi - lo + 1e-9))\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(5,3)) plt.plot(losses, color='tab:blue') plt.xlabel('Epoch') plt.ylabel('MSE Loss') plt.title('Training curve (Hybrid)') # zoom if nearly flat if len(losses) &gt; 5 and (max(losses) - min(losses)) &lt; 1e-2:     lo, hi = min(losses), max(losses)     plt.ylim(lo - 0.02 * (hi - lo + 1e-9), hi + 0.02 * (hi - lo + 1e-9)) plt.tight_layout() plt.show() In\u00a0[10]: Copied! <pre>y_pred_test = model_best.predict(X_test)\nplt.figure(figsize=(4,4))\nplt.scatter(y_test, y_pred_test, s=10, alpha=0.4, color='tab:green')\nmn, mx = float(np.min(y_test)), float(np.max(y_test))\nplt.plot([mn, mx], [mn, mx], 'r--', lw=2, label='ideal')\nplt.xlabel('y true')\nplt.ylabel('y pred')\nplt.title('Parity plot (test)')\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> y_pred_test = model_best.predict(X_test) plt.figure(figsize=(4,4)) plt.scatter(y_test, y_pred_test, s=10, alpha=0.4, color='tab:green') mn, mx = float(np.min(y_test)), float(np.max(y_test)) plt.plot([mn, mx], [mn, mx], 'r--', lw=2, label='ideal') plt.xlabel('y true') plt.ylabel('y pred') plt.title('Parity plot (test)') plt.legend() plt.tight_layout() plt.show() In\u00a0[11]: Copied! <pre>res = (y_test - y_pred_test).ravel()\nplt.figure(figsize=(5,3))\nplt.hist(res, bins=30, color='tab:purple', alpha=0.75)\nplt.xlabel('Residual')\nplt.ylabel('Count')\nplt.title('Residuals histogram (test)')\nplt.tight_layout()\nplt.show()\n</pre> res = (y_test - y_pred_test).ravel() plt.figure(figsize=(5,3)) plt.hist(res, bins=30, color='tab:purple', alpha=0.75) plt.xlabel('Residual') plt.ylabel('Count') plt.title('Residuals histogram (test)') plt.tight_layout() plt.show() In\u00a0[12]: Copied! <pre># Choose to vary dimensions 0 and 1; fix dim 2 at its train median\ndim_x, dim_y, dim_fix = 0, 1, 2\nfixed_val = np.median(X_train[:, dim_fix])\n\ngx = np.linspace(np.percentile(X_train[:, dim_x], 2), np.percentile(X_train[:, dim_x], 98), 60)\ngy = np.linspace(np.percentile(X_train[:, dim_y], 2), np.percentile(X_train[:, dim_y], 98), 60)\nGX, GY = np.meshgrid(gx, gy)\ngrid = np.stack([GX.ravel(), GY.ravel(), np.full(GX.size, fixed_val)], axis=1)\nZ = model_best.predict(grid).reshape(GX.shape)\n\nplt.figure(figsize=(5,4))\ncs = plt.contourf(GX, GY, Z, levels=30, cmap='viridis')\nplt.colorbar(cs, shrink=0.8, label='prediction')\nplt.xlabel(f'feature {dim_x} (std)')\nplt.ylabel(f'feature {dim_y} (std)')\nplt.title('2D prediction surface (slice, fix dim 2)')\nplt.tight_layout()\nplt.show()\n</pre> # Choose to vary dimensions 0 and 1; fix dim 2 at its train median dim_x, dim_y, dim_fix = 0, 1, 2 fixed_val = np.median(X_train[:, dim_fix])  gx = np.linspace(np.percentile(X_train[:, dim_x], 2), np.percentile(X_train[:, dim_x], 98), 60) gy = np.linspace(np.percentile(X_train[:, dim_y], 2), np.percentile(X_train[:, dim_y], 98), 60) GX, GY = np.meshgrid(gx, gy) grid = np.stack([GX.ravel(), GY.ravel(), np.full(GX.size, fixed_val)], axis=1) Z = model_best.predict(grid).reshape(GX.shape)  plt.figure(figsize=(5,4)) cs = plt.contourf(GX, GY, Z, levels=30, cmap='viridis') plt.colorbar(cs, shrink=0.8, label='prediction') plt.xlabel(f'feature {dim_x} (std)') plt.ylabel(f'feature {dim_y} (std)') plt.title('2D prediction surface (slice, fix dim 2)') plt.tight_layout() plt.show()"},{"location":"examples/advanced_example/#advanced-anfis-example","title":"Advanced ANFIS Example\u00b6","text":"<p>This notebook demonstrates a more advanced workflow for ANFIS-Toolbox:</p> <ul> <li>3D nonlinear regression dataset with noise</li> <li>Feature standardization</li> <li>Lightweight hyperparameter search with 3-fold CV (grid over <code>n_mfs</code>, <code>mf_type</code>, <code>epochs</code>)</li> <li>Final training and hold-out evaluation</li> <li>Visualizations: training curve, parity plot, residuals histogram, and a 2D surface (slice)</li> </ul>"},{"location":"examples/advanced_example/#1-imports-and-setup","title":"1) Imports and setup\u00b6","text":"<p>We import NumPy, plotting, and core utilities from ANFIS-Toolbox.</p>"},{"location":"examples/advanced_example/#2-create-a-3d-nonlinear-dataset-and-standardize","title":"2) Create a 3D nonlinear dataset and standardize\u00b6","text":"<p>Target: <code>y = sin(x1) + 0.3 * x2^2 + 0.5 * cos(1.5 * x3) + noise</code>. We standardize inputs to help training stability.</p>"},{"location":"examples/advanced_example/#3-traintest-split-8020","title":"3) Train/test split (80/20)\u00b6","text":""},{"location":"examples/advanced_example/#4-hyperparameter-grid-and-3-fold-cross-validation","title":"4) Hyperparameter grid and 3-fold cross-validation\u00b6","text":"<p>We search over MF count, MF type, and epochs. Metric: mean validation R\u00b2.</p>"},{"location":"examples/advanced_example/#5-train-final-model-with-best-config-and-evaluate-on-hold-out","title":"5) Train final model with best config and evaluate on hold-out\u00b6","text":""},{"location":"examples/advanced_example/#training-curve-loss-vs-epoch","title":"Training curve (loss vs. epoch)\u00b6","text":""},{"location":"examples/advanced_example/#parity-plot-y-true-vs-y-pred-on-test-set","title":"Parity plot (y true vs. y pred) on test set\u00b6","text":""},{"location":"examples/advanced_example/#residuals-histogram-test-set","title":"Residuals histogram (test set)\u00b6","text":""},{"location":"examples/advanced_example/#6-2d-prediction-surface-slice","title":"6) 2D prediction surface (slice)\u00b6","text":"<p>We fix one feature at its median (from train set) and visualize predictions over a grid for the other two features.</p>"},{"location":"examples/basic_example/","title":"Basic Usage","text":"<p>We import NumPy and helper utilities from ANFIS-Toolbox, then generate a simple noisy sine dataset for regression:</p> <ul> <li>Inputs <code>X</code> are evenly spaced in [-\u03c0, \u03c0].</li> <li>Targets <code>y</code> follow <code>sin(x)</code> with Gaussian noise. This small problem is ideal to showcase ANFIS function approximation.</li> </ul> In\u00a0[18]: Copied! <pre>import numpy as np\n\nnp.random.seed(42)  # For reproducibility\n\nn = 200\nX = np.linspace(-np.pi, np.pi, n).reshape(-1, 1)\ny = np.sin(X[:, 0]) + 0.2 * np.random.randn(n)\ny = y.reshape(-1, 1)\n</pre> import numpy as np  np.random.seed(42)  # For reproducibility  n = 200 X = np.linspace(-np.pi, np.pi, n).reshape(-1, 1) y = np.sin(X[:, 0]) + 0.2 * np.random.randn(n) y = y.reshape(-1, 1) In\u00a0[19]: Copied! <pre>from anfis_toolbox import QuickANFIS, quick_evaluate\n\n# Build ANFIS model with Gaussian MFs (FCM init for centers)\nmodel = QuickANFIS.for_regression(X, random_state=42)\nlosses = model.fit(X, y)\nmetrics = quick_evaluate(model, X, y)\n</pre> from anfis_toolbox import QuickANFIS, quick_evaluate  # Build ANFIS model with Gaussian MFs (FCM init for centers) model = QuickANFIS.for_regression(X, random_state=42) losses = model.fit(X, y) metrics = quick_evaluate(model, X, y) <pre>==================================================\nANFIS Model Evaluation Results\n==================================================\nMean Squared Error (MSE):     0.033254\nRoot Mean Squared Error:      0.182356\nMean Absolute Error (MAE):    0.145541\nR-squared (R\u00b2):               0.9402\nMean Abs. Percentage Error:   61.73%\nMaximum Error:                0.543382\nStandard Deviation of Error:  0.182356\n==================================================\n</pre> In\u00a0[20]: Copied! <pre>import matplotlib.pyplot as plt\n\ny_pred = model.predict(X)\n\nplt.scatter(X, y, s=20, alpha=0.2, label=\"y\")\nplt.plot(X, y_pred, label=\"ANFIS prediction\")\nplt.legend()\nplt.show()\n</pre> import matplotlib.pyplot as plt  y_pred = model.predict(X)  plt.scatter(X, y, s=20, alpha=0.2, label=\"y\") plt.plot(X, y_pred, label=\"ANFIS prediction\") plt.legend() plt.show()"},{"location":"examples/basic_example/#basic-usage","title":"Basic Usage\u00b6","text":""},{"location":"examples/basic_example/#1-imports-and-synthetic-dataset","title":"1) Imports and synthetic dataset\u00b6","text":""},{"location":"examples/basic_example/#2-build-train-and-evaluate-anfis","title":"2) Build, train, and evaluate ANFIS\u00b6","text":"<p>We create a quick ANFIS model for regression using Gaussian membership functions. Then we:</p> <ul> <li>train with the default Hybrid trainer via <code>fit</code>,</li> <li>compute metrics with <code>quick_evaluate</code>, and</li> <li>keep the loss history to inspect training behavior.</li> </ul>"},{"location":"examples/basic_example/#3-quick-visualization-with-matplotlib","title":"3) Quick visualization with Matplotlib\u00b6","text":"<p>We compare the ground truth samples against the ANFIS prediction curve:</p> <ul> <li>The scatter shows noisy <code>y</code> values.</li> <li>The line is the model\u2019s prediction <code>y_pred = model.predict(X)</code>. This gives a fast sense of fit quality.</li> </ul>"},{"location":"examples/intermediate_example/","title":"Basic: Exploring QuickANFIS Options","text":"In\u00a0[19]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom anfis_toolbox import QuickANFIS, quick_evaluate\nfrom anfis_toolbox.optim import SGDTrainer\n\nnp.random.seed(42)  # For reproducibility\n</pre> import matplotlib.pyplot as plt import numpy as np  from anfis_toolbox import QuickANFIS, quick_evaluate from anfis_toolbox.optim import SGDTrainer  np.random.seed(42)  # For reproducibility In\u00a0[20]: Copied! <pre>n = 300\nX1 = np.random.uniform(-3, 3, size=n)\nX2 = np.random.uniform(-2, 2, size=n)\nX = np.column_stack([X1, X2])\ny = np.sin(X1) + 0.3 * (X2 ** 2) + 0.1 * np.random.randn(n)\ny = y.reshape(-1, 1)\nX.shape, y.shape\n</pre> n = 300 X1 = np.random.uniform(-3, 3, size=n) X2 = np.random.uniform(-2, 2, size=n) X = np.column_stack([X1, X2]) y = np.sin(X1) + 0.3 * (X2 ** 2) + 0.1 * np.random.randn(n) y = y.reshape(-1, 1) X.shape, y.shape Out[20]: <pre>((300, 2), (300, 1))</pre> In\u00a0[\u00a0]: Copied! <pre>model = QuickANFIS.for_regression(\n    X,\n    n_mfs=3,\n    mf_type=\"gaussian\",\n    init=\"grid\"\n)\nlosses = model.fit(X, y, epochs=80, learning_rate=0.02, verbose=False)\nmetrics = quick_evaluate(model, X, y, print_results=True)\n</pre> model = QuickANFIS.for_regression(     X,     n_mfs=3,     mf_type=\"gaussian\",     init=\"grid\" ) losses = model.fit(X, y, epochs=80, learning_rate=0.02, verbose=False) metrics = quick_evaluate(model, X, y, print_results=True) <pre>==================================================\nANFIS Model Evaluation Results\n==================================================\nMean Squared Error (MSE):     0.009289\nRoot Mean Squared Error:      0.096377\nMean Absolute Error (MAE):    0.077391\nR-squared (R\u00b2):               0.9861\nMean Abs. Percentage Error:   55.15%\nMaximum Error:                0.296354\nStandard Deviation of Error:  0.096377\n==================================================\n</pre> In\u00a0[29]: Copied! <pre>mf_types = [\"gaussian\", \"triangular\", \"bell\", \"sigmoidal\"]\nresults_mf = {}\nfor mft in mf_types:\n    m = QuickANFIS.for_regression(X, n_mfs=3, mf_type=mft, init=\"grid\")\n    ls = m.fit(X, y, epochs=60, learning_rate=0.02, verbose=False)\n    results_mf[mft] = float(ls[-1])\n    print(f\"MF type: {mft}, final training loss: {ls[-1]:.4f}\")\n</pre> mf_types = [\"gaussian\", \"triangular\", \"bell\", \"sigmoidal\"] results_mf = {} for mft in mf_types:     m = QuickANFIS.for_regression(X, n_mfs=3, mf_type=mft, init=\"grid\")     ls = m.fit(X, y, epochs=60, learning_rate=0.02, verbose=False)     results_mf[mft] = float(ls[-1])     print(f\"MF type: {mft}, final training loss: {ls[-1]:.4f}\") <pre>MF type: gaussian, final training loss: 0.0093\nMF type: triangular, final training loss: 0.0119\nMF type: triangular, final training loss: 0.0119\nMF type: bell, final training loss: 0.0092\nMF type: bell, final training loss: 0.0092\nMF type: sigmoidal, final training loss: 0.0093\nMF type: sigmoidal, final training loss: 0.0093\n</pre> In\u00a0[\u00a0]: Copied! <pre># Compare grid vs fcm for the same MF type\nm_grid = QuickANFIS.for_regression(\n    X,\n    n_mfs=5,\n    mf_type=\"gaussian\",\n    init=\"grid\"\n)\nloss_grid = m_grid.fit(\n    X,\n    y,\n    epochs=60,\n    learning_rate=0.02,\n    verbose=False\n)[-1]\n\nm_fcm = QuickANFIS.for_regression(\n    X,\n    n_mfs=5,\n    mf_type=\"gaussian\",\n    init=\"fcm\",\n    random_state=42\n)\nloss_fcm = m_fcm.fit(\n    X,\n    y,\n    epochs=60,\n    learning_rate=0.02,\n    verbose=False\n)[-1]\n\nprint(f\"Final training loss (grid init): {loss_grid:.4f}\")\nprint(f\"Final training loss (fcm init): {loss_fcm:.4f}\")\n</pre> # Compare grid vs fcm for the same MF type m_grid = QuickANFIS.for_regression(     X,     n_mfs=5,     mf_type=\"gaussian\",     init=\"grid\" ) loss_grid = m_grid.fit(     X,     y,     epochs=60,     learning_rate=0.02,     verbose=False )[-1]  m_fcm = QuickANFIS.for_regression(     X,     n_mfs=5,     mf_type=\"gaussian\",     init=\"fcm\",     random_state=42 ) loss_fcm = m_fcm.fit(     X,     y,     epochs=60,     learning_rate=0.02,     verbose=False )[-1]  print(f\"Final training loss (grid init): {loss_grid:.4f}\") print(f\"Final training loss (fcm init): {loss_fcm:.4f}\") <pre>Final training loss (grid init): 0.0082\nFinal training loss (fcm init): 0.0095\n</pre> In\u00a0[31]: Copied! <pre>nmfs_list = [2, 3, 5, 7]\nresults_nmfs = {}\nfor k in nmfs_list:\n    m = QuickANFIS.for_regression(X, n_mfs=k, mf_type=\"gaussian\", init=\"fcm\", random_state=42)\n    ls = m.fit(X, y, epochs=60, learning_rate=0.02, verbose=False)\n    results_nmfs[k] = float(ls[-1])\n    print(f\"n_mfs: {k}, final training loss: {ls[-1]:.4f}\")\n</pre> nmfs_list = [2, 3, 5, 7] results_nmfs = {} for k in nmfs_list:     m = QuickANFIS.for_regression(X, n_mfs=k, mf_type=\"gaussian\", init=\"fcm\", random_state=42)     ls = m.fit(X, y, epochs=60, learning_rate=0.02, verbose=False)     results_nmfs[k] = float(ls[-1])     print(f\"n_mfs: {k}, final training loss: {ls[-1]:.4f}\") <pre>n_mfs: 2, final training loss: 0.0481\nn_mfs: 3, final training loss: 0.0192\nn_mfs: 3, final training loss: 0.0192\nn_mfs: 5, final training loss: 0.0095\nn_mfs: 5, final training loss: 0.0095\nn_mfs: 7, final training loss: 0.0054\nn_mfs: 7, final training loss: 0.0054\n</pre> In\u00a0[32]: Copied! <pre># Deterministic FCM init\nm1 = QuickANFIS.for_regression(X, n_mfs=4, mf_type=\"bell\", init=\"fcm\", random_state=123)\nloss1 = m1.fit(X, y, epochs=40, learning_rate=0.02, verbose=False)[-1]\n\nm2 = QuickANFIS.for_regression(X, n_mfs=4, mf_type=\"bell\", init=\"fcm\", random_state=123)\nloss2 = m2.fit(X, y, epochs=40, learning_rate=0.02, verbose=False)[-1]\n\n# Explicit SGD trainer\nsgd = SGDTrainer(learning_rate=0.02, epochs=40, batch_size=32, shuffle=True, verbose=False)\nm_sgd = QuickANFIS.for_regression(X, n_mfs=4, mf_type=\"bell\", init=\"fcm\", random_state=123)\nloss_sgd = m_sgd.fit(X, y, trainer=sgd)[-1]\n\n# Simple parity plot for the last model\ny_pred = m_sgd.predict(X)\nplt.scatter(y, y_pred, s=8, alpha=0.5)\nmn, mx = float(np.min(y)), float(np.max(y))\nplt.plot([mn, mx], [mn, mx], \"r--\", lw=2)\nplt.xlabel(\"y true\")\nplt.ylabel(\"y pred\")\nplt.title(\"Parity plot (SGD-trained)\")\nplt.tight_layout()\nplt.show()\n\nprint(f\"Final training loss (deterministic FCM init): {loss1:.4f}\")\nprint(f\"Final training loss (SGD trainer): {loss_sgd:.4f}\")\n</pre> # Deterministic FCM init m1 = QuickANFIS.for_regression(X, n_mfs=4, mf_type=\"bell\", init=\"fcm\", random_state=123) loss1 = m1.fit(X, y, epochs=40, learning_rate=0.02, verbose=False)[-1]  m2 = QuickANFIS.for_regression(X, n_mfs=4, mf_type=\"bell\", init=\"fcm\", random_state=123) loss2 = m2.fit(X, y, epochs=40, learning_rate=0.02, verbose=False)[-1]  # Explicit SGD trainer sgd = SGDTrainer(learning_rate=0.02, epochs=40, batch_size=32, shuffle=True, verbose=False) m_sgd = QuickANFIS.for_regression(X, n_mfs=4, mf_type=\"bell\", init=\"fcm\", random_state=123) loss_sgd = m_sgd.fit(X, y, trainer=sgd)[-1]  # Simple parity plot for the last model y_pred = m_sgd.predict(X) plt.scatter(y, y_pred, s=8, alpha=0.5) mn, mx = float(np.min(y)), float(np.max(y)) plt.plot([mn, mx], [mn, mx], \"r--\", lw=2) plt.xlabel(\"y true\") plt.ylabel(\"y pred\") plt.title(\"Parity plot (SGD-trained)\") plt.tight_layout() plt.show()  print(f\"Final training loss (deterministic FCM init): {loss1:.4f}\") print(f\"Final training loss (SGD trainer): {loss_sgd:.4f}\") <pre>Final training loss (deterministic FCM init): 0.0124\nFinal training loss (SGD trainer): 0.1083\n</pre>"},{"location":"examples/intermediate_example/#basic-exploring-quickanfis-options","title":"Basic: Exploring QuickANFIS Options\u00b6","text":"<p>This notebook shows how to use <code>QuickANFIS</code> effectively: selecting membership function types, choosing initialization (grid vs FCM), controlling the number of MFs, using <code>random_state</code> for determinism, and the alternative <code>for_function_approximation</code> helper.</p>"},{"location":"examples/intermediate_example/#1-imports-and-setup","title":"1) Imports and setup\u00b6","text":"<p>We'll import <code>QuickANFIS</code> and helpers. We'll also set a random seed for reproducibility.</p>"},{"location":"examples/intermediate_example/#2-create-a-small-2d-regression-dataset","title":"2) Create a small 2D regression dataset\u00b6","text":"<p>We'll reuse this dataset to compare QuickANFIS options.</p>"},{"location":"examples/intermediate_example/#3-quick-start-defaults-gaussian-mfs-grid-init","title":"3) Quick start: defaults (gaussian MFs, grid init)\u00b6","text":"<p><code>QuickANFIS.for_regression</code> infers input ranges from data, distributes MFs on a grid, and uses Gaussian MFs by default. Training via <code>model.fit</code> uses the Hybrid trainer by default.</p>"},{"location":"examples/intermediate_example/#4-choosing-membership-function-type-mf_type","title":"4) Choosing membership function type (<code>mf_type</code>)\u00b6","text":"<p><code>mf_type</code> controls the shape family used for all inputs. Supported types include: <code>gaussian</code>, <code>triangular</code>, <code>trapezoidal</code>, <code>bell</code> (aka <code>gbell</code>), <code>sigmoidal</code> (aka <code>sigmoid</code>), <code>sshape</code> (aka <code>s</code>), <code>zshape</code> (aka <code>z</code>), and <code>pi</code> (aka <code>pimf</code>). We'll compare a few quickly.</p>"},{"location":"examples/intermediate_example/#5-initialization-initgrid-vs-initfcm","title":"5) Initialization: <code>init=\"grid\"</code> vs <code>init=\"fcm\"</code>\u00b6","text":"<ul> <li>Grid: places MFs evenly across observed range (with small margins).</li> <li>FCM: uses Fuzzy C-Means on each input column to set centers and widths; supports all MF families used above.</li> </ul>"},{"location":"examples/intermediate_example/#6-number-of-mfs-per-input-n_mfs","title":"6) Number of MFs per input (<code>n_mfs</code>)\u00b6","text":"<p>Increasing <code>n_mfs</code> adds rules and capacity. More isn't always better\u2014watch for overfitting and compute cost.</p>"},{"location":"examples/intermediate_example/#7-determinism-and-alternative-trainer","title":"7) Determinism and alternative trainer\u00b6","text":"<ul> <li>Use <code>random_state</code> with <code>init=\"fcm\"</code> to get repeatable MF initialization.</li> <li>You can also pass a trainer explicitly to <code>fit</code>, e.g., <code>SGDTrainer</code> for pure backprop.</li> </ul>"},{"location":"examples/intermediate_example/#tips-next-steps","title":"Tips &amp; Next steps\u00b6","text":"<ul> <li>Start with <code>mf_type=\"gaussian\"</code> and <code>init=\"fcm\"</code> for robust baselines.</li> <li>Sweep <code>n_mfs</code> to balance fit quality and complexity; monitor R\u00b2 or validation MSE.</li> <li>Try different MF families (<code>triangular</code>, <code>bell</code>, <code>pi</code>) when residuals show shape mismatches.</li> <li>For larger problems or streaming data, use <code>SGDTrainer</code> with mini-batches.</li> <li>For function approximation on known ranges, use <code>QuickANFIS.for_function_approximation([(min,max), ...])</code>.</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>ANFIS Toolbox is available on PyPI and can be installed with <code>pip</code>. Choose the installation method that best fits your needs.</p>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.9+</li> <li>Operating System: Windows, macOS, Linux</li> <li>Memory: 4GB RAM minimum (8GB+ recommended for large models)</li> <li>Dependencies: NumPy (required), SciPy (required)</li> </ul>"},{"location":"getting-started/installation/#installation-options","title":"Installation Options","text":""},{"location":"getting-started/installation/#basic-installation","title":"Basic Installation","text":"<p>The core package with minimal dependencies:</p> <pre><code>pip install anfis-toolbox\n</code></pre> <p>This gives you:</p> <ul> <li>\u2705 Core ANFIS functionality</li> <li>\u2705 All 6 membership functions</li> <li>\u2705 Hybrid and backpropagation training</li> <li>\u2705 Model persistence and configuration</li> <li>\u2705 Basic utilities</li> </ul> <p>Dependencies: <code>numpy</code></p>"},{"location":"getting-started/installation/#full-installation-recommended","title":"Full Installation (Recommended)","text":"<p>Install with all optional features:</p> <pre><code>pip install anfis-toolbox[all]\n</code></pre> <p>This includes everything from the basic installation plus:</p> <ul> <li>\u2705 Visualization: Membership functions, training curves, predictions</li> <li>\u2705 Validation: Cross-validation, metrics, model comparison</li> <li>\u2705 Examples: Complete example datasets and notebooks</li> </ul> <p>Additional Dependencies: <code>matplotlib</code></p>"},{"location":"getting-started/installation/#feature-specific-installation","title":"Feature-Specific Installation","text":"<p>Install only the features you need:</p>"},{"location":"getting-started/installation/#visualization-features","title":"Visualization Features","text":"<pre><code>pip install anfis-toolbox[visualization]\n</code></pre> <p>Adds: <code>matplotlib</code> for plotting capabilities</p> <ul> <li><code>ANFISVisualizer</code> class</li> <li><code>plot_membership_functions()</code></li> <li><code>plot_training_curves()</code></li> <li><code>plot_prediction_vs_target()</code></li> </ul> <p>Validation features are now built-in and do not require scikit-learn. You can still install scikit-learn optionally; if present, compatible utilities will delegate to it.</p>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>For contributing to the project:</p> <pre><code>git clone https://github.com/dcruzf/anfis-toolbox.git\ncd anfis-toolbox\npip install -e .[all,dev]\n</code></pre> <p>This includes all features plus development tools:</p> <ul> <li><code>pytest</code> for testing</li> <li><code>ruff</code> for linting and formatting</li> <li><code>mypy</code> for type checking</li> <li><code>mkdocs</code> for documentation</li> </ul>"},{"location":"getting-started/installation/#upgrading","title":"Upgrading","text":"<p>To upgrade to the latest version:</p> <pre><code>pip install --upgrade anfis-toolbox\n</code></pre> <p>To upgrade with all features:</p> <pre><code>pip install --upgrade anfis-toolbox[all]\n</code></pre>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>Verify your installation works correctly:</p> <pre><code>import anfis_toolbox as anfis\nimport numpy as np\n\nprint(f\"ANFIS Toolbox version: {anfis.__version__}\")\n\n# Test basic functionality\nX = np.random.uniform(-1, 1, (50, 2))\ny = X[:, 0]**2 + X[:, 1]**2\n\nmodel = anfis.QuickANFIS.for_regression(X, n_mfs=2)\nlosses = model.fit_hybrid(X, y, epochs=10)\n\nprint(\"\u2705 Installation successful!\")\nprint(f\"Final training loss: {losses[-1]:.4f}\")\n</code></pre> <p>Expected output: <pre><code>ANFIS Toolbox version: 1.0.0\n\u2705 Installation successful!\nFinal training loss: 0.0234\n</code></pre></p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/installation/#import-error-no-module-named-sklearn","title":"Import Error: No module named 'sklearn'","text":"<p>Validation no longer requires scikit-learn. If you want to use scikit-learn alongside, install it with:</p> <pre><code>pip install scikit-learn\n</code></pre>"},{"location":"getting-started/installation/#import-error-no-module-named-matplotlib","title":"Import Error: No module named 'matplotlib'","text":"<p>If you get this error when using visualization:</p> <pre><code>pip install anfis-toolbox[visualization]\n# or\npip install matplotlib\n</code></pre>"},{"location":"getting-started/installation/#slow-training-performance","title":"Slow Training Performance","text":"<p>For better performance with large models:</p> <pre><code># Install optimized NumPy (if available)\npip install numpy[mkl]\n\n# Or consider switching to conda\nconda install numpy matplotlib scikit-learn\npip install anfis-toolbox\n</code></pre>"},{"location":"getting-started/installation/#memory-issues","title":"Memory Issues","text":"<p>For large datasets or models:</p> <ol> <li>Reduce batch size in training</li> <li>Use fewer membership functions</li> <li>Consider data preprocessing (normalization, dimensionality reduction)</li> </ol>"},{"location":"getting-started/installation/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"getting-started/installation/#windows","title":"Windows","text":"<p>No additional requirements. Make sure you have a recent Python version.</p>"},{"location":"getting-started/installation/#macos","title":"macOS","text":"<p>If you encounter compilation issues:</p> <pre><code># Install Xcode command line tools\nxcode-select --install\n\n# Then retry installation\npip install anfis-toolbox[all]\n</code></pre>"},{"location":"getting-started/installation/#linux","title":"Linux","text":"<p>Most distributions work out-of-the-box. For older systems:</p> <pre><code># Update system packages first\nsudo apt update &amp;&amp; sudo apt upgrade\n\n# Install Python development headers (Ubuntu/Debian)\nsudo apt install python3-dev\n\n# Install Python development headers (CentOS/RHEL)\nsudo yum install python3-devel\n</code></pre>"},{"location":"getting-started/installation/#alternative-installation-methods","title":"Alternative Installation Methods","text":""},{"location":"getting-started/installation/#using-conda","title":"Using conda","text":"<p>While not officially distributed on conda-forge yet, you can still use conda for dependency management:</p> <pre><code># Create environment\nconda create -n anfis python=3.11\nconda activate anfis\n\n# Install dependencies via conda\nconda install numpy scipy matplotlib scikit-learn\n\n# Install ANFIS Toolbox via pip\npip install anfis-toolbox\n</code></pre>"},{"location":"getting-started/installation/#using-poetry","title":"Using Poetry","text":"<p>If you're using Poetry for dependency management:</p> <pre><code>[tool.poetry.dependencies]\npython = \"^3.9\"\nanfis-toolbox = {extras = [\"all\"], version = \"^1.0.0\"}\n</code></pre> <p>Then run: <pre><code>poetry install\n</code></pre></p>"},{"location":"getting-started/installation/#using-docker","title":"Using Docker","text":"<p>A Docker image with everything pre-installed:</p> <pre><code>docker pull dcruzf/anfis-toolbox:latest\ndocker run -it --rm -v $(pwd):/workspace dcruzf/anfis-toolbox:latest\n</code></pre>"},{"location":"getting-started/installation/#whats-next","title":"What's Next?","text":"<p>Now that you have ANFIS Toolbox installed, check out:</p> <ul> <li>\ud83d\ude80 Quick Start - Build your first model in 5 minutes</li> <li>\ud83d\udcd6 Basic Tutorial - Learn the fundamentals</li> <li>\ud83d\udca1 Examples - See practical applications</li> </ul> <p>Having installation issues? Open an issue and we'll help you get started!</p>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get up and running with ANFIS Toolbox in just 5 minutes! This tutorial will walk you through creating your first neuro-fuzzy model.</p>"},{"location":"getting-started/quickstart/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this tutorial, you'll know how to:</p> <ul> <li>\u2705 Load or generate data for training</li> <li>\u2705 Create an ANFIS model with one line of code</li> <li>\u2705 Train the model using hybrid learning</li> <li>\u2705 Make predictions and evaluate performance</li> <li>\u2705 Visualize results and membership functions</li> </ul>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<p>Make sure you have ANFIS Toolbox installed:</p> <pre><code>pip install anfis-toolbox[all]\n</code></pre>"},{"location":"getting-started/quickstart/#your-first-anfis-model","title":"Your First ANFIS Model","text":"<p>Let's create a model to approximate the function <code>f(x, y) = x\u00b2 + y\u00b2</code>:</p>"},{"location":"getting-started/quickstart/#step-1-import-and-prepare-data","title":"Step 1: Import and Prepare Data","text":"<pre><code>import numpy as np\nfrom anfis_toolbox import QuickANFIS, quick_evaluate\n\n# Generate training data\nnp.random.seed(42)  # For reproducible results\nn_samples = 200\n\n# Create 2D input space: x and y from -2 to 2\nX = np.random.uniform(-2, 2, (n_samples, 2))\n\n# Target function: f(x, y) = x\u00b2 + y\u00b2\ny = X[:, 0]**2 + X[:, 1]**2\n\n# Add some noise to make it realistic\ny += np.random.normal(0, 0.1, n_samples)\n\nprint(f\"Training data shape: X={X.shape}, y={y.shape}\")\nprint(f\"Input range: [{X.min():.2f}, {X.max():.2f}]\")\nprint(f\"Output range: [{y.min():.2f}, {y.max():.2f}]\")\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-create-the-model","title":"Step 2: Create the Model","text":"<pre><code># Create ANFIS model with QuickANFIS (one line!)\nmodel = QuickANFIS.for_regression(\n    X=X,\n    n_mfs=3,  # 3 membership functions per input\n    mf_type='gaussian'  # Gaussian membership functions\n)\n\nprint(f\"Model created with {model.n_rules} rules\")\nprint(f\"Total parameters: {len(model.get_parameters())}\")\n</code></pre>"},{"location":"getting-started/quickstart/#step-3-train-the-model","title":"Step 3: Train the Model","text":"<pre><code># Train using hybrid learning (LSE + backpropagation)\nprint(\"Training model...\")\nlosses = model.fit_hybrid(\n    X=X,\n    y=y,\n    epochs=100,\n    learning_rate=0.01,\n    verbose=True\n)\n\nprint(f\"\u2705 Training complete!\")\nprint(f\"Initial loss: {losses[0]:.4f}\")\nprint(f\"Final loss: {losses[-1]:.4f}\")\nprint(f\"Improvement: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%\")\n</code></pre>"},{"location":"getting-started/quickstart/#step-4-evaluate-performance","title":"Step 4: Evaluate Performance","text":"<pre><code># Quick evaluation with common metrics\nmetrics = quick_evaluate(model, X, y)\n\nprint(\"\\n\ud83d\udcca Model Performance:\")\nprint(f\"R\u00b2 Score: {metrics['r2']:.4f}\")\nprint(f\"MAE: {metrics['mae']:.4f}\")\nprint(f\"RMSE: {metrics['rmse']:.4f}\")\nprint(f\"MAPE: {metrics['mape']:.2f}%\")\n</code></pre>"},{"location":"getting-started/quickstart/#step-5-make-predictions","title":"Step 5: Make Predictions","text":"<pre><code># Test on new data points\ntest_points = np.array([\n    [1.0, 1.0],    # Should predict ~2.0\n    [0.0, 0.0],    # Should predict ~0.0\n    [-1.5, 0.5],   # Should predict ~2.5\n    [2.0, -2.0]    # Should predict ~8.0\n])\n\npredictions = model.predict(test_points)\n\nprint(\"\\n\ud83c\udfaf Predictions vs Expected:\")\nfor i, (point, pred) in enumerate(zip(test_points, predictions)):\n    expected = point[0]**2 + point[1]**2\n    error = abs(pred - expected)\n    print(f\"Point {point}: predicted={pred:.3f}, expected={expected:.3f}, error={error:.3f}\")\n</code></pre>"},{"location":"getting-started/quickstart/#step-6-visualize-results-optional","title":"Step 6: Visualize Results (Optional)","text":"<p>If you installed with visualization features:</p> <pre><code>from anfis_toolbox import ANFISVisualizer\n\n# Create visualizer\nviz = ANFISVisualizer(model)\n\n# Plot membership functions for each input\nviz.plot_membership_functions()\n\n# Plot training progress\nviz.plot_training_curves(losses)\n\n# Plot predictions vs targets\nviz.plot_prediction_vs_target(X, y)\n\nprint(\"\ud83d\udcc8 Plots displayed! Check the figures.\")\n</code></pre>"},{"location":"getting-started/quickstart/#complete-example","title":"Complete Example","text":"<p>Here's the complete working example:</p> <pre><code>import numpy as np\nfrom anfis_toolbox import QuickANFIS, quick_evaluate\n\n# 1. Generate data\nnp.random.seed(42)\nX = np.random.uniform(-2, 2, (200, 2))\ny = X[:, 0]**2 + X[:, 1]**2 + np.random.normal(0, 0.1, 200)\n\n# 2. Create and train model\nmodel = QuickANFIS.for_regression(X, n_mfs=3)\nlosses = model.fit_hybrid(X, y, epochs=100)\n\n# 3. Evaluate\nmetrics = quick_evaluate(model, X, y)\nprint(f\"R\u00b2 Score: {metrics['r2']:.4f}\")\n\n# 4. Predict\npredictions = model.predict([[1.0, 1.0], [0.0, 0.0]])\nprint(f\"Predictions: {predictions}\")\n\n# 5. Visualize (if matplotlib available)\ntry:\n    from anfis_toolbox import ANFISVisualizer\n    viz = ANFISVisualizer(model)\n    viz.plot_membership_functions()\nexcept ImportError:\n    print(\"Install matplotlib for visualization: pip install anfis-toolbox[visualization]\")\n</code></pre> <p>Expected output: <pre><code>R\u00b2 Score: 0.9876\nPredictions: [1.987 0.023]\n</code></pre></p>"},{"location":"getting-started/quickstart/#understanding-the-results","title":"Understanding the Results","text":""},{"location":"getting-started/quickstart/#training-loss-curve","title":"Training Loss Curve","text":"<p>A good ANFIS model should show: - Decreasing loss: Steady improvement over epochs - Convergence: Loss stabilizes after some epochs - No overfitting: Validation loss (if used) follows training loss</p>"},{"location":"getting-started/quickstart/#performance-metrics","title":"Performance Metrics","text":"<ul> <li>R\u00b2 Score: Closer to 1.0 is better (0.95+ is excellent)</li> <li>MAE: Mean Absolute Error - lower is better</li> <li>RMSE: Root Mean Square Error - penalizes large errors</li> <li>MAPE: Mean Absolute Percentage Error - good for comparing across scales</li> </ul>"},{"location":"getting-started/quickstart/#membership-functions","title":"Membership Functions","text":"<p>After training, the membership functions adapt to the data: - Centers shift to important regions - Widths adjust for optimal coverage - Shapes optimize for the target function</p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>\ud83c\udf89 Congratulations! You've created your first ANFIS model. Now you can:</p>"},{"location":"getting-started/quickstart/#try-different-configurations","title":"Try Different Configurations","text":"<pre><code># Different membership function types\nmodel_bell = QuickANFIS.for_regression(X, n_mfs=4, mf_type='bell')\nmodel_triangular = QuickANFIS.for_regression(X, n_mfs=2, mf_type='triangular')\n\n# Different training methods\nlosses_bp = model.fit(X, y, epochs=50)  # Pure backpropagation\nlosses_hybrid = model.fit_hybrid(X, y, epochs=50)  # Hybrid (recommended)\n</code></pre>"},{"location":"getting-started/quickstart/#use-advanced-features","title":"Use Advanced Features","text":"<pre><code># Cross-validation\nfrom anfis_toolbox import ANFISValidator\n\nvalidator = ANFISValidator(model)\ncv_scores = validator.cross_validate(X, y, cv=5)\nprint(f\"CV R\u00b2: {cv_scores['r2_mean']:.3f} \u00b1 {cv_scores['r2_std']:.3f}\")\n\n# Learning curves\nlearning_data = validator.learning_curve(X, y, train_sizes=[0.2, 0.5, 0.8])\n</code></pre>"},{"location":"getting-started/quickstart/#save-and-load-models","title":"Save and Load Models","text":"<pre><code># Save trained model\nmodel.save('my_anfis_model.pkl')\n\n# Load later\nfrom anfis_toolbox import load_anfis\nloaded_model = load_anfis('my_anfis_model.pkl')\n</code></pre>"},{"location":"getting-started/quickstart/#common-issues-solutions","title":"Common Issues &amp; Solutions","text":""},{"location":"getting-started/quickstart/#training-loss-not-decreasing","title":"\"Training loss not decreasing\"","text":"<ul> <li>Try different learning rates: <code>0.001</code>, <code>0.01</code>, <code>0.1</code></li> <li>Reduce number of membership functions</li> <li>Check if data is normalized</li> <li>Use hybrid learning instead of pure backpropagation</li> </ul>"},{"location":"getting-started/quickstart/#poor-prediction-accuracy","title":"\"Poor prediction accuracy\"","text":"<ul> <li>Increase number of membership functions</li> <li>Try different MF types (<code>'gaussian'</code>, <code>'bell'</code>, <code>'triangular'</code>)</li> <li>Check for sufficient training data</li> <li>Consider data preprocessing (normalization, feature engineering)</li> </ul>"},{"location":"getting-started/quickstart/#training-too-slow","title":"\"Training too slow\"","text":"<ul> <li>Reduce number of epochs or membership functions</li> <li>Use smaller datasets for initial testing</li> <li>Consider using pure analytical methods for simple problems</li> </ul>"},{"location":"getting-started/quickstart/#whats-next","title":"What's Next?","text":"<p>Now that you've mastered the basics, explore:</p> <ul> <li>\ud83d\udcda User Guide - Deep dive into ANFIS theory and advanced usage</li> <li>\ud83d\udca1 Examples - Real-world applications and use cases</li> <li>\ud83d\udd27 API Reference - Complete documentation of all classes and methods</li> <li>\ud83c\udfaf Advanced Tutorial - Custom membership functions, manual model building</li> </ul> <p>Ready to build more sophisticated models? Continue with the User Guide \u2192</p>"},{"location":"hooks/test_hook/","title":"Test hook","text":"In\u00a0[\u00a0]: Copied! <pre>def on_post_page(output, page, config):\n    path = str(page.file.src_uri)\n    if not path.endswith(\".ipynb\"):\n        return output\n\n    output = output.replace(\n        \"\"\"&lt;div class=\"highlight-ipynb hl-python\"&gt;\"\"\",\n        \"\"\"&lt;div class=\"language-python highlight\"&gt;\"\"\"\n        )\n\n    return output\n</pre> def on_post_page(output, page, config):     path = str(page.file.src_uri)     if not path.endswith(\".ipynb\"):         return output      output = output.replace(         \"\"\"\"\"\",         \"\"\"\"\"\"         )      return output"},{"location":"membership_functions/01_gaussianmf/","title":"Gaussian","text":"<p>The Gaussian membership function (GaussianMF) is a fundamental concept in fuzzy logic, widely used to define fuzzy sets. Unlike a classical set where an element either fully belongs or does not belong, a fuzzy set allows for partial membership, and the GaussianMF provides a smooth, continuous way to represent this degree of belonging. It possesses a smooth, bell-like shape, which contributes to its intuitive nature and popularity across various applications.</p> <p>The function is characterized by two main parameters:</p> <ul> <li>mean ($\\mu$): This parameter determines the center of the curve. It represents the point in the domain where the degree of membership is maximum, specifically 1.</li> <li>sigma ($\\sigma$): This parameter controls the width or spread of the curve. It must be a positive value. A larger $\\sigma$ results in a wider, flatter curve, indicating a broader range of values with high membership. Conversely, a smaller $\\sigma$ produces a sharper, more peaked curve, suggesting a narrower range of values with a high degree of belonging.</li> </ul> <p>The mathematical formula for the Gaussian membership function is given by:</p> <p>$$\\mu(x) = e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$</p> <p>where:</p> <ul> <li>$\\mu(x)$ is the degree of membership of element $x$ in the fuzzy set.</li> <li>$x$ is the input value.</li> <li>$\\mu$ is the mean of the curve.</li> <li>$\\sigma$ is the standard deviation (width) of the curve.</li> </ul> <p>The partial derivatives of the Gaussian membership function are crucial for optimization algorithms, especially in adaptive or machine learning-based fuzzy systems. They show how the membership value changes in response to small adjustments to the parameters, which is essential for training models to better fit data.</p> <p>The partial derivative of the function with respect to the mean ($\\mu$) is:</p> <p>$$\\frac{\\partial f}{\\partial \\mu} = \\frac{x-\\mu}{\\sigma^2} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$</p> <p>This derivative indicates how the membership value is affected when the center of the bell curve is shifted. It is used to adjust the position of the function to better align with the data.</p> <p>The partial derivative with respect to the standard deviation ($\\sigma$) is:</p> <p>$$\\frac{\\partial f}{\\partial \\sigma} = \\frac{(x-\\mu)^2}{\\sigma^3} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$</p> <p>This derivative shows how the membership value changes as the width of the curve is adjusted. It is used to refine the spread of the function, making it sharper or wider as needed to represent the uncertainty in the data more accurately.</p> In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom anfis_toolbox import GaussianMF\n\ngaussian = GaussianMF(5, 1)\n\nx = np.linspace(0, 10, 100)\ny = gaussian(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  from anfis_toolbox import GaussianMF  gaussian = GaussianMF(5, 1)  x = np.linspace(0, 10, 100) y = gaussian(x)  plt.plot(x, y) plt.show() <p>Below is a visual representation of a Gaussian membership function, showing how its shape is influenced by the mean $\\mu$ and sigma ($\\sigma$) parameters.</p> <p>The image displays a classic bell-shaped curve, illustrating how the membership value (on the y-axis) smoothly changes for different input values (on the x-axis). The peak of the curve is located at the mean, and the spread of the curve is controlled by sigma.</p>"},{"location":"membership_functions/01_gaussianmf/#gaussian","title":"Gaussian\u00b6","text":""},{"location":"membership_functions/01_gaussianmf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":""},{"location":"membership_functions/01_gaussianmf/#derivative-with-respect-to-mu","title":"Derivative with respect to $\\mu$\u00b6","text":""},{"location":"membership_functions/01_gaussianmf/#derivative-with-respect-to-sigma","title":"Derivative with respect to $\\sigma$\u00b6","text":""},{"location":"membership_functions/01_gaussianmf/#python-example","title":"Python Example\u00b6","text":""},{"location":"membership_functions/01_gaussianmf/#visualization","title":"Visualization\u00b6","text":""},{"location":"membership_functions/02_gaussian2mf/","title":"Gaussian Combination","text":"<p>The Gaussian combination membership function (Gaussian2MF) is a versatile fuzzy membership function that combines two Gaussian curves with an optional flat region in between. This function is particularly useful for representing fuzzy sets with asymmetric shapes or plateau regions, making it suitable for applications where the membership degree needs to be constant over a range of values.</p> <p>The function is characterized by four main parameters:</p> <ul> <li>sigma1 ($\\sigma_1$): Standard deviation of the left Gaussian tail (must be positive).</li> <li>c1 ($c_1$): Center of the left Gaussian tail.</li> <li>sigma2 ($\\sigma_2$): Standard deviation of the right Gaussian tail (must be positive).</li> <li>c2 ($c_2$): Center of the right Gaussian tail. Must satisfy $c_1 \\leq c_2$.</li> </ul> <p>The mathematical formula for the Gaussian combination membership function is defined piecewise:</p> <p>$$\\mu(x) =  \\begin{array}{ll}  e^{-\\frac{(x-c_1)^2}{2\\sigma_1^2}} &amp; x &lt; c_1 \\\\[6pt]  1 &amp; c_1 \\leq x \\leq c_2 \\\\[6pt]  e^{-\\frac{(x-c_2)^2}{2\\sigma_2^2}} &amp; x &gt; c_2  \\end{array}$$</p> <p>where:</p> <ul> <li>$\\mu(x)$ is the degree of membership of element $x$ in the fuzzy set.</li> <li>$x$ is the input value.</li> <li>$\\sigma_1, c_1$ define the left Gaussian tail.</li> <li>$\\sigma_2, c_2$ define the right Gaussian tail.</li> </ul> <p>When $c_1 = c_2$, the function becomes an asymmetric Gaussian centered at $c_1$ with different spreads on each side.</p> In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom anfis_toolbox.membership import Gaussian2MF\n\n\ngaussian2 = Gaussian2MF(sigma1=.5, c1=2, sigma2=1, c2=5)\n\nx = np.linspace(0, 10, 100)\ny = gaussian2(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  from anfis_toolbox.membership import Gaussian2MF   gaussian2 = Gaussian2MF(sigma1=.5, c1=2, sigma2=1, c2=5)  x = np.linspace(0, 10, 100) y = gaussian2(x)  plt.plot(x, y) plt.show() <p>The visualization above demonstrates various configurations of the Gaussian2MF. This flexibility makes Gaussian2MF suitable for modeling complex fuzzy concepts with asymmetric uncertainty or plateau regions where membership should remain constant.</p>"},{"location":"membership_functions/02_gaussian2mf/#gaussian-combination","title":"Gaussian Combination\u00b6","text":""},{"location":"membership_functions/02_gaussian2mf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":"<p>The partial derivatives of the Gaussian combination membership function are essential for optimization in adaptive fuzzy systems. Since the function is piecewise, derivatives are computed separately for each region.</p>"},{"location":"membership_functions/02_gaussian2mf/#derivative-with-respect-to-c_1","title":"Derivative with respect to $c_1$\u00b6","text":"<p>For $x &lt; c_1$: $$\\frac{\\partial \\mu}{\\partial c_1} = \\frac{x-c_1}{\\sigma_1^2} e^{-\\frac{(x-c_1)^2}{2\\sigma_1^2}}$$</p> <p>For $c_1 \\leq x \\leq c_2$: The derivative is 0 (flat region).</p> <p>For $x &gt; c_2$: The derivative is 0.</p>"},{"location":"membership_functions/02_gaussian2mf/#derivative-with-respect-to-sigma_1","title":"Derivative with respect to $\\sigma_1$\u00b6","text":"<p>For $x &lt; c_1$: $$\\frac{\\partial \\mu}{\\partial \\sigma_1} = \\frac{(x-c_1)^2}{\\sigma_1^3} e^{-\\frac{(x-c_1)^2}{2\\sigma_1^2}}$$</p> <p>For other regions: The derivative is 0.</p>"},{"location":"membership_functions/02_gaussian2mf/#derivative-with-respect-to-c_2","title":"Derivative with respect to $c_2$\u00b6","text":"<p>For $x &lt; c_1$: The derivative is 0.</p> <p>For $c_1 \\leq x \\leq c_2$: The derivative is 0.</p> <p>For $x &gt; c_2$: $$\\frac{\\partial \\mu}{\\partial c_2} = \\frac{x-c_2}{\\sigma_2^2} e^{-\\frac{(x-c_2)^2}{2\\sigma_2^2}}$$</p>"},{"location":"membership_functions/02_gaussian2mf/#derivative-with-respect-to-sigma_2","title":"Derivative with respect to $\\sigma_2$\u00b6","text":"<p>For $x &gt; c_2$: $$\\frac{\\partial \\mu}{\\partial \\sigma_2} = \\frac{(x-c_2)^2}{\\sigma_2^3} e^{-\\frac{(x-c_2)^2}{2\\sigma_2^2}}$$</p> <p>For other regions: The derivative is 0.</p> <p>These derivatives enable gradient-based optimization of the membership function parameters.</p>"},{"location":"membership_functions/02_gaussian2mf/#python-example","title":"Python Example\u00b6","text":""},{"location":"membership_functions/02_gaussian2mf/#visualization","title":"Visualization\u00b6","text":"<p>Below is a comprehensive visualization showing how the Gaussian2MF shape changes with different parameter combinations. We'll explore variations in the centers (c\u2081, c\u2082) and standard deviations (\u03c3\u2081, \u03c3\u2082).</p>"},{"location":"membership_functions/03_bellmf/","title":"Bell-shaped","text":"In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom anfis_toolbox import BellMF\n\nbellmf = BellMF(a=2, b=4, c=5)\n\nx = np.linspace(0, 10, 100)\ny = bellmf(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  from anfis_toolbox import BellMF  bellmf = BellMF(a=2, b=4, c=5)  x = np.linspace(0, 10, 100) y = bellmf(x)  plt.plot(x, y) plt.show() <p>The image displays a series of symmetrical bell-shaped curves. You can observe how increasing the width ($a$) makes the curve broader, while increasing the slope ($b$) makes the sides of the curve steeper.</p>"},{"location":"membership_functions/03_bellmf/#bell-shaped","title":"Bell-shaped\u00b6","text":"<p>The Generalized Bell membership function (BellMF), also known as the Bell-shaped curve, is a versatile function used in fuzzy logic to define fuzzy sets. Like other membership functions, it assigns a degree of membership to an element, but it offers greater flexibility than the GaussianMF by using an additional parameter to control its shape. Its form is a smooth, symmetrical bell curve.</p> <p>The function is defined by three parameters:</p> <ul> <li>center ($c$): This parameter determines the center of the curve, representing the point in the domain with a maximum membership value of 1.</li> <li>width ($a$): This parameter controls the width or spread of the curve. A larger value of $a$ results in a wider curve, while a smaller value produces a narrower curve.</li> <li>slope ($b$): This parameter, which must be a positive value, determines the slope of the curve's sides. It directly impacts the steepness of the curve's transition from 0 to 1. A larger $b$ value creates a steeper curve, making the fuzzy set sharper and less \"fuzzy.\"</li> </ul> <p>The mathematical formula for the Generalized Bell membership function is given by:</p> <p>$$\\mu(x) = \\frac{1}{1 + \\left|\\frac{x-c}{a}\\right|^{2b}}$$</p> <p>where:</p> <ul> <li>$\\mu(x)$ is the degree of membership of element $x$ in the fuzzy set.</li> <li>$x$ is the input value.</li> <li>$c$ is the center of the curve.</li> <li>$a$ is the width of the curve.</li> <li>$b$ is the slope of the curve.</li> </ul>"},{"location":"membership_functions/03_bellmf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":"<p>The partial derivatives of the GbellMF are essential for training and optimizing fuzzy systems. They show how the membership value changes with respect to small changes in each of the three parameters, which is vital for algorithms like backpropagation used in fuzzy-neural networks.</p>"},{"location":"membership_functions/03_bellmf/#derivative-with-respect-to-the-center-c","title":"Derivative with respect to the center ($c$)\u00b6","text":"<p>The partial derivative of the function with respect to its center ($c$) is:</p> <p>$$\\frac{\\partial f}{\\partial c} = \\frac{2b(x-c)}{a^2} \\left(1 + \\left|\\frac{x-c}{a}\\right|^{2b}\\right)^{-2}$$</p> <p>This derivative indicates how the membership value changes when the curve is shifted along the x-axis.</p>"},{"location":"membership_functions/03_bellmf/#derivative-with-respect-to-the-width-a","title":"Derivative with respect to the width ($a$)\u00b6","text":"<p>The partial derivative with respect to the width ($a$) is:</p> <p>$$\\frac{\\partial f}{\\partial a} = \\frac{2b(x-c)^2}{a^3} \\left(1 + \\left|\\frac{x-c}{a}\\right|^{2b}\\right)^{-2}$$</p> <p>This derivative helps in adjusting the spread of the fuzzy set to encompass a broader or narrower range of values.</p>"},{"location":"membership_functions/03_bellmf/#derivative-with-respect-to-the-slope-b","title":"Derivative with respect to the slope ($b$)\u00b6","text":"<p>The partial derivative with respect to the slope ($b$) is:</p> <p>$$\\frac{\\partial f}{\\partial b} = -\\frac{2}{b} \\frac{(x-c)^2}{a^2} \\left(\\frac{1}{1 + \\left|\\frac{x-c}{a}\\right|^{2b}}\\right)^2 \\ln\\left|\\frac{x-c}{a}\\right|$$</p> <p>This derivative is used to modify the steepness of the curve, allowing for fine-tuning of the transition from non-membership to full membership.</p>"},{"location":"membership_functions/03_bellmf/#python-example","title":"Python Example\u00b6","text":"<p>The following code demonstrates how to generate a Generalized Bell membership function using the <code>numpy</code> and <code>matplotlib</code> libraries in Python.</p>"},{"location":"membership_functions/03_bellmf/#visualization","title":"Visualization\u00b6","text":"<p>Below is a visual representation of a Generalized Bell membership function, showing how its shape is influenced by the width ($a$) and slope ($b$) parameters, while the center ($c$) remains fixed.</p>"},{"location":"membership_functions/04_pimf/","title":"Pi-shaped","text":"<p>The Pi-shaped Membership Function is defined piecewise with smooth transitions:</p> <p>$$\\mu(x) = \\begin{array}{ll}  S(x; a, b) &amp; a \\leq x \\leq b \\\\[6pt] 1 &amp; b \\leq x \\leq c \\\\[6pt] Z(x; c, d) &amp; c \\leq x \\leq d \\\\[6pt] 0 &amp; \\text{otherwise} \\end{array}$$</p> <p>Where:</p> <ul> <li>S(x; a, b) is the rising S-shaped function: smooth transition from 0 to 1</li> <li>Z(x; c, d) is the falling Z-shaped function: smooth transition from 1 to 0</li> </ul> <p>The smooth transitions use cubic smoothstep functions:</p> <p>S-function (rising edge): $$S(x; a, b) = 3t^2 - 2t^3 \\quad \\text{where} \\quad t = \\frac{x - a}{b - a}$$</p> <p>Z-function (falling edge): $$Z(x; c, d) = 1 - S(x; c, d) = 1 - (3t^2 - 2t^3) \\quad \\text{where} \\quad t = \\frac{x - c}{d - c}$$</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom anfis_toolbox.membership import PiMF\n\npimf = PiMF(a=1, b=3, c=7, d=9)\n\nx = np.linspace(0, 10, 200)\ny = pimf(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from anfis_toolbox.membership import PiMF  pimf = PiMF(a=1, b=3, c=7, d=9)  x = np.linspace(0, 10, 200) y = pimf(x)  plt.plot(x, y) plt.show()"},{"location":"membership_functions/04_pimf/#pi-shaped","title":"Pi-shaped\u00b6","text":"<p>The Pi-shaped Membership Function creates a smooth bell-like curve with a flat plateau at the top. It combines S-shaped rising and Z-shaped falling edges with a trapezoidal-like plateau, making it ideal for representing concepts with gradual transitions and stable regions.</p>"},{"location":"membership_functions/04_pimf/#parameters","title":"Parameters\u00b6","text":"<p>The function is characterized by four parameters:</p> <ul> <li>a: Left foot - where the function starts rising from 0</li> <li>b: Left shoulder - where the function reaches the plateau (\u03bc = 1)</li> <li>c: Right shoulder - where the function starts falling from the plateau</li> <li>d: Right foot - where the function reaches 0</li> </ul> <p>For a valid Pi-shaped function, parameters must satisfy: a &lt; b \u2264 c &lt; d</p>"},{"location":"membership_functions/04_pimf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":"<p>For optimization in ANFIS networks, we need the gradients of the membership function with respect to each parameter. The PiMF has analytical gradients computed by region:</p>"},{"location":"membership_functions/04_pimf/#s-function-region-a-x-b","title":"S-Function Region (a \u2264 x \u2264 b)\u00b6","text":"<p>For the rising edge: \u03bc(x) = S(x; a, b) = 3t\u00b2 - 2t\u00b3 where t = (x-a)/(b-a)</p> <ul> <li>\u2202\u03bc/\u2202a = dS/dt \u00b7 dt/da = [6t(1-t)] \u00b7 [(x-b)/(b-a)\u00b2]</li> <li>\u2202\u03bc/\u2202b = dS/dt \u00b7 dt/db = [6t(1-t)] \u00b7 [-(x-a)/(b-a)\u00b2]</li> <li>\u2202\u03bc/\u2202c = 0 (no effect in this region)</li> <li>\u2202\u03bc/\u2202d = 0 (no effect in this region)</li> </ul>"},{"location":"membership_functions/04_pimf/#plateau-region-b-x-c","title":"Plateau Region (b \u2264 x \u2264 c)\u00b6","text":"<p>\u03bc(x) = 1 (constant function)</p> <ul> <li>\u2202\u03bc/\u2202a = 0 (constant function)</li> <li>\u2202\u03bc/\u2202b = 0 (constant function)</li> <li>\u2202\u03bc/\u2202c = 0 (constant function)</li> <li>\u2202\u03bc/\u2202d = 0 (constant function)</li> </ul>"},{"location":"membership_functions/04_pimf/#z-function-region-c-x-d","title":"Z-Function Region (c \u2264 x \u2264 d)\u00b6","text":"<p>For the falling edge: \u03bc(x) = Z(x; c, d) = 1 - S(x; c, d) where t = (x-c)/(d-c)</p> <ul> <li>\u2202\u03bc/\u2202a = 0 (no effect in this region)</li> <li>\u2202\u03bc/\u2202b = 0 (no effect in this region)</li> <li>\u2202\u03bc/\u2202c = dZ/dt \u00b7 dt/dc = [-6t(1-t)] \u00b7 [(x-d)/(d-c)\u00b2]</li> <li>\u2202\u03bc/\u2202d = dZ/dt \u00b7 dt/dd = [-6t(1-t)] \u00b7 [-(x-c)/(d-c)\u00b2]</li> </ul>"},{"location":"membership_functions/04_pimf/#python-example","title":"Python Example\u00b6","text":"<p>Let's create a Pi-shaped membership function and visualize it:</p>"},{"location":"membership_functions/04_pimf/#visualization","title":"Visualization\u00b6","text":"<p>The following interactive plot shows different Pi-shaped membership functions with varying parameter combinations. Each subplot demonstrates how the plateau width and transition smoothness affect the overall shape.</p>"},{"location":"membership_functions/05_triangularmf/","title":"Triangular","text":"<p>The Triangular membership function (TriangularMF) is one of the most fundamental and widely used membership functions in fuzzy logic. It represents fuzzy sets with a simple triangular shape, making it intuitive and computationally efficient. The function is defined by three key points that form the triangle: the left base point, the peak, and the right base point.</p> <p>The function is characterized by three main parameters:</p> <ul> <li>a: Left base point of the triangle (\u03bc(x) = 0 for x \u2264 a).</li> <li>b: Peak point of the triangle (\u03bc(b) = 1, the maximum membership value).</li> <li>c: Right base point of the triangle (\u03bc(x) = 0 for x \u2265 c).</li> </ul> <p>These parameters must satisfy the constraint: a \u2264 b \u2264 c.</p> <p>The mathematical formula for the triangular membership function is defined piecewise:</p> <p>$$ \\mu(x) = \\begin{array}{ll} 0, &amp; x \\leq a, \\\\[4pt] \\dfrac{x-a}{b-a}, &amp; a &lt; x \\leq b, \\\\[4pt] \\dfrac{c-x}{c-b}, &amp; b &lt; x &lt; c, \\\\[4pt] 0, &amp; x \\geq c. \\end{array} $$</p> <p>where:</p> <ul> <li>$\\mu(x)$ is the degree of membership of element $x$ in the fuzzy set.</li> <li>$x$ is the input value.</li> <li>$a$ is the left base point.</li> <li>$b$ is the peak point.</li> <li>$c$ is the right base point.</li> </ul> <p>The triangular membership function is particularly useful for representing concepts like \"approximately equal to b\" or \"around b\", where the membership decreases linearly as we move away from the peak value.</p> In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom anfis_toolbox.membership import TriangularMF\n\ntriangular = TriangularMF(a=2, b=5, c=8)\n\nx = np.linspace(0, 10, 100)\ny = triangular(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  from anfis_toolbox.membership import TriangularMF  triangular = TriangularMF(a=2, b=5, c=8)  x = np.linspace(0, 10, 100) y = triangular(x)  plt.plot(x, y) plt.show()"},{"location":"membership_functions/05_triangularmf/#triangular","title":"Triangular\u00b6","text":""},{"location":"membership_functions/05_triangularmf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":"<p>The partial derivatives of the triangular membership function are essential for optimization in adaptive fuzzy systems. Since the function is piecewise linear, the derivatives are computed separately for each region.</p>"},{"location":"membership_functions/05_triangularmf/#derivative-with-respect-to-a","title":"Derivative with respect to $a$\u00b6","text":"<p>For $a &lt; x &lt; b$: $$\\frac{\\partial \\mu}{\\partial a} = \\frac{x-b}{(b-a)^2}$$</p> <p>For other regions: The derivative is 0.</p>"},{"location":"membership_functions/05_triangularmf/#derivative-with-respect-to-b","title":"Derivative with respect to $b$\u00b6","text":"<p>For $a &lt; x &lt; b$: $$\\frac{\\partial \\mu}{\\partial b} = \\frac{-(x-a)}{(b-a)^2}$$</p> <p>For $b &lt; x &lt; c$: $$\\frac{\\partial \\mu}{\\partial b} = \\frac{x-c}{(c-b)^2}$$</p> <p>For other regions: The derivative is 0.</p>"},{"location":"membership_functions/05_triangularmf/#derivative-with-respect-to-c","title":"Derivative with respect to $c$\u00b6","text":"<p>For $b &lt; x &lt; c$: $$\\frac{\\partial \\mu}{\\partial c} = \\frac{x-b}{(c-b)^2}$$</p> <p>For other regions: The derivative is 0.</p> <p>These derivatives enable gradient-based optimization of the triangular membership function parameters, allowing the triangle to adapt its shape during training to better fit the data.</p>"},{"location":"membership_functions/05_triangularmf/#python-example","title":"Python Example\u00b6","text":""},{"location":"membership_functions/05_triangularmf/#visualization","title":"Visualization\u00b6","text":"<p>Below is a comprehensive visualization showing how the TriangularMF shape changes with different parameter combinations. We'll explore variations in the base points (a, c) and peak position (b).</p>"},{"location":"membership_functions/06_trapezoidalmf/","title":"Trapezoidal","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom anfis_toolbox.membership import TrapezoidalMF\n\ntrapezoidal = TrapezoidalMF(a=2, b=4, c=6, d=8)\n\n\nx = np.linspace(0, 10, 200)\ny = trapezoidal(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from anfis_toolbox.membership import TrapezoidalMF  trapezoidal = TrapezoidalMF(a=2, b=4, c=6, d=8)   x = np.linspace(0, 10, 200) y = trapezoidal(x)  plt.plot(x, y) plt.show()"},{"location":"membership_functions/06_trapezoidalmf/#trapezoidal","title":"Trapezoidal\u00b6","text":"<p>The Trapezoidal Membership Function is a piecewise linear function that creates a trapezoid-shaped membership curve. It is widely used in fuzzy logic systems when you need a plateau region of full membership, providing robustness to noise and uncertainty.</p>"},{"location":"membership_functions/06_trapezoidalmf/#mathematical-definition","title":"Mathematical Definition\u00b6","text":"<p>The Trapezoidal Membership Function is defined by the piecewise linear equation:</p> <p>$$\\mu(x) =  \\begin{array}{ll} 0 &amp; x \\leq a \\\\ \\frac{x - a}{b - a} &amp; a &lt; x &lt; b \\\\ 1 &amp; b \\leq x \\leq c \\\\ \\frac{d - x}{d - c} &amp; c &lt; x &lt; d \\\\ 0 &amp; x \\geq d  \\end{array}$$</p>"},{"location":"membership_functions/06_trapezoidalmf/#parameters","title":"Parameters\u00b6","text":"<p>The function is characterized by four parameters:</p> <ul> <li>a: Left base point (lower support bound) - where \u03bc(x) starts increasing from 0</li> <li>b: Left peak point (start of plateau) - where \u03bc(x) reaches 1</li> <li>c: Right peak point (end of plateau) - where \u03bc(x) starts decreasing from 1</li> <li>d: Right base point (upper support bound) - where \u03bc(x) returns to 0</li> </ul>"},{"location":"membership_functions/06_trapezoidalmf/#parameter-constraints","title":"Parameter Constraints\u00b6","text":"<p>For a valid trapezoidal function, parameters must satisfy: a \u2264 b \u2264 c \u2264 d</p>"},{"location":"membership_functions/06_trapezoidalmf/#geometric-interpretation","title":"Geometric Interpretation\u00b6","text":"<ul> <li>The region [a, b] forms the left slope (rising edge)</li> <li>The region [b, c] forms the plateau (full membership region)</li> <li>The region [c, d] forms the right slope (falling edge)</li> <li>Outside [a, d], membership is zero</li> </ul> <p>This shape is particularly useful when you need:</p> <ul> <li>A stable region of full membership (plateau)</li> <li>Gradual transitions at the boundaries</li> <li>Robustness to small variations in input values</li> </ul>"},{"location":"membership_functions/06_trapezoidalmf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":"<p>For optimization in ANFIS networks, we need the gradients of the membership function with respect to each parameter. The derivatives are computed analytically for each region:</p>"},{"location":"membership_functions/06_trapezoidalmf/#left-slope-region-a-x-b","title":"Left Slope Region (a &lt; x &lt; b)\u00b6","text":"<p>$$\\mu(x) = \\frac{x - a}{b - a}$$</p> <ul> <li>\u2202\u03bc/\u2202a = -1/(b-a)</li> <li>\u2202\u03bc/\u2202b = -(x-a)/(b-a)\u00b2</li> <li>\u2202\u03bc/\u2202c = 0 (no effect in this region)</li> <li>\u2202\u03bc/\u2202d = 0 (no effect in this region)</li> </ul>"},{"location":"membership_functions/06_trapezoidalmf/#plateau-region-b-x-c","title":"Plateau Region (b \u2264 x \u2264 c)\u00b6","text":"<p>$$\\mu(x) = 1$$</p> <ul> <li>\u2202\u03bc/\u2202a = 0 (constant function)</li> <li>\u2202\u03bc/\u2202b = 0 (constant function)</li> <li>\u2202\u03bc/\u2202c = 0 (constant function)</li> <li>\u2202\u03bc/\u2202d = 0 (constant function)</li> </ul>"},{"location":"membership_functions/06_trapezoidalmf/#right-slope-region-c-x-d","title":"Right Slope Region (c &lt; x &lt; d)\u00b6","text":"<p>$$\\mu(x) = \\frac{d - x}{d - c}$$</p> <ul> <li>\u2202\u03bc/\u2202a = 0 (no effect in this region)</li> <li>\u2202\u03bc/\u2202b = 0 (no effect in this region)</li> <li>\u2202\u03bc/\u2202c = (x-d)/(d-c)\u00b2</li> <li>\u2202\u03bc/\u2202d = (x-c)/(d-c)\u00b2</li> </ul>"},{"location":"membership_functions/06_trapezoidalmf/#python-example","title":"Python Example\u00b6","text":"<p>Let's create a trapezoidal membership function and visualize it:</p>"},{"location":"membership_functions/06_trapezoidalmf/#visualization","title":"Visualization\u00b6","text":"<p>The following interactive plot shows different trapezoidal membership functions with varying parameter combinations. Each subplot demonstrates how the shape changes with different plateau widths and slope characteristics.</p>"},{"location":"membership_functions/07_sigmoidmf/","title":"Sigmoidal","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom anfis_toolbox.membership import SigmoidalMF\n\nsigmoid = SigmoidalMF(a=2, c=0)\n\nx = np.linspace(-5, 5, 200)\ny = sigmoid(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from anfis_toolbox.membership import SigmoidalMF  sigmoid = SigmoidalMF(a=2, c=0)  x = np.linspace(-5, 5, 200) y = sigmoid(x)  plt.plot(x, y) plt.show()"},{"location":"membership_functions/07_sigmoidmf/#sigmoidal","title":"Sigmoidal\u00b6","text":"<p>The Sigmoidal Membership Function implements a smooth S-shaped curve that transitions gradually from 0 to 1. It is widely used in fuzzy logic systems and neural networks for modeling smooth transitions and gradual changes.</p>"},{"location":"membership_functions/07_sigmoidmf/#mathematical-definition","title":"Mathematical Definition\u00b6","text":"<p>The Sigmoidal Membership Function is defined by the logistic function:</p> <p>$$\\mu(x) = \\frac{1}{1 + e^{-a(x - c)}}$$</p>"},{"location":"membership_functions/07_sigmoidmf/#parameters","title":"Parameters\u00b6","text":"<p>The function is characterized by two parameters:</p> <ul> <li><p>a: Slope parameter - controls the steepness of the S-curve</p> <ul> <li>Positive values: standard sigmoid (0 \u2192 1 as x increases)</li> <li>Negative values: inverted sigmoid (1 \u2192 0 as x increases)</li> <li>Larger |a|: steeper transition (more abrupt change)</li> <li>Smaller |a|: gentler transition (more gradual change)</li> </ul> </li> <li><p>c: Center parameter - controls the inflection point where \u03bc(c) = 0.5</p> <ul> <li>\u03bc(c) = 0.5 (50% membership)</li> <li>Shifts the curve left/right along the x-axis</li> </ul> </li> </ul>"},{"location":"membership_functions/07_sigmoidmf/#parameter-constraints","title":"Parameter Constraints\u00b6","text":"<ul> <li>a \u2260 0: Cannot be zero (would result in constant function \u03bc(x) = 0.5)</li> <li>a and c can be any real numbers otherwise</li> </ul>"},{"location":"membership_functions/07_sigmoidmf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":"<p>For optimization in ANFIS networks, we need the gradients of the membership function with respect to each parameter. The sigmoid function has elegant derivative properties:</p>"},{"location":"membership_functions/07_sigmoidmf/#derivative-of-the-sigmoid-function","title":"Derivative of the Sigmoid Function\u00b6","text":"<p>For \u03bc(x) = 1/(1 + e^{-a(x-c)}), the derivative with respect to x is:</p> <p>$$\\frac{d\\mu}{dx} = \\mu(x) \\cdot (1 - \\mu(x)) \\cdot a$$</p> <p>This is a fundamental property of the sigmoid function and is used extensively in neural networks.</p>"},{"location":"membership_functions/07_sigmoidmf/#partial-derivatives-wrt-parameters","title":"Partial Derivatives w.r.t. Parameters\u00b6","text":"<p>For \u03bc(x) = 1/(1 + exp(-a(x-c))):</p> <ul> <li>\u2202\u03bc/\u2202a = \u03bc(x) \u00b7 (1 - \u03bc(x)) \u00b7 (x - c)</li> <li>\u2202\u03bc/\u2202c = -a \u00b7 \u03bc(x) \u00b7 (1 - \u03bc(x))</li> </ul>"},{"location":"membership_functions/07_sigmoidmf/#python-example","title":"Python Example\u00b6","text":"<p>Let's create a sigmoidal membership function and visualize it:</p>"},{"location":"membership_functions/07_sigmoidmf/#visualization","title":"Visualization\u00b6","text":"<p>The following interactive plot shows different sigmoidal membership functions with varying parameter combinations. Each subplot demonstrates how the slope (a) and center (c) parameters affect the shape of the S-curve.</p>"},{"location":"membership_functions/08_diffsigmoidalmf/","title":"Difference of Sigmoidal","text":"In\u00a0[5]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom anfis_toolbox.membership import DiffSigmoidalMF\n\ndiff_sigmoid = DiffSigmoidalMF(a1=2, c1=4, a2=5, c2=8)\n\nx = np.linspace(0, 10, 100)\ny = diff_sigmoid(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from anfis_toolbox.membership import DiffSigmoidalMF  diff_sigmoid = DiffSigmoidalMF(a1=2, c1=4, a2=5, c2=8)  x = np.linspace(0, 10, 100) y = diff_sigmoid(x)  plt.plot(x, y) plt.show()"},{"location":"membership_functions/08_diffsigmoidalmf/#difference-of-sigmoidal","title":"Difference of Sigmoidal\u00b6","text":"<p>The Difference of Sigmoidal Membership Functions implements \u03bc(x) = s\u2081(x) - s\u2082(x), where each s is a logistic curve with its own slope and center parameters. This creates complex membership shapes by combining two sigmoid functions.</p>"},{"location":"membership_functions/08_diffsigmoidalmf/#mathematical-definition","title":"Mathematical Definition\u00b6","text":"<p>The Difference of Sigmoidal Membership Functions is defined as:</p> <p>$$\\mu(x) = s_1(x) - s_2(x)$$</p> <p>Where each sigmoid function is:</p> <p>$$s_1(x) = \\frac{1}{1 + e^{-a_1(x - c_1)}}$$ $$s_2(x) = \\frac{1}{1 + e^{-a_2(x - c_2)}}$$</p>"},{"location":"membership_functions/08_diffsigmoidalmf/#parameters","title":"Parameters\u00b6","text":"<p>The function is characterized by four parameters (two for each sigmoid):</p> <ul> <li><p>a\u2081: Slope parameter for the first sigmoid (s\u2081)</p> <ul> <li>Positive values: standard sigmoid (0 \u2192 1 as x increases)</li> <li>Negative values: inverted sigmoid (1 \u2192 0 as x increases)</li> <li>Larger |a\u2081|: steeper transition for s\u2081</li> </ul> </li> <li><p>c\u2081: Center parameter for the first sigmoid (s\u2081)</p> <ul> <li>Controls the inflection point where s\u2081(c\u2081) = 0.5</li> <li>Shifts s\u2081 left/right along the x-axis</li> </ul> </li> <li><p>a\u2082: Slope parameter for the second sigmoid (s\u2082)</p> <ul> <li>Same interpretation as a\u2081 but for s\u2082</li> </ul> </li> <li><p>c\u2082: Center parameter for the second sigmoid (s\u2082)</p> <ul> <li>Same interpretation as c\u2081 but for s\u2082</li> </ul> </li> </ul>"},{"location":"membership_functions/08_diffsigmoidalmf/#parameter-constraints","title":"Parameter Constraints\u00b6","text":"<ul> <li>a\u2081 \u2260 0 and a\u2082 \u2260 0: Cannot be zero (would result in constant functions)</li> <li>All parameters can be any real numbers otherwise</li> </ul>"},{"location":"membership_functions/08_diffsigmoidalmf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":"<p>For optimization in ANFIS networks, we need the gradients of the membership function with respect to each parameter. Since \u03bc(x) = s\u2081(x) - s\u2082(x), the derivatives follow from the chain rule:</p>"},{"location":"membership_functions/08_diffsigmoidalmf/#derivative-wrt-parameters-of-first-sigmoid-s1","title":"Derivative w.r.t. Parameters of First Sigmoid (s\u2081)\u00b6","text":"<p>For s\u2081(x) = 1/(1 + exp(-a\u2081(x - c\u2081))):</p> <ul> <li>\u2202\u03bc/\u2202a\u2081 = \u2202s\u2081/\u2202a\u2081 = s\u2081(x) \u00b7 (1 - s\u2081(x)) \u00b7 (x - c\u2081)</li> <li>\u2202\u03bc/\u2202c\u2081 = \u2202s\u2081/\u2202c\u2081 = -a\u2081 \u00b7 s\u2081(x) \u00b7 (1 - s\u2081(x))</li> </ul>"},{"location":"membership_functions/08_diffsigmoidalmf/#derivative-wrt-parameters-of-second-sigmoid-s2","title":"Derivative w.r.t. Parameters of Second Sigmoid (s\u2082)\u00b6","text":"<p>For s\u2082(x) = 1/(1 + exp(-a\u2082(x - c\u2082))), and since \u03bc(x) = s\u2081(x) - s\u2082(x):</p> <ul> <li>\u2202\u03bc/\u2202a\u2082 = -\u2202s\u2082/\u2202a\u2082 = -s\u2082(x) \u00b7 (1 - s\u2082(x)) \u00b7 (x - c\u2082)</li> <li>\u2202\u03bc/\u2202c\u2082 = -\u2202s\u2082/\u2202c\u2082 = -(-a\u2082 \u00b7 s\u2082(x) \u00b7 (1 - s\u2082(x))) = a\u2082 \u00b7 s\u2082(x) \u00b7 (1 - s\u2082(x))</li> </ul>"},{"location":"membership_functions/08_diffsigmoidalmf/#derivative-wrt-input-optional","title":"Derivative w.r.t. Input (Optional)\u00b6","text":"<p>For chaining in neural networks:</p> <p>$$\\frac{d\\mu}{dx} = \\frac{ds_1}{dx} - \\frac{ds_2}{dx}$$</p> <p>Where: $$\\frac{ds_1}{dx} = a_1 \\cdot s_1(x) \\cdot (1 - s_1(x))$$ $$\\frac{ds_2}{dx} = a_2 \\cdot s_2(x) \\cdot (1 - s_2(x))$$</p>"},{"location":"membership_functions/08_diffsigmoidalmf/#gradient-computation-details","title":"Gradient Computation Details\u00b6","text":"<p>The gradients are computed using the fundamental sigmoid derivative property: $$\\frac{d}{dx}\\left(\\frac{1}{1+e^{-z}}\\right) = \\frac{1}{1+e^{-z}} \\cdot \\left(1 - \\frac{1}{1+e^{-z}}\\right) = s(x) \\cdot (1 - s(x))$$</p> <p>This property is used extensively in neural network backpropagation and makes the DiffSigmoidalMF computationally efficient for optimization.</p>"},{"location":"membership_functions/08_diffsigmoidalmf/#python-example","title":"Python Example\u00b6","text":"<p>Let's create a difference of sigmoidal membership functions and visualize its components:</p>"},{"location":"membership_functions/08_diffsigmoidalmf/#visualization","title":"Visualization\u00b6","text":"<p>The following interactive plot shows different difference of sigmoidal membership functions with varying parameter combinations. Each subplot demonstrates how the combination of two sigmoids creates complex membership shapes.</p>"},{"location":"membership_functions/09_prodsigmoidalmf/","title":"Product of Sigmoidal","text":"In\u00a0[12]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom anfis_toolbox.membership import ProdSigmoidalMF\n\nmf = ProdSigmoidalMF(a1=2, c1=3, a2=-2, c2=4)\n\nx = np.linspace(0, 10, 400)\ny = mf(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from anfis_toolbox.membership import ProdSigmoidalMF  mf = ProdSigmoidalMF(a1=2, c1=3, a2=-2, c2=4)  x = np.linspace(0, 10, 400) y = mf(x)  plt.plot(x, y) plt.show()"},{"location":"membership_functions/09_prodsigmoidalmf/#product-of-sigmoidal","title":"Product of Sigmoidal\u00b6","text":"<p>The Product of Sigmoidal Membership Function creates a smooth, asymmetrical, bell-shaped curve by multiplying two distinct sigmoidal functions. It's used to model fuzzy sets that require a gradual but non-uniform transition, offering more flexibility than symmetric functions.</p>"},{"location":"membership_functions/09_prodsigmoidalmf/#mathematical-definition","title":"Mathematical Definition\u00b6","text":"<p>The function is defined as the product of two sigmoidal functions:</p> <p>$$\\mu(x) = f_1(x) \\cdot f_2(x)$$ $$f_1(x) = \\frac{1}{1 + e^{-a_1(x-c_1)}}$$ $$f_2(x) = \\frac{1}{1 + e^{-a_2(x-c_2)}}$$</p>"},{"location":"membership_functions/09_prodsigmoidalmf/#parameters","title":"Parameters\u00b6","text":"<p>The function is controlled by four parameters, two for each component sigmoid:</p> <ul> <li>$a_1$: Slope of the first sigmoid function.</li> <li>$c_1$: Center (inflection point) of the first sigmoid function.</li> <li>$a_2$: Slope of the second sigmoid function.</li> <li>$c_2$: Center (inflection point) of the second sigmoid function.</li> </ul>"},{"location":"membership_functions/09_prodsigmoidalmf/#parameter-constraints","title":"Parameter Constraints\u00b6","text":"<ul> <li>To form a proper bell-shaped curve, the slopes $a_1$ and $a_2$ must have opposite signs (e.g., if $a_1 &gt; 0$, then $a_2 &lt; 0$).</li> <li>The centers $c_1$ and $c_2$ determine the width and position of the curve's peak.</li> </ul>"},{"location":"membership_functions/09_prodsigmoidalmf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":"<p>The partial derivatives with respect to the parameters $a_1, c_1, a_2,$ and $c_2$ are:</p> <ol> <li><p>With respect to $a_1$: $$\\frac{\\partial \\mu}{\\partial a_1} = (x-c_1) \\cdot (1 - f_1(x)) \\cdot \\mu(x)$$</p> </li> <li><p>With respect to $c_1$: $$\\frac{\\partial \\mu}{\\partial c_1} = -a_1 \\cdot (1 - f_1(x)) \\cdot \\mu(x)$$</p> </li> <li><p>With respect to $a_2$: $$\\frac{\\partial \\mu}{\\partial a_2} = (x-c_2) \\cdot (1 - f_2(x)) \\cdot \\mu(x)$$</p> </li> <li><p>With respect to $c_2$: $$\\frac{\\partial \\mu}{\\partial c_2} = -a_2 \\cdot (1 - f_2(x)) \\cdot \\mu(x)$$</p> </li> </ol>"},{"location":"membership_functions/09_prodsigmoidalmf/#python-example","title":"Python Example\u00b6","text":""},{"location":"membership_functions/09_prodsigmoidalmf/#visualization","title":"Visualization\u00b6","text":"<p>Below is a comprehensive visualization showing how the ProdSigmoidalMF shape changes with different parameter combinations.</p>"},{"location":"membership_functions/10_zshapedmf/","title":"Z-shaped","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom anfis_toolbox.membership import ZShapedMF\n\nmf = ZShapedMF(a=15, b=25)\n\nx = np.linspace(0, 40, 100)\ny = mf(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from anfis_toolbox.membership import ZShapedMF  mf = ZShapedMF(a=15, b=25)  x = np.linspace(0, 40, 100) y = mf(x)  plt.plot(x, y) plt.show() <p>Below is a comprehensive visualization showing how the ZShapedMF shape changes with different parameter combinations.</p>"},{"location":"membership_functions/10_zshapedmf/#z-shaped","title":"Z-shaped\u00b6","text":"<p>The Z-shaped Membership Function (<code>ZShapedMF</code>) is a fundamental type of membership function in fuzzy logic. It provides a smooth and continuous transition from a full degree of membership (1.0) to zero. This form is ideal for modeling concepts like \"cold\" or \"slow,\" where membership is high up to a certain point and then decreases gradually. The transition is defined using a cubic polynomial, resulting in a smooth curve without angular points.</p>"},{"location":"membership_functions/10_zshapedmf/#parameters","title":"Parameters\u00b6","text":"<p>The function is defined by two key parameters that delimit the transition region:</p> <ul> <li><code>a</code> (Left Shoulder): The point where the transition from a full degree of membership (1.0) begins. For input values less than or equal to <code>a</code>, the membership is always 1.0.</li> <li><code>b</code> (Right Foot): The point where the transition ends and the degree of membership becomes zero. For input values greater than or equal to <code>b</code>, the membership is always 0.0.</li> </ul> <p>It is crucial that <code>a</code> is less than <code>b</code> for the transition to occur correctly.</p>"},{"location":"membership_functions/10_zshapedmf/#mathematical-formula","title":"Mathematical Formula\u00b6","text":"<p>The formula for the <code>ZShapedMF</code> is based on the smoothstep function, a third-degree polynomial. The function is defined in parts:</p> <p>$$ \\mu(x) = \\begin{array}{ll} 1, &amp; x \\leq a, \\\\[6pt] 1 - \\bigl(3t^{2} - 2t^{3}\\bigr),  &amp; a &lt; x &lt; b \\\\[6pt] 0, &amp; x \\geq b. \\end{array} $$</p> <p>Where:</p> <p>$\\mu(x)$ is the degree of membership of element $x$ and $t = \\dfrac{x-a}{\\,b-a\\,}$.</p>"},{"location":"membership_functions/10_zshapedmf/#partial-derivatives-gradients","title":"Partial Derivatives (Gradients)\u00b6","text":"<p>The partial derivatives are crucial for optimizing the parameters <code>a</code> and <code>b</code> in adaptive fuzzy systems. They show how the function's output changes in response to small changes in these parameters.</p>"},{"location":"membership_functions/10_zshapedmf/#derivative-with-respect-to-a-fracpartial-mupartial-a","title":"Derivative with respect to <code>a</code> ($\\frac{\\partial \\mu}{\\partial a}$)\u00b6","text":"<p>This derivative indicates how the degree of membership is affected by adjusting the starting point of the transition.</p> <p>$$\\frac{\\partial \\mu}{\\partial a} = \\frac{\\partial \\mu}{\\partial t} \\frac{\\partial t}{\\partial a} = - (6t(t-1)) \\cdot \\frac{x-b}{(b-a)^2}$$</p>"},{"location":"membership_functions/10_zshapedmf/#derivative-with-respect-to-b-fracpartial-mupartial-b","title":"Derivative with respect to <code>b</code> ($\\frac{\\partial \\mu}{\\partial b}$)\u00b6","text":"<p>This derivative indicates how the degree of membership is affected by adjusting the endpoint of the transition.</p> <p>$$\\frac{\\partial \\mu}{\\partial b} = \\frac{\\partial \\mu}{\\partial t} \\frac{\\partial t}{\\partial b} = - (6t(t-1)) \\cdot - \\frac{x-a}{(b-a)^2}$$</p>"},{"location":"membership_functions/10_zshapedmf/#python-example","title":"Python Example\u00b6","text":""},{"location":"membership_functions/10_zshapedmf/#visualization","title":"Visualization\u00b6","text":""},{"location":"membership_functions/11_linzshapedmf/","title":"Linear Z-shaped","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom anfis_toolbox.membership import LinZShapedMF\n\nmf = LinZShapedMF(a=15, b=35)\n\nx = np.linspace(0, 50, 100)\ny = mf.forward(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from anfis_toolbox.membership import LinZShapedMF  mf = LinZShapedMF(a=15, b=35)  x = np.linspace(0, 50, 100) y = mf.forward(x)  plt.plot(x, y) plt.show()"},{"location":"membership_functions/11_linzshapedmf/#linear-z-shaped","title":"Linear Z-shaped\u00b6","text":"<p>The Linear Z-shaped Membership Function (<code>LinZShapedMF</code>) is a type of membership function in fuzzy logic that represents a smooth linear transition from a full degree of membership (1.0) to zero. Its shape is ideal for modeling concepts like \"cold\" or \"low,\" where membership is high up to a certain point and then decreases linearly to zero.</p>"},{"location":"membership_functions/11_linzshapedmf/#parameters","title":"Parameters\u00b6","text":"<p>The function is defined by two parameters that delimit the linear transition region:</p> <ul> <li><code>a</code> (Left Shoulder): The point where the membership value begins to transition from 1.0. For input values less than or equal to <code>a</code>, the membership is always 1.0.</li> <li><code>b</code> (Right Foot): The point where the membership value reaches and stays at zero. For input values greater than or equal to <code>b</code>, the membership is always 0.0.</li> </ul> <p>It is crucial that the parameter <code>a</code> is less than <code>b</code> for the linear transition to occur correctly.</p>"},{"location":"membership_functions/11_linzshapedmf/#mathematical-formula","title":"Mathematical Formula\u00b6","text":"<p>The formula for the <code>LinZShapedMF</code> is a piecewise linear function:</p> <p>$$ \\mu(x) = \\begin{array}{ll} 1, &amp; x \\le a \\\\[6pt] \\frac{b - x}{b - a}, &amp; a &lt; x &lt; b \\\\[6pt] 0, &amp; x \\ge b \\end{array} $$</p> <p>Where $\\mu(x)$ is the degree of membership of element $x$ in the fuzzy set.</p>"},{"location":"membership_functions/11_linzshapedmf/#partial-derivatives-gradients","title":"Partial Derivatives (Gradients)\u00b6","text":"<p>The partial derivatives are essential for optimizing the parameters <code>a</code> and <code>b</code> in adaptive fuzzy systems.</p>"},{"location":"membership_functions/11_linzshapedmf/#derivative-with-respect-to-a","title":"Derivative with respect to <code>a</code>\u00b6","text":"<p>$$\\frac{\\partial \\mu}{\\partial a} = \\frac{b - x}{(b - a)^2}$$</p>"},{"location":"membership_functions/11_linzshapedmf/#derivative-with-respect-to-b","title":"Derivative with respect to <code>b</code>\u00b6","text":"<p>$$\\frac{\\partial \\mu}{\\partial b} = -\\frac{x - a}{(b - a)^2}$$</p>"},{"location":"membership_functions/11_linzshapedmf/#python-example","title":"Python Example\u00b6","text":""},{"location":"membership_functions/11_linzshapedmf/#visualization","title":"Visualization\u00b6","text":"<p>Below is a comprehensive visualization showing how the LinZShapedMF shape changes with different parameter combinations.</p>"},{"location":"membership_functions/12_sshapedmf/","title":"S-shaped","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom anfis_toolbox.membership import SShapedMF\n\n\nmf = SShapedMF(a=2, b=8)\n\nx = np.linspace(0, 10, 200)\ny = mf(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from anfis_toolbox.membership import SShapedMF   mf = SShapedMF(a=2, b=8)  x = np.linspace(0, 10, 200) y = mf(x)  plt.plot(x, y) plt.show()"},{"location":"membership_functions/12_sshapedmf/#s-shaped","title":"S-shaped\u00b6","text":"<p>The S-shaped Membership Function (<code>SShapedMF</code>) is a type of membership function used in fuzzy logic. It models the gradual transition from a zero degree of membership (0.0) to a full degree (1.0). This form is ideal for representing concepts like \"hot\" or \"fast,\" where membership starts low and progressively increases to a certain point. The transition is defined by a cubic polynomial, resulting in a smooth, continuous curve without angular points.</p>"},{"location":"membership_functions/12_sshapedmf/#parameters","title":"Parameters\u00b6","text":"<p>The S-shaped function's curve is defined by two main parameters:</p> <ul> <li>$a$: The point where the function begins to rise from a membership degree of 0.0.</li> <li>$b$: The point where the function reaches a membership degree of 1.0.</li> </ul> <p>The transition between these two points is described by the following equation:</p> <p>$$ S(x; a, b) = \\begin{array}{ll} 0 &amp; x \\le a \\\\[6pt] 2 \\left( \\frac{x-a}{b-a} \\right)^2 &amp; a &lt; x \\le \\frac{a+b}{2} \\\\[6pt] 1 - 2 \\left( \\frac{x-b}{b-a} \\right)^2 &amp; \\frac{a+b}{2} &lt; x &lt; b \\\\[6pt] 1 &amp; x \\ge b \\end{array}{ll} $$</p> <p>This formulation ensures a smooth and continuous transition between the different segments of the curve, which is fundamental for representing uncertainties and imprecision in fuzzy logic systems.</p>"},{"location":"membership_functions/12_sshapedmf/#partial-derivatives","title":"Partial Derivatives\u00b6","text":"<p>To optimize the shape of the S-shaped membership function for a specific application, it's often necessary to calculate the partial derivatives with respect to its parameters, $a$ and $b$. These derivatives are crucial for optimization algorithms like gradient descent.</p>"},{"location":"membership_functions/12_sshapedmf/#partial-derivative-with-respect-to-a","title":"Partial Derivative with Respect to $a$\u00b6","text":"<p>The partial derivative of the S-shaped function with respect to the parameter $a$ is calculated as follows:</p> <p>$$ \\frac{\\partial S}{\\partial a} = \\begin{array}{ll}   0 &amp; x \\le a \\\\[6pt]   \\frac{-4(x-a)}{(b-a)^2} + \\frac{4(x-a)^2}{(b-a)^3} &amp; a &lt; x \\le \\frac{a+b}{2} \\\\[6pt]   \\frac{4(x-b)^2}{(b-a)^3} &amp; \\frac{a+b}{2} &lt; x &lt; b \\\\[6pt]   0 &amp; x \\ge b \\end{array} $$</p> <p>This derivative shows how the membership value changes as the starting point of the curve, $a$, is adjusted.</p>"},{"location":"membership_functions/12_sshapedmf/#partial-derivative-with-respect-to-b","title":"Partial Derivative with Respect to $b$\u00b6","text":"<p>The partial derivative of the S-shaped function with respect to the parameter $b$ is calculated as follows:</p> <p>$$ \\frac{\\partial S}{\\partial b} = \\begin{array}{ll}   0 &amp; x \\le a \\\\[6pt]   \\frac{-4(x-a)^2}{(b-a)^3} &amp; a &lt; x \\le \\frac{a+b}{2} \\\\[6pt]   \\frac{-4(x-b)}{(b-a)^2} + \\frac{4(x-b)^2}{(b-a)^3} &amp; \\frac{a+b}{2} &lt; x &lt; b \\\\[6pt]   0 &amp; x \\ge b \\end{array} $$</p> <p>This derivative indicates how the membership value changes as the ending point of the curve, $b$, is adjusted.</p> <p>These partial derivatives are essential tools for tuning the S-shaped membership function to better fit data or to meet specific system requirements. They enable gradient-based optimization by providing the direction and magnitude of the steepest ascent/descent for the parameters.</p>"},{"location":"membership_functions/12_sshapedmf/#python-example","title":"Python Example\u00b6","text":""},{"location":"membership_functions/12_sshapedmf/#visualization","title":"Visualization\u00b6","text":"<p>Below is a visual representation of the S-shaped membership function, showing how its shape is influenced by the parameters <code>a</code> and <code>b</code>.</p>"},{"location":"membership_functions/13_linsshapedmf/","title":"Linear S-shaped","text":"In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom anfis_toolbox.membership import LinSShapedMF\n\nmf = LinSShapedMF(a=3, b=7)\n\nx = np.linspace(0, 10, 100)\ny = mf.forward(x)\n\nplt.plot(x, y)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from anfis_toolbox.membership import LinSShapedMF  mf = LinSShapedMF(a=3, b=7)  x = np.linspace(0, 10, 100) y = mf.forward(x)  plt.plot(x, y) plt.show()"},{"location":"membership_functions/13_linsshapedmf/#linear-s-shaped","title":"Linear S-shaped\u00b6","text":"<p>The linear S-shaped membership function (<code>LinSShapedMF</code>) is a fundamental concept in fuzzy logic, used to define fuzzy sets. Unlike a classical set where an element either fully belongs or doesn't, a fuzzy set allows for partial membership, and the <code>LinSShapedMF</code> provides a smooth, continuous way to represent this degree of belonging.</p> <p>It's a piecewise linear function that transitions from 0 to 1 over a defined interval.</p>"},{"location":"membership_functions/13_linsshapedmf/#parameters","title":"Parameters\u00b6","text":"<p>The function is characterized by two main parameters:</p> <ul> <li><code>a</code> (start point): The \"left foot\" of the curve. This is the point where the membership transition begins from 0.</li> <li><code>b</code> (end point): The \"right shoulder\" of the curve. This is the point where the membership reaches and stays at 1. The parameter <code>b</code> must always be greater than <code>a</code>.</li> </ul>"},{"location":"membership_functions/13_linsshapedmf/#mathematical-formula","title":"Mathematical Formula\u00b6","text":"<p>The mathematical formula for the linear S-shaped membership function is given by:</p> <ul> <li>$\u03bc(x) = 0$, for $x \\le a$</li> <li>$\u03bc(x) = (x - a) / (b - a)$, for $a &lt; x &lt; b$</li> <li>$\u03bc(x) = 1$, for $x \\ge b$</li> </ul> <p>Where:</p> <ul> <li>$\u03bc(x)$ is the degree of membership for element $x$ in the fuzzy set.</li> <li>$a$ and $b$ are the parameters that define the start and end of the linear ramp.</li> </ul>"},{"location":"membership_functions/13_linsshapedmf/#partial-derivatives-gradients","title":"Partial Derivatives (Gradients)\u00b6","text":"<p>The partial derivatives of the membership function are crucial for optimization algorithms, such as backpropagation, which allow the system to adapt. They indicate how the membership value changes in response to small adjustments in the parameters <code>a</code> and <code>b</code>.</p>"},{"location":"membership_functions/13_linsshapedmf/#derivative-with-respect-to-a-fracpartial-mupartial-a","title":"Derivative with respect to <code>a</code> ($\\frac{\\partial \\mu}{\\partial a}$)\u00b6","text":"<p>The partial derivative with respect to <code>a</code> indicates how the membership value is affected when the starting point of the ramp is adjusted.</p> <p>$\\frac{\\partial \\mu}{\\partial a} = -\\frac{1}{b-a}$ (for the ramp region)</p>"},{"location":"membership_functions/13_linsshapedmf/#derivative-with-respect-to-b-fracpartial-mupartial-b","title":"Derivative with respect to <code>b</code> ($\\frac{\\partial \\mu}{\\partial b}$)\u00b6","text":"<p>The partial derivative with respect to <code>b</code> shows how the membership value changes when the end point of the ramp is adjusted.</p> <p>$\\frac{\\partial \\mu}{\\partial b} = \\frac{x-a}{(b-a)^2}$ (for the ramp region)</p>"},{"location":"membership_functions/13_linsshapedmf/#visualization","title":"Visualization\u00b6","text":"<p>Below is a visual representation of the S-shaped membership function, showing how its shape is influenced by the parameters <code>a</code> and <code>b</code>.</p>"}]}